"""
torchvision.models ä½¿ç”¨å®Œå…¨æŒ‡å—

è¿™ä¸ªæ¨¡å—æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨ torchvision.models ä¸­çš„é¢„è®­ç»ƒæ¨¡å‹ï¼š
1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹çš„å¤šç§æ–¹å¼
2. æ¨¡å‹ç»“æ„æŸ¥çœ‹å’Œä¿®æ”¹
3. ç‰¹å¾æå– vs å¾®è°ƒ
4. è¿ç§»å­¦ä¹ çš„å®é™…åº”ç”¨
5. ä¸åŒæ¨¡å‹æ¶æ„çš„å¯¹æ¯”

ä½œè€…: Seeback
æ—¥æœŸ: 2025-10-23
"""

import torch
import torch.nn as nn
import torchvision.models as models
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np


def demo_available_models():
    """æ¼”ç¤º torchvision ä¸­å¯ç”¨çš„æ¨¡å‹"""
    print("=" * 70)
    print("torchvision.models ä¸­å¯ç”¨çš„ä¸»æµæ¨¡å‹")
    print("=" * 70)

    model_categories = {
        "ç»å…¸CNNæ¶æ„": [
            "alexnet", "vgg11", "vgg16", "vgg19",
            "resnet18", "resnet34", "resnet50", "resnet101", "resnet152"
        ],
        "è½»é‡çº§æ¨¡å‹": [
            "mobilenet_v2", "mobilenet_v3_small", "mobilenet_v3_large",
            "shufflenet_v2_x0_5", "shufflenet_v2_x1_0"
        ],
        "é«˜æ€§èƒ½æ¨¡å‹": [
            "efficientnet_b0", "efficientnet_b4", "efficientnet_b7",
            "resnext50_32x4d", "wide_resnet50_2"
        ],
        "è§†è§‰Transformer": [
            "vit_b_16", "vit_b_32", "vit_l_16",
            "swin_t", "swin_s", "swin_b"
        ],
        "ç›®æ ‡æ£€æµ‹": [
            "fasterrcnn_resnet50_fpn", "maskrcnn_resnet50_fpn",
            "retinanet_resnet50_fpn"
        ],
        "è¯­ä¹‰åˆ†å‰²": [
            "fcn_resnet50", "deeplabv3_resnet50",
            "lraspp_mobilenet_v3_large"
        ]
    }

    for category, model_list in model_categories.items():
        print(f"\nğŸ“¦ {category}:")
        for model_name in model_list:
            print(f"   - {model_name}")

    print("\n" + "=" * 70)
    print("ğŸ’¡ æç¤º: æ‰€æœ‰æ¨¡å‹éƒ½å¯ä»¥é€šè¿‡ models.æ¨¡å‹å(weights='DEFAULT') åŠ è½½")
    print("=" * 70)


def demo_load_pretrained_models():
    """æ¼”ç¤ºåŠ è½½é¢„è®­ç»ƒæ¨¡å‹çš„ä¸åŒæ–¹å¼"""
    print("\n" + "=" * 70)
    print("åŠ è½½é¢„è®­ç»ƒæ¨¡å‹çš„æ–¹å¼")
    print("=" * 70)

    # æ–¹å¼1: æ—§ç‰ˆAPI (PyTorch < 1.13)
    print("\n1ï¸âƒ£ æ—§ç‰ˆAPI (ä¸æ¨è,ä½†ä»å¯ç”¨):")
    print("   model = models.resnet18(pretrained=True)")

    # æ–¹å¼2: æ–°ç‰ˆAPI (PyTorch >= 1.13) - æ¨è
    print("\n2ï¸âƒ£ æ–°ç‰ˆAPI (æ¨è):")
    print("   from torchvision.models import ResNet18_Weights")
    print("   model = models.resnet18(weights=ResNet18_Weights.DEFAULT)")
    print("   æˆ–è€…ç®€åŒ–å†™æ³•:")
    print("   model = models.resnet18(weights='DEFAULT')")

    # æ–¹å¼3: ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡
    print("\n3ï¸âƒ£ ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡:")
    print("   model = models.resnet18(weights=None)")

    # å®é™…åŠ è½½ä¸€ä¸ªæ¨¡å‹
    print("\nğŸ“¥ å®é™…åŠ è½½ ResNet-18 æ¨¡å‹...")
    model = models.resnet18(weights='DEFAULT')

    # æ¨¡å‹ä¿¡æ¯
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"\næ¨¡å‹å‚æ•°ç»Ÿè®¡:")
    print(f"   æ€»å‚æ•°é‡: {total_params:,}")
    print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"   æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB (float32)")

    return model


def demo_model_structure(model):
    """æ¼”ç¤ºå¦‚ä½•æŸ¥çœ‹å’Œç†è§£æ¨¡å‹ç»“æ„"""
    print("\n" + "=" * 70)
    print("æ¨¡å‹ç»“æ„åˆ†æ")
    print("=" * 70)

    print("\n1ï¸âƒ£ ResNet-18 æ•´ä½“ç»“æ„:")
    print("-" * 70)
    print(model)

    print("\n" + "=" * 70)
    print("2ï¸âƒ£ å…³é”®å±‚è§£æ:")
    print("-" * 70)
    print(f"   è¾“å…¥å±‚: conv1 - {model.conv1}")
    print(f"   BatchNorm: bn1 - {model.bn1}")
    print(f"   æ¿€æ´»å‡½æ•°: relu - {model.relu}")
    print(f"   æ± åŒ–å±‚: maxpool - {model.maxpool}")
    print(f"   æ®‹å·®å—1: layer1 - {len(model.layer1)} ä¸ªBasicBlock")
    print(f"   æ®‹å·®å—2: layer2 - {len(model.layer2)} ä¸ªBasicBlock")
    print(f"   æ®‹å·®å—3: layer3 - {len(model.layer3)} ä¸ªBasicBlock")
    print(f"   æ®‹å·®å—4: layer4 - {len(model.layer4)} ä¸ªBasicBlock")
    print(f"   å…¨å±€å¹³å‡æ± åŒ–: avgpool - {model.avgpool}")
    print(f"   åˆ†ç±»å™¨: fc - {model.fc}")

    # æŸ¥çœ‹è¾“å…¥è¾“å‡ºå½¢çŠ¶
    print("\n" + "=" * 70)
    print("3ï¸âƒ£ æ•°æ®æµåŠ¨æ¼”ç¤º (è¾“å…¥: 224x224 RGBå›¾åƒ):")
    print("-" * 70)

    # åˆ›å»ºä¸€ä¸ªæµ‹è¯•è¾“å…¥
    dummy_input = torch.randn(1, 3, 224, 224)

    with torch.no_grad():
        # é€å±‚æŸ¥çœ‹å½¢çŠ¶å˜åŒ–
        x = dummy_input
        print(f"   è¾“å…¥å½¢çŠ¶: {x.shape}")

        x = model.conv1(x) # conv1: å·ç§¯å±‚, è¾“å…¥: 3é€šé“, è¾“å‡º: 64é€šé“, æ ¸å¤§å°: 7x7, æ­¥é•¿: 2, å¡«å……: 3
        print(f"   conv1 å: {x.shape}")

        x = model.bn1(x)
        x = model.relu(x)
        x = model.maxpool(x)
        print(f"   maxpool å: {x.shape}")

        x = model.layer1(x)
        print(f"   layer1 å: {x.shape}")

        x = model.layer2(x)
        print(f"   layer2 å: {x.shape}")

        x = model.layer3(x)
        print(f"   layer3 å: {x.shape}")

        x = model.layer4(x)
        print(f"   layer4 å: {x.shape}")

        x = model.avgpool(x)
        print(f"   avgpool å: {x.shape}")

        x = torch.flatten(x, 1)
        print(f"   flatten å: {x.shape}")

        x = model.fc(x)
        print(f"   fc å(è¾“å‡º): {x.shape}")


def demo_modify_model_for_transfer_learning():
    """æ¼”ç¤ºå¦‚ä½•ä¿®æ”¹æ¨¡å‹ç”¨äºè¿ç§»å­¦ä¹ """
    print("\n" + "=" * 70)
    print("è¿ç§»å­¦ä¹  - ä¿®æ”¹æ¨¡å‹ç”¨äºè‡ªå®šä¹‰ä»»åŠ¡")
    print("=" * 70)

    # åœºæ™¯: ç”¨ ResNet-18 åš 10 åˆ†ç±»ä»»åŠ¡ (å¦‚CIFAR-10)
    print("\nğŸ¯ ä»»åŠ¡: å°† ImageNet(1000ç±») æ¨¡å‹æ”¹ä¸º CIFAR-10(10ç±») æ¨¡å‹")

    # 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    model = models.resnet18(weights='DEFAULT')
    print("\n1ï¸âƒ£ åŸå§‹æ¨¡å‹çš„æœ€åä¸€å±‚:")
    print(f"   {model.fc}")
    print(f"   è¾“å‡ºç»´åº¦: 1000 (ImageNetç±»åˆ«æ•°)")

    # 2. æ–¹æ³•ä¸€: ç›´æ¥æ›¿æ¢æœ€åä¸€å±‚
    print("\n2ï¸âƒ£ æ–¹æ³•ä¸€: åªæ›¿æ¢æœ€åä¸€å±‚ (ç‰¹å¾æå–)")
    num_classes = 10

    # å†»ç»“æ‰€æœ‰å±‚
    for param in model.parameters():
        param.requires_grad = False

    # æ›¿æ¢æœ€åçš„å…¨è¿æ¥å±‚
    num_features = model.fc.in_features
    model.fc = nn.Linear(num_features, num_classes)

    print(f"   æ–°çš„fcå±‚: {model.fc}")
    print(f"   è¾“å‡ºç»´åº¦: {num_classes}")

    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total = sum(p.numel() for p in model.parameters())
    print(f"   å¯è®­ç»ƒå‚æ•°: {trainable:,} / {total:,} ({trainable/total*100:.2f}%)")

    # 3. æ–¹æ³•äºŒ: å¾®è°ƒæ•´ä¸ªæ¨¡å‹
    print("\n3ï¸âƒ£ æ–¹æ³•äºŒ: å¾®è°ƒæ•´ä¸ªæ¨¡å‹ (Fine-tuning)")
    model2 = models.resnet18(weights='DEFAULT')
    model2.fc = nn.Linear(model2.fc.in_features, num_classes)

    # ä¸å†»ç»“ä»»ä½•å±‚,ä½†å¯ä»¥å¯¹ä¸åŒå±‚ä½¿ç”¨ä¸åŒå­¦ä¹ ç‡
    trainable2 = sum(p.numel() for p in model2.parameters() if p.requires_grad)
    total2 = sum(p.numel() for p in model2.parameters())
    print(f"   å¯è®­ç»ƒå‚æ•°: {trainable2:,} / {total2:,} ({trainable2/total2*100:.2f}%)")

    # 4. æ–¹æ³•ä¸‰: æ·»åŠ è‡ªå®šä¹‰åˆ†ç±»å™¨
    print("\n4ï¸âƒ£ æ–¹æ³•ä¸‰: æ·»åŠ è‡ªå®šä¹‰åˆ†ç±»å™¨å±‚")
    model3 = models.resnet18(weights='DEFAULT')

    # å†»ç»“ç‰¹å¾æå–å±‚
    for param in model3.parameters():
        param.requires_grad = False

    # æ·»åŠ è‡ªå®šä¹‰åˆ†ç±»å™¨
    model3.fc = nn.Sequential(
        nn.Linear(model3.fc.in_features, 256),
        nn.ReLU(),
        nn.Dropout(0.5),
        nn.Linear(256, num_classes)
    )

    print(f"   æ–°çš„åˆ†ç±»å™¨:")
    print(f"   {model3.fc}")

    trainable3 = sum(p.numel() for p in model3.parameters() if p.requires_grad)
    total3 = sum(p.numel() for p in model3.parameters())
    print(f"   å¯è®­ç»ƒå‚æ•°: {trainable3:,} / {total3:,} ({trainable3/total3*100:.2f}%)")

    return model, model2, model3


def demo_feature_extraction():
    """æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æå–ç‰¹å¾"""
    print("\n" + "=" * 70)
    print("ç‰¹å¾æå– - ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ä½œä¸ºç‰¹å¾æå–å™¨")
    print("=" * 70)

    # åŠ è½½æ¨¡å‹
    model = models.resnet18(weights='DEFAULT')

    # æ–¹æ³•1: ç§»é™¤æœ€åçš„åˆ†ç±»å±‚
    print("\n1ï¸âƒ£ æ–¹æ³•ä¸€: ç§»é™¤æœ€åçš„å…¨è¿æ¥å±‚")
    feature_extractor = nn.Sequential(*list(model.children())[:-1])

    print("   ç‰¹å¾æå–å™¨ç»“æ„:")
    print(f"   {feature_extractor}")

    # æµ‹è¯•
    dummy_input = torch.randn(4, 3, 224, 224) # éšæœºç”Ÿæˆçš„ 4 å¼  224x224  RGB å›¾åƒ
    with torch.no_grad():
        features = feature_extractor(dummy_input)

    print(f"\n   è¾“å…¥å½¢çŠ¶: {dummy_input.shape}")
    print(f"   è¾“å‡ºç‰¹å¾å½¢çŠ¶: {features.shape}")
    print(f"   ç‰¹å¾å‘é‡ç»´åº¦: {features.shape[1]}")

    # æ–¹æ³•2: ä½¿ç”¨ hook æå–ä¸­é—´å±‚ç‰¹å¾
    print("\n2ï¸âƒ£ æ–¹æ³•äºŒ: ä½¿ç”¨ Hook æå–ä¸­é—´å±‚ç‰¹å¾")

    activation = {}
    def get_activation(name):
        def hook(model, input, output):
            activation[name] = output.detach()
        return hook

    # æ³¨å†Œ hook
    model.layer4.register_forward_hook(get_activation('layer4')) # layer4: æœ€åä¸€ä¸ªå·ç§¯å±‚, è¾“å‡º: 512é€šé“
    model.avgpool.register_forward_hook(get_activation('avgpool')) # avgpool: å…¨å±€å¹³å‡æ± åŒ–å±‚, è¾“å‡º: 512é€šé“

    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        _ = model(dummy_input)# å‰å‘ä¼ æ’­, æå–ç‰¹å¾

    print(f"   layer4 è¾“å‡ºå½¢çŠ¶: {activation['layer4'].shape}")
    print(f"   avgpool è¾“å‡ºå½¢çŠ¶: {activation['avgpool'].shape}")

    return feature_extractor


def demo_different_models_comparison():
    """æ¼”ç¤ºä¸åŒæ¨¡å‹çš„å¯¹æ¯”"""
    print("\n" + "=" * 70)
    print("ä¸åŒæ¨¡å‹æ¶æ„å¯¹æ¯”")
    print("=" * 70)

    models_to_compare = {
        "ResNet-18": models.resnet18(weights='DEFAULT'),
        "MobileNetV2": models.mobilenet_v2(weights='DEFAULT'),
        "EfficientNet-B0": models.efficientnet_b0(weights='DEFAULT'),
    }

    print("\n" + "-" * 70)
    print(f"{'æ¨¡å‹':<20} {'å‚æ•°é‡':<15} {'æ¨¡å‹å¤§å°':<15} {'è¾“å…¥å°ºå¯¸':<15}")
    print("-" * 70)

    dummy_input = torch.randn(1, 3, 224, 224)

    for name, model in models_to_compare.items():
        model.eval()

        # è®¡ç®—å‚æ•°é‡
        params = sum(p.numel() for p in model.parameters())
        size_mb = params * 4 / 1024 / 1024

        # æµ‹è¯•æ¨ç†é€Ÿåº¦
        import time
        with torch.no_grad():
            start = time.time()
            _ = model(dummy_input)
            inference_time = (time.time() - start) * 1000

        print(f"{name:<20} {params:>12,}   {size_mb:>10.2f} MB   224x224")

    print("-" * 70)


def demo_training_setup():
    """æ¼”ç¤ºå¦‚ä½•è®¾ç½®è®­ç»ƒå¾ªç¯"""
    print("\n" + "=" * 70)
    print("è®­ç»ƒé…ç½®ç¤ºä¾‹")
    print("=" * 70)

    # åŠ è½½æ¨¡å‹å¹¶ä¿®æ”¹
    model = models.resnet18(weights='DEFAULT')
    num_classes = 10
    model.fc = nn.Linear(model.fc.in_features, num_classes)

    print("\n1ï¸âƒ£ ç‰¹å¾æå–æ¨¡å¼ (åªè®­ç»ƒæœ€åä¸€å±‚):")
    print("-" * 70)

    # å†»ç»“æ‰€æœ‰å±‚é™¤äº†æœ€åä¸€å±‚
    for name, param in model.named_parameters():
        if 'fc' not in name:
            param.requires_grad = False

    # ä¼˜åŒ–å™¨åªä¼˜åŒ–å¯è®­ç»ƒå‚æ•°
    optimizer1 = torch.optim.Adam(
        filter(lambda p: p.requires_grad, model.parameters()),
        lr=0.001
    )

    print("   optimizer = torch.optim.Adam(")
    print("       filter(lambda p: p.requires_grad, model.parameters()),")
    print("       lr=0.001")
    print("   )")
    print(f"   å¯è®­ç»ƒå‚æ•°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")

    print("\n2ï¸âƒ£ å¾®è°ƒæ¨¡å¼ (æ‰€æœ‰å±‚éƒ½è®­ç»ƒ,ä½¿ç”¨ä¸åŒå­¦ä¹ ç‡):")
    print("-" * 70)

    # è§£å†»æ‰€æœ‰å±‚
    for param in model.parameters():
        param.requires_grad = True

    # ä¸ºä¸åŒå±‚è®¾ç½®ä¸åŒå­¦ä¹ ç‡
    optimizer2 = torch.optim.SGD([
        {'params': model.conv1.parameters(), 'lr': 0.0001},
        {'params': model.layer1.parameters(), 'lr': 0.0001},
        {'params': model.layer2.parameters(), 'lr': 0.0005},
        {'params': model.layer3.parameters(), 'lr': 0.0005},
        {'params': model.layer4.parameters(), 'lr': 0.001},
        {'params': model.fc.parameters(), 'lr': 0.01}
    ], momentum=0.9)

    print("   optimizer = torch.optim.SGD([")
    print("       {'params': model.conv1.parameters(), 'lr': 0.0001},")
    print("       {'params': model.layer1.parameters(), 'lr': 0.0001},")
    print("       ...")
    print("       {'params': model.fc.parameters(), 'lr': 0.01}")
    print("   ], momentum=0.9)")
    print(f"   å¯è®­ç»ƒå‚æ•°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")

    print("\n3ï¸âƒ£ å®Œæ•´è®­ç»ƒå¾ªç¯ç¤ºä¾‹:")
    print("-" * 70)
    print("""
    model.train()
    for epoch in range(num_epochs):
        for batch_X, batch_y in train_loader:
            # å‰å‘ä¼ æ’­
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        # æ¯ä¸ªepochåéªŒè¯
        model.eval()
        with torch.no_grad():
            val_loss = evaluate(model, val_loader)
        model.train()
    """)


def demo_practical_usage():
    """æ¼”ç¤ºå®é™…ä½¿ç”¨åœºæ™¯"""
    print("\n" + "=" * 70)
    print("å®é™…åº”ç”¨åœºæ™¯ç¤ºä¾‹")
    print("=" * 70)

    print("\nğŸ“± åœºæ™¯1: ç§»åŠ¨ç«¯éƒ¨ç½² - ä½¿ç”¨è½»é‡çº§æ¨¡å‹")
    print("-" * 70)
    print("   model = models.mobilenet_v2(weights='DEFAULT')")
    print("   # MobileNetV2: 3.5Må‚æ•°, é€‚åˆç§»åŠ¨ç«¯")

    print("\nğŸ¯ åœºæ™¯2: é«˜ç²¾åº¦ä»»åŠ¡ - ä½¿ç”¨å¤§å‹æ¨¡å‹")
    print("-" * 70)
    print("   model = models.resnet152(weights='DEFAULT')")
    print("   # ResNet-152: 60Må‚æ•°, æ›´é«˜ç²¾åº¦")

    print("\nâš¡ åœºæ™¯3: å®æ—¶æ¨ç† - ä½¿ç”¨é«˜æ•ˆæ¨¡å‹")
    print("-" * 70)
    print("   model = models.efficientnet_b0(weights='DEFAULT')")
    print("   # EfficientNet-B0: 5.3Må‚æ•°, æ•ˆç‡ä¸ç²¾åº¦å¹³è¡¡")

    print("\nğŸ”¬ åœºæ™¯4: è¿ç§»å­¦ä¹  - å°æ•°æ®é›†")
    print("-" * 70)
    print("""
    # 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    model = models.resnet18(weights='DEFAULT')

    # 2. å†»ç»“ç‰¹å¾æå–å±‚
    for param in model.parameters():
        param.requires_grad = False

    # 3. æ›¿æ¢åˆ†ç±»å™¨
    model.fc = nn.Linear(model.fc.in_features, num_classes)

    # 4. åªè®­ç»ƒåˆ†ç±»å™¨ (æ›´å¿«, é¿å…è¿‡æ‹Ÿåˆ)
    optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)
    """)

    print("\nğŸš€ åœºæ™¯5: ç‰¹å¾æå– - ç”¨äºä¸‹æ¸¸ä»»åŠ¡")
    print("-" * 70)
    print("""
    # 1. ç§»é™¤åˆ†ç±»å±‚,åªä¿ç•™ç‰¹å¾æå–å™¨
    model = models.resnet50(weights='DEFAULT')
    feature_extractor = nn.Sequential(*list(model.children())[:-1])

    # 2. æå–ç‰¹å¾
    features = feature_extractor(images)  # shape: [batch, 2048, 1, 1]
    features = features.flatten(1)        # shape: [batch, 2048]

    # 3. ç”¨æå–çš„ç‰¹å¾è®­ç»ƒç®€å•åˆ†ç±»å™¨ (å¦‚ SVM, KNN)
    """)


def main():
    """ä¸»å‡½æ•° - è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
    print("\n" + "=" * 70)
    print("ğŸ“ torchvision.models å®Œå…¨ä½¿ç”¨æŒ‡å—")
    print("=" * 70)

    # 1. æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
    demo_available_models()

    # 2. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    model = demo_load_pretrained_models()

    # 3. æŸ¥çœ‹æ¨¡å‹ç»“æ„
    demo_model_structure(model)

    # 4. è¿ç§»å­¦ä¹  - ä¿®æ”¹æ¨¡å‹
    model1, model2, model3 = demo_modify_model_for_transfer_learning()

    # 5. ç‰¹å¾æå–
    feature_extractor = demo_feature_extraction()

    # 6. æ¨¡å‹å¯¹æ¯”
    demo_different_models_comparison()

    # 7. è®­ç»ƒé…ç½®
    demo_training_setup()

    # 8. å®é™…åº”ç”¨åœºæ™¯
    demo_practical_usage()

    print("\n" + "=" * 70)
    print("âœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆ!")
    print("=" * 70)
    print("\nğŸ’¡ å…³é”®è¦ç‚¹:")
    print("   1. ä½¿ç”¨ weights='DEFAULT' åŠ è½½æœ€æ–°çš„é¢„è®­ç»ƒæƒé‡")
    print("   2. è¿ç§»å­¦ä¹ æ—¶å†»ç»“ç‰¹å¾æå–å±‚å¯ä»¥åŠ é€Ÿè®­ç»ƒ")
    print("   3. å°æ•°æ®é›†é€‚åˆç‰¹å¾æå–,å¤§æ•°æ®é›†é€‚åˆå¾®è°ƒ")
    print("   4. ä¸åŒå±‚ä½¿ç”¨ä¸åŒå­¦ä¹ ç‡å¯ä»¥æé«˜å¾®è°ƒæ•ˆæœ")
    print("   5. é€‰æ‹©æ¨¡å‹æ—¶è¦æƒè¡¡ç²¾åº¦ã€é€Ÿåº¦å’Œæ¨¡å‹å¤§å°")
    print("=" * 70)


if __name__ == "__main__":
    main()
