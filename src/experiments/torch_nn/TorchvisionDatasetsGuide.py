"""
torchvision.datasets å®Œå…¨ä½¿ç”¨æŒ‡å—

è¿™ä¸ªæ¨¡å—è¯¦ç»†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ torchvision.datasets ä¸‹è½½å’Œä½¿ç”¨å„ç§æ•°æ®é›†ï¼š
1. å¸¸ç”¨æ•°æ®é›†çš„ä¸‹è½½å’ŒåŠ è½½
2. æ•°æ®é¢„å¤„ç†å’Œå¢å¼º (transforms)
3. DataLoader çš„ä½¿ç”¨
4. è‡ªå®šä¹‰æ•°æ®é›†
5. æ•°æ®å¯è§†åŒ–

é‡è¦è¯´æ˜:
- torchvision.datasets å†…ç½®äº†æ•°æ®ä¸‹è½½åŠŸèƒ½,ä¸éœ€è¦ scipy
- scipy æ˜¯ç§‘å­¦è®¡ç®—åº“,ä¸»è¦ç”¨äºæ•°å­¦è¿ç®—,ä¸ç”¨äºä¸‹è½½æ•°æ®é›†
- torchvision.datasets ä¼šè‡ªåŠ¨ä»å®˜æ–¹æºä¸‹è½½æ•°æ®

ä½œè€…: Seeback
æ—¥æœŸ: 2025-10-23
"""

import torch
from torch.utils.data import DataLoader, Dataset, random_split
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import os


def demo_available_datasets():
    """æ¼”ç¤º torchvision.datasets ä¸­å¯ç”¨çš„æ•°æ®é›†"""
    print("=" * 70)
    print("torchvision.datasets ä¸­å¯ç”¨çš„æ•°æ®é›†")
    print("=" * 70)

    dataset_categories = {
        "å›¾åƒåˆ†ç±»æ•°æ®é›†": {
            "MNIST": "æ‰‹å†™æ•°å­— (60Kè®­ç»ƒ + 10Kæµ‹è¯•, 28x28 ç°åº¦)",
            "FashionMNIST": "æ—¶å°šç‰©å“ (60Kè®­ç»ƒ + 10Kæµ‹è¯•, 28x28 ç°åº¦)",
            "CIFAR10": "10ç±»ç‰©ä½“ (50Kè®­ç»ƒ + 10Kæµ‹è¯•, 32x32 å½©è‰²)",
            "CIFAR100": "100ç±»ç‰©ä½“ (50Kè®­ç»ƒ + 10Kæµ‹è¯•, 32x32 å½©è‰²)",
            "ImageNet": "1000ç±»ç‰©ä½“ (éœ€æ‰‹åŠ¨ä¸‹è½½, éœ€è¦æ³¨å†Œ)",
            "STL10": "10ç±»ç‰©ä½“ (5Kè®­ç»ƒ + 8Kæµ‹è¯•, 96x96 å½©è‰²)",
        },
        "ç›®æ ‡æ£€æµ‹æ•°æ®é›†": {
            "VOCDetection": "PASCAL VOC ç›®æ ‡æ£€æµ‹",
            "VOCSegmentation": "PASCAL VOC è¯­ä¹‰åˆ†å‰²",
            "CocoDetection": "COCO ç›®æ ‡æ£€æµ‹ (éœ€æ‰‹åŠ¨ä¸‹è½½)",
        },
        "å…¶ä»–æ•°æ®é›†": {
            "SVHN": "è¡—æ™¯é—¨ç‰Œå· (73Kè®­ç»ƒ + 26Kæµ‹è¯•)",
            "EMNIST": "æ‰©å±•çš„ MNIST æ•°æ®é›†",
            "KMNIST": "æ—¥æ–‡å¹³å‡åæ‰‹å†™å­—ç¬¦",
            "Omniglot": "å¤šè¯­è¨€æ‰‹å†™å­—ç¬¦",
        }
    }

    for category, datasets_dict in dataset_categories.items():
        print(f"\nğŸ“¦ {category}:")
        print("-" * 70)
        for name, description in datasets_dict.items():
            print(f"   {name:<20} - {description}")

    print("\n" + "=" * 70)
    print("ğŸ’¡ æç¤º: å¤§å¤šæ•°æ•°æ®é›†éƒ½æ”¯æŒè‡ªåŠ¨ä¸‹è½½ (download=True)")
    print("=" * 70)


def demo_download_and_load_datasets():
    """æ¼”ç¤ºä¸‹è½½å’ŒåŠ è½½æ•°æ®é›†"""
    print("\n" + "=" * 70)
    print("ä¸‹è½½å’ŒåŠ è½½æ•°æ®é›†")
    print("=" * 70)

    print("\n1ï¸âƒ£ åŸºæœ¬ç”¨æ³• - ä¸‹è½½ MNIST æ•°æ®é›†:")
    print("-" * 70)
    print("""
    from torchvision import datasets

    # ä¸‹è½½è®­ç»ƒé›†
    train_dataset = datasets.MNIST(
        root='./data',          # æ•°æ®ä¿å­˜è·¯å¾„
        train=True,             # åŠ è½½è®­ç»ƒé›†
        download=True,          # å¦‚æœä¸å­˜åœ¨åˆ™ä¸‹è½½
        transform=None          # æ•°æ®é¢„å¤„ç† (å¯é€‰)
    )

    # ä¸‹è½½æµ‹è¯•é›†
    test_dataset = datasets.MNIST(
        root='./data',
        train=False,            # åŠ è½½æµ‹è¯•é›†
        download=True
    )
    """)

    print("\n2ï¸âƒ£ å®é™…åŠ è½½ MNIST æ•°æ®é›†:")
    print("-" * 70)

    # å®é™…åŠ è½½ (åªåŠ è½½ä¸€å°éƒ¨åˆ†æ¼”ç¤º)
    try:
        train_dataset = datasets.MNIST( # åŠ è½½ MNIST è®­ç»ƒé›†, å¹¶å°†å›¾åƒè½¬æ¢ä¸º Tensor
            root='./data',
            train=True,
            download=True,
            transform=transforms.ToTensor()
        )

        print(f"âœ… MNIST è®­ç»ƒé›†åŠ è½½æˆåŠŸ!")
        print(f"   æ ·æœ¬æ•°é‡: {len(train_dataset)}")
        print(f"   å›¾åƒå½¢çŠ¶: {train_dataset[0][0].shape}")
        print(f"   æ ‡ç­¾èŒƒå›´: 0-9 (10ä¸ªç±»åˆ«)")

        # æŸ¥çœ‹ç¬¬ä¸€ä¸ªæ ·æœ¬
        image, label = train_dataset[0]
        print(f"\n   ç¬¬ä¸€ä¸ªæ ·æœ¬:")
        print(f"   - å›¾åƒå½¢çŠ¶: {image.shape}")
        print(f"   - æ ‡ç­¾: {label}")
        print(f"   - åƒç´ å€¼èŒƒå›´: [{image.min():.3f}, {image.max():.3f}]")

    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")

    print("\n3ï¸âƒ£ åŠ è½½ CIFAR-10 æ•°æ®é›†:")
    print("-" * 70)

    try:
        cifar10_train = datasets.CIFAR10(
            root='./data',
            train=True,
            download=True,
            transform=transforms.ToTensor()
        )

        print(f"âœ… CIFAR-10 è®­ç»ƒé›†åŠ è½½æˆåŠŸ!")
        print(f"   æ ·æœ¬æ•°é‡: {len(cifar10_train)}")
        print(f"   å›¾åƒå½¢çŠ¶: {cifar10_train[0][0].shape}")
        print(f"   ç±»åˆ«: {cifar10_train.classes}")

    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")


def demo_transforms():
    """æ¼”ç¤ºæ•°æ®é¢„å¤„ç†å’Œå¢å¼º"""
    print("\n" + "=" * 70)
    print("æ•°æ®é¢„å¤„ç†å’Œå¢å¼º (transforms)")
    print("=" * 70)

    print("\n1ï¸âƒ£ åŸºæœ¬è½¬æ¢:")
    print("-" * 70)
    print("""
    from torchvision import transforms

    # è½¬æ¢ä¸º Tensor
    transform = transforms.ToTensor()

    # å½’ä¸€åŒ– (mean, std)
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))  # ç°åº¦å›¾
    ])

    # RGB å›¾åƒå½’ä¸€åŒ–
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.485, 0.456, 0.406),  # ImageNet mean
                            (0.229, 0.224, 0.225))   # ImageNet std
    ])
    """)

    print("\n2ï¸âƒ£ æ•°æ®å¢å¼º (Data Augmentation):")
    print("-" * 70)
    print("""
    # è®­ç»ƒé›†å¢å¼º
    train_transform = transforms.Compose([
        transforms.RandomHorizontalFlip(p=0.5),    # éšæœºæ°´å¹³ç¿»è½¬
        transforms.RandomRotation(10),              # éšæœºæ—‹è½¬ Â±10åº¦
        transforms.RandomCrop(32, padding=4),       # éšæœºè£å‰ª
        transforms.ColorJitter(                     # é¢œè‰²æŠ–åŠ¨
            brightness=0.2,
            contrast=0.2,
            saturation=0.2
        ),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    # æµ‹è¯•é›†ä¸éœ€è¦å¢å¼º
    test_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    """)

    print("\n3ï¸âƒ£ å®é™…åº”ç”¨ transforms:")
    print("-" * 70)

    # å®šä¹‰ transforms
    train_transform = transforms.Compose([
        transforms.RandomHorizontalFlip(),
        transforms.RandomCrop(32, padding=4),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    test_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    # åŠ è½½æ•°æ®é›†
    train_dataset = datasets.CIFAR10(
        root='./data',
        train=True,
        download=True,
        transform=train_transform  # åº”ç”¨è®­ç»ƒé›†å¢å¼º
    )

    test_dataset = datasets.CIFAR10(
        root='./data',
        train=False,
        download=True,
        transform=test_transform  # åº”ç”¨æµ‹è¯•é›†è½¬æ¢
    )

    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ!")
    print(f"   è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬ (å¸¦å¢å¼º)")
    print(f"   æµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬ (æ— å¢å¼º)")

    return train_dataset, test_dataset


def demo_dataloader():
    """æ¼”ç¤º DataLoader çš„ä½¿ç”¨"""
    print("\n" + "=" * 70)
    print("DataLoader - æ‰¹é‡æ•°æ®åŠ è½½")
    print("=" * 70)

    print("\n1ï¸âƒ£ DataLoader åŸºæœ¬ç”¨æ³•:")
    print("-" * 70)
    print("""
    from torch.utils.data import DataLoader

    train_loader = DataLoader(
        dataset=train_dataset,
        batch_size=32,          # æ‰¹æ¬¡å¤§å°
        shuffle=True,           # æ‰“ä¹±æ•°æ®
        num_workers=2,          # å¹¶è¡ŒåŠ è½½è¿›ç¨‹æ•°
        pin_memory=True         # å›ºå®šå†…å­˜ (GPUè®­ç»ƒæ—¶åŠ é€Ÿ)
    )

    # è¿­ä»£æ•°æ®
    for batch_idx, (images, labels) in enumerate(train_loader):
        # images: [batch_size, channels, height, width]
        # labels: [batch_size]
        print(f"Batch {batch_idx}: {images.shape}, {labels.shape}")
    """)

    print("\n2ï¸âƒ£ å®é™…åˆ›å»º DataLoader:")
    print("-" * 70)

    # åŠ è½½æ•°æ®é›†
    train_dataset = datasets.CIFAR10(
        root='./data',
        train=True,
        download=True,
        transform=transforms.ToTensor()
    )

    # åˆ›å»º DataLoader
    train_loader = DataLoader(
        dataset=train_dataset,
        batch_size=32,
        shuffle=True,
        num_workers=0  # è®¾ç½®ä¸º 0 é¿å…å¤šè¿›ç¨‹é—®é¢˜
    )

    print(f"âœ… DataLoader åˆ›å»ºæˆåŠŸ!")
    print(f"   æ€»æ ·æœ¬æ•°: {len(train_dataset)}")
    print(f"   æ‰¹æ¬¡å¤§å°: {train_loader.batch_size}")
    print(f"   æ€»æ‰¹æ¬¡æ•°: {len(train_loader)}")

    # è·å–ä¸€ä¸ªæ‰¹æ¬¡
    images, labels = next(iter(train_loader))
    print(f"\n   å•ä¸ªæ‰¹æ¬¡:")
    print(f"   - å›¾åƒå½¢çŠ¶: {images.shape}")
    print(f"   - æ ‡ç­¾å½¢çŠ¶: {labels.shape}")
    print(f"   - æ ‡ç­¾å†…å®¹: {labels[:10].tolist()}")

    print("\n3ï¸âƒ£ ä¸åŒé…ç½®çš„ DataLoader:")
    print("-" * 70)

    configs = [
        {"batch_size": 16, "shuffle": True, "name": "å°æ‰¹æ¬¡ + æ‰“ä¹±"},
        {"batch_size": 128, "shuffle": True, "name": "å¤§æ‰¹æ¬¡ + æ‰“ä¹±"},
        {"batch_size": 32, "shuffle": False, "name": "ä¸­æ‰¹æ¬¡ + ä¸æ‰“ä¹±"},
    ]

    for config in configs:
        loader = DataLoader(
            train_dataset,
            batch_size=config["batch_size"],
            shuffle=config["shuffle"],
            num_workers=0
        )
        print(f"   {config['name']:<20} - æ‰¹æ¬¡æ•°: {len(loader)}")

    return train_loader


def demo_dataset_split():
    """æ¼”ç¤ºæ•°æ®é›†åˆ’åˆ†"""
    print("\n" + "=" * 70)
    print("æ•°æ®é›†åˆ’åˆ† - è®­ç»ƒé›† / éªŒè¯é›† / æµ‹è¯•é›†")
    print("=" * 70)

    print("\n1ï¸âƒ£ åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†:")
    print("-" * 70)
    print("""
    from torch.utils.data import random_split

    # åŠ è½½å®Œæ•´è®­ç»ƒé›†
    full_train = datasets.CIFAR10(root='./data', train=True, ...)

    # åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›† (90% / 10%)
    train_size = int(0.9 * len(full_train))
    val_size = len(full_train) - train_size

    train_dataset, val_dataset = random_split(
        full_train,
        [train_size, val_size]
    )
    """)

    print("\n2ï¸âƒ£ å®é™…åˆ’åˆ†æ•°æ®é›†:")
    print("-" * 70)

    # åŠ è½½æ•°æ®
    full_train = datasets.CIFAR10(
        root='./data',
        train=True,
        download=True,
        transform=transforms.ToTensor()
    )

    # åˆ’åˆ†
    train_size = int(0.9 * len(full_train))
    val_size = len(full_train) - train_size

    train_dataset, val_dataset = random_split(full_train, [train_size, val_size])# random_split: éšæœºåˆ’åˆ†æ•°æ®é›†

    print(f"âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆ!")
    print(f"   åŸå§‹è®­ç»ƒé›†: {len(full_train)} æ ·æœ¬")
    print(f"   æ–°è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬ (90%)")
    print(f"   éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬ (10%)")

    # åˆ›å»ºå¯¹åº”çš„ DataLoader
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

    print(f"\n   è®­ç»ƒ DataLoader: {len(train_loader)} æ‰¹æ¬¡")
    print(f"   éªŒè¯ DataLoader: {len(val_loader)} æ‰¹æ¬¡")

    return train_loader, val_loader


def demo_custom_dataset():
    """æ¼”ç¤ºè‡ªå®šä¹‰æ•°æ®é›†"""
    print("\n" + "=" * 70)
    print("è‡ªå®šä¹‰æ•°æ®é›† - ç»§æ‰¿ Dataset ç±»")
    print("=" * 70)

    print("\n1ï¸âƒ£ è‡ªå®šä¹‰æ•°æ®é›†çš„åŸºæœ¬ç»“æ„:")
    print("-" * 70)
    print("""
    from torch.utils.data import Dataset

    class CustomDataset(Dataset):
        def __init__(self, data, labels, transform=None):
            '''
            åˆå§‹åŒ–æ•°æ®é›†
            '''
            self.data = data
            self.labels = labels
            self.transform = transform

        def __len__(self):
            '''
            è¿”å›æ•°æ®é›†å¤§å°
            '''
            return len(self.data)

        def __getitem__(self, idx):
            '''
            æ ¹æ®ç´¢å¼•è¿”å›ä¸€ä¸ªæ ·æœ¬
            '''
            image = self.data[idx]
            label = self.labels[idx]

            if self.transform:
                image = self.transform(image)

            return image, label
    """)

    print("\n2ï¸âƒ£ å®é™…åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†:")
    print("-" * 70)

    class SimpleDataset(Dataset):
        """ç®€å•çš„éšæœºæ•°æ®é›†"""
        def __init__(self, num_samples, image_size, num_classes):
            self.num_samples = num_samples
            self.image_size = image_size
            self.num_classes = num_classes

            # ç”Ÿæˆéšæœºæ•°æ®
            self.data = torch.randn(num_samples, 3, image_size, image_size)
            self.labels = torch.randint(0, num_classes, (num_samples,))

        def __len__(self):
            return self.num_samples

        def __getitem__(self, idx):
            return self.data[idx], self.labels[idx]

    # åˆ›å»ºæ•°æ®é›†
    custom_dataset = SimpleDataset(num_samples=1000, image_size=32, num_classes=10)

    print(f"âœ… è‡ªå®šä¹‰æ•°æ®é›†åˆ›å»ºæˆåŠŸ!")
    print(f"   æ ·æœ¬æ•°é‡: {len(custom_dataset)}")
    print(f"   å›¾åƒå½¢çŠ¶: {custom_dataset[0][0].shape}")
    print(f"   æ ‡ç­¾èŒƒå›´: 0-{custom_dataset.num_classes-1}")

    # åˆ›å»º DataLoader
    custom_loader = DataLoader(custom_dataset, batch_size=32, shuffle=True)
    print(f"   æ‰¹æ¬¡æ•°: {len(custom_loader)}")

    return custom_dataset


def demo_visualization():
    """æ¼”ç¤ºæ•°æ®å¯è§†åŒ–"""
    print("\n" + "=" * 70)
    print("æ•°æ®å¯è§†åŒ–")
    print("=" * 70)

    # åŠ è½½æ•°æ®
    train_dataset = datasets.CIFAR10(
        root='./data',
        train=True,
        download=True,
        transform=transforms.ToTensor()
    )

    print(f"\næ­£åœ¨å¯è§†åŒ– CIFAR-10 æ•°æ®é›†...")
    print(f"ç±»åˆ«: {train_dataset.classes}")

    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(2, 5, figsize=(15, 6))
    fig.suptitle('CIFAR-10 æ ·æœ¬å±•ç¤º', fontsize=16, fontweight='bold')

    for i, ax in enumerate(axes.flat):
        # è·å–æ ·æœ¬
        image, label = train_dataset[i]

        # è½¬æ¢ä¸º numpy å¹¶è°ƒæ•´é€šé“é¡ºåº
        image_np = image.permute(1, 2, 0).numpy()

        # æ˜¾ç¤ºå›¾åƒ
        ax.imshow(image_np)
        ax.set_title(f'ç±»åˆ«: {train_dataset.classes[label]}', fontsize=10)
        ax.axis('off')

    plt.tight_layout()

    # ä¿å­˜å›¾åƒ
    output_path = 'artifacts/cifar10_samples.png'
    os.makedirs('artifacts', exist_ok=True)
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"\nâœ… å¯è§†åŒ–å®Œæˆ! ä¿å­˜åˆ°: {output_path}")

    plt.close()


def demo_batch_visualization():
    """æ¼”ç¤ºæ‰¹æ¬¡æ•°æ®å¯è§†åŒ–"""
    print("\n" + "=" * 70)
    print("æ‰¹æ¬¡æ•°æ®å¯è§†åŒ–")
    print("=" * 70)

    # åŠ è½½æ•°æ®
    train_dataset = datasets.CIFAR10(
        root='./data',
        train=True,
        download=True,
        transform=transforms.ToTensor()
    )

    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)

    # è·å–ä¸€ä¸ªæ‰¹æ¬¡
    images, labels = next(iter(train_loader))

    print(f"\næ‰¹æ¬¡ä¿¡æ¯:")
    print(f"   å›¾åƒå½¢çŠ¶: {images.shape}")
    print(f"   æ ‡ç­¾å½¢çŠ¶: {labels.shape}")
    print(f"   æ ‡ç­¾: {labels.tolist()}")

    # å¯è§†åŒ–æ‰¹æ¬¡
    fig, axes = plt.subplots(4, 4, figsize=(12, 12)) #subplots: åˆ›å»ºä¸€ä¸ª 4x4 çš„å­å›¾ç½‘æ ¼
    fig.suptitle('ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ® (batch_size=16)', fontsize=16, fontweight='bold')

    for i, ax in enumerate(axes.flat): #enumerate : éå†å­å›¾ç½‘æ ¼çš„æ¯ä¸ªå­å›¾
        # è½¬æ¢å›¾åƒ
        image_np = images[i].permute(1, 2, 0).numpy() #permute: æ”¹å˜å¼ é‡çš„ç»´åº¦é¡ºåº, ä» (C, H, W) è½¬æ¢ä¸º (H, W, C)

        # æ˜¾ç¤º
        ax.imshow(image_np) #imshow: æ˜¾ç¤ºå›¾åƒ
        ax.set_title(f'{train_dataset.classes[labels[i]]}', fontsize=10)#set_title: è®¾ç½®å­å›¾çš„æ ‡é¢˜
        ax.axis('off')

    plt.tight_layout()

    # ä¿å­˜
    output_path = 'artifacts/cifar10_batch.png'
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"\nâœ… æ‰¹æ¬¡å¯è§†åŒ–å®Œæˆ! ä¿å­˜åˆ°: {output_path}")

    plt.close()


def demo_scipy_vs_torchvision():
    """æ¼”ç¤º scipy å’Œ torchvision çš„åŒºåˆ«"""
    print("\n" + "=" * 70)
    print("â“ scipy vs torchvision - æ¾„æ¸…å¸¸è§è¯¯è§£")
    print("=" * 70)

    print("\n1ï¸âƒ£ torchvision.datasets - æ•°æ®é›†ä¸‹è½½å’ŒåŠ è½½å·¥å…·")
    print("-" * 70)
    print("""
    ç”¨é€”: ä¸‹è½½ã€åŠ è½½ã€é¢„å¤„ç†è®¡ç®—æœºè§†è§‰æ•°æ®é›†
    åŠŸèƒ½:
    - è‡ªåŠ¨ä¸‹è½½å¸¸ç”¨æ•°æ®é›† (MNIST, CIFAR-10, ImageNetç­‰)
    - æ•°æ®é¢„å¤„ç†å’Œå¢å¼º (transforms)
    - ä¸ PyTorch DataLoader æ— ç¼é›†æˆ

    ç¤ºä¾‹:
    from torchvision import datasets
    dataset = datasets.CIFAR10(root='./data', download=True)
    """)

    print("\n2ï¸âƒ£ scipy - ç§‘å­¦è®¡ç®—åº“")
    print("-" * 70)
    print("""
    ç”¨é€”: æ•°å­¦è¿ç®—ã€ç§‘å­¦è®¡ç®—ã€ä¿¡å·å¤„ç†
    åŠŸèƒ½:
    - ä¼˜åŒ–ç®—æ³• (scipy.optimize)
    - çº¿æ€§ä»£æ•° (scipy.linalg)
    - ä¿¡å·å¤„ç† (scipy.signal)
    - å›¾åƒå¤„ç† (scipy.ndimage) - åŸºç¡€çš„å›¾åƒæ“ä½œ
    - ç»Ÿè®¡åˆ†æ (scipy.stats)

    ç¤ºä¾‹:
    from scipy import ndimage
    from scipy.optimize import minimize
    """)

    print("\n3ï¸âƒ£ å…³é”®åŒºåˆ«:")
    print("-" * 70)
    print("""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     åŠŸèƒ½         â”‚   torchvision        â”‚      scipy           â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ æ•°æ®é›†ä¸‹è½½       â”‚   âœ… æ”¯æŒ            â”‚   âŒ ä¸æ”¯æŒ          â”‚
    â”‚ æ·±åº¦å­¦ä¹ é›†æˆ     â”‚   âœ… å®Œç¾é›†æˆ        â”‚   âŒ æ— é›†æˆ          â”‚
    â”‚ æ•°æ®å¢å¼º         â”‚   âœ… ä¸°å¯Œ            â”‚   âŒ æ—               â”‚
    â”‚ å›¾åƒå¤„ç†         â”‚   âœ… (transforms)    â”‚   âœ… (ndimage)       â”‚
    â”‚ æ•°å­¦è®¡ç®—         â”‚   âŒ æœ‰é™            â”‚   âœ… å¼ºå¤§            â”‚
    â”‚ ä¼˜åŒ–ç®—æ³•         â”‚   âŒ æ—               â”‚   âœ… ä¸°å¯Œ            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)

    print("\n4ï¸âƒ£ æ­£ç¡®çš„ä½¿ç”¨æ–¹å¼:")
    print("-" * 70)
    print("""
    âœ… æ­£ç¡®: ä½¿ç”¨ torchvision.datasets ä¸‹è½½æ•°æ®é›†
    train_dataset = datasets.CIFAR10(
        root='./data',
        train=True,
        download=True  # è‡ªåŠ¨ä»å®˜æ–¹æºä¸‹è½½
    )

    âŒ é”™è¯¯: è¯•å›¾ç”¨ scipy ä¸‹è½½æ•°æ®é›†
    # scipy æ²¡æœ‰æ•°æ®é›†ä¸‹è½½åŠŸèƒ½!
    """)

    print("\n5ï¸âƒ£ scipy çš„å®é™…ç”¨é€”ç¤ºä¾‹:")
    print("-" * 70)
    print("""
    # å›¾åƒæ»¤æ³¢
    from scipy import ndimage
    smoothed = ndimage.gaussian_filter(image, sigma=2)

    # ä¼˜åŒ–é—®é¢˜
    from scipy.optimize import minimize
    result = minimize(loss_function, initial_params)

    # ç»Ÿè®¡åˆ†æ
    from scipy import stats
    t_stat, p_value = stats.ttest_ind(group1, group2)
    """)


def main():
    """ä¸»å‡½æ•° - è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
    print("\n" + "=" * 70)
    print("ğŸ“ torchvision.datasets å®Œå…¨ä½¿ç”¨æŒ‡å—")
    print("=" * 70)

    # 1. æ˜¾ç¤ºå¯ç”¨æ•°æ®é›†
    demo_available_datasets()

    # 2. ä¸‹è½½å’ŒåŠ è½½æ•°æ®é›†
    demo_download_and_load_datasets()

    # 3. æ•°æ®é¢„å¤„ç†
    train_dataset, test_dataset = demo_transforms()

    # 4. DataLoader ä½¿ç”¨
    train_loader = demo_dataloader()

    # 5. æ•°æ®é›†åˆ’åˆ†
    train_loader, val_loader = demo_dataset_split()

    # 6. è‡ªå®šä¹‰æ•°æ®é›†
    custom_dataset = demo_custom_dataset()

    # 7. æ•°æ®å¯è§†åŒ–
    demo_visualization()

    # 8. æ‰¹æ¬¡å¯è§†åŒ–
    demo_batch_visualization()

    # 9. scipy vs torchvision
    demo_scipy_vs_torchvision()

    print("\n" + "=" * 70)
    print("âœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆ!")
    print("=" * 70)
    print("\nğŸ’¡ å…³é”®è¦ç‚¹:")
    print("   1. âœ… ä½¿ç”¨ torchvision.datasets ä¸‹è½½æ•°æ®é›† (download=True)")
    print("   2. âœ… transforms ç”¨äºæ•°æ®é¢„å¤„ç†å’Œå¢å¼º")
    print("   3. âœ… DataLoader ç”¨äºæ‰¹é‡åŠ è½½å’Œè¿­ä»£æ•°æ®")
    print("   4. âœ… random_split ç”¨äºåˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†")
    print("   5. âŒ scipy ä¸ç”¨äºä¸‹è½½æ•°æ®é›†,å®ƒæ˜¯ç§‘å­¦è®¡ç®—åº“")
    print("   6. âœ… è‡ªå®šä¹‰æ•°æ®é›†éœ€è¦å®ç° __len__ å’Œ __getitem__")
    print("=" * 70)


if __name__ == "__main__":
    main()
