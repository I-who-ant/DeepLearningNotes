"""
ç¤ºä¾‹5: æ•°æ®å¢å¼º (Data Augmentation)

åœ¨ç¤ºä¾‹4çš„åŸºç¡€ä¸Šæ·»åŠ :
- å¸¸ç”¨æ•°æ®å¢å¼ºæŠ€æœ¯ (ç¿»è½¬ã€æ—‹è½¬ã€è£å‰ªã€é¢œè‰²å˜æ¢ç­‰)
- å¯¹æ¯”æœ‰æ— æ•°æ®å¢å¼ºçš„è®­ç»ƒæ•ˆæœ
- å¯è§†åŒ–æ•°æ®å¢å¼ºæ•ˆæœ
- TensorBoard å¯è§†åŒ–å¢å¼ºåçš„å›¾åƒ
- é˜²æ­¢è¿‡æ‹Ÿåˆ

è¿è¡Œ: python src/experiments/model_train/05_data_augmentation.py
æŸ¥çœ‹TensorBoard: tensorboard --logdir=/home/seeback/PycharmProjects/DeepLearning/tensor_board
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torch.utils.tensorboard import SummaryWriter
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
import os


# ============================================================
# 1. å®šä¹‰ç›¸åŒçš„CNNæ¨¡å‹
# ============================================================
class SimpleCNN(nn.Module):
    """ç®€å•çš„3å±‚å·ç§¯ç¥ç»ç½‘ç»œ"""
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(128 * 4 * 4, 256)
        self.fc2 = nn.Linear(256, 10)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.5)  # æ–°å¢: Dropouté˜²æ­¢è¿‡æ‹Ÿåˆ

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = self.pool(self.relu(self.conv3(x)))
        x = x.view(x.size(0), -1)
        x = self.relu(self.fc1(x))
        x = self.dropout(x)  # æ–°å¢: åœ¨FCå±‚ä¹‹é—´åº”ç”¨Dropout
        x = self.fc2(x)
        return x


# ============================================================
# 2. åˆ›å»ºæ•°æ®å¢å¼ºå˜æ¢ - æ–°å¢!
# ============================================================
def get_transforms(use_augmentation=True):
    """
    è·å–æ•°æ®é¢„å¤„ç†å’Œå¢å¼ºçš„transforms

    å‚æ•°:
        use_augmentation: æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼º

    è¿”å›:
        train_transform: è®­ç»ƒé›†transform
        val_transform: éªŒè¯é›†transform
    """
    if use_augmentation:
        # è®­ç»ƒé›†: åº”ç”¨æ•°æ®å¢å¼º
        train_transform = transforms.Compose([
            # 1. éšæœºæ°´å¹³ç¿»è½¬ (50%æ¦‚ç‡)
            transforms.RandomHorizontalFlip(p=0.5),

            # 2. éšæœºè£å‰ªå¹¶è°ƒæ•´å¤§å°
            transforms.RandomCrop(32, padding=4),

            # 3. éšæœºæ—‹è½¬ (Â±15åº¦)
            transforms.RandomRotation(15),

            # 4. é¢œè‰²æŠ–åŠ¨ (éšæœºæ”¹å˜äº®åº¦ã€å¯¹æ¯”åº¦ã€é¥±å’Œåº¦ã€è‰²è°ƒ)
            transforms.ColorJitter(
                brightness=0.2,    # äº®åº¦å˜åŒ–Â±20%
                contrast=0.2,      # å¯¹æ¯”åº¦å˜åŒ–Â±20%
                saturation=0.2,    # é¥±å’Œåº¦å˜åŒ–Â±20%
                hue=0.1            # è‰²è°ƒå˜åŒ–Â±10%
            ),

            # 5. éšæœºæ“¦é™¤ (æ¨¡æ‹Ÿé®æŒ¡)
            transforms.RandomErasing(
                p=0.3,              # 30%æ¦‚ç‡
                scale=(0.02, 0.1),  # æ“¦é™¤åŒºåŸŸå 2%-10%
                ratio=(0.3, 3.3),   # é•¿å®½æ¯”
                value='random'      # éšæœºå¡«å……
            ),

            # 6. è½¬ä¸ºTensor
            transforms.ToTensor(),

            # 7. æ ‡å‡†åŒ–
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])

        print("âœ… å¯ç”¨æ•°æ®å¢å¼º:")
        print("   - éšæœºæ°´å¹³ç¿»è½¬ (50%)")
        print("   - éšæœºè£å‰ª (padding=4)")
        print("   - éšæœºæ—‹è½¬ (Â±15Â°)")
        print("   - é¢œè‰²æŠ–åŠ¨ (äº®åº¦/å¯¹æ¯”åº¦/é¥±å’Œåº¦/è‰²è°ƒ)")
        print("   - éšæœºæ“¦é™¤ (30%æ¦‚ç‡)")

    else:
        # è®­ç»ƒé›†: ä¸ä½¿ç”¨æ•°æ®å¢å¼º
        train_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])

        print("âŒ ä¸ä½¿ç”¨æ•°æ®å¢å¼º")

    # éªŒè¯é›†: å§‹ç»ˆä¸ä½¿ç”¨æ•°æ®å¢å¼º
    val_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    return train_transform, val_transform


# ============================================================
# 3. å‡†å¤‡æ•°æ® - ä¿®æ”¹: æ”¯æŒæ•°æ®å¢å¼º
# ============================================================
def prepare_data(use_augmentation=True, val_ratio=0.2):
    """
    åŠ è½½CIFAR-10æ•°æ®é›†å¹¶åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†

    å‚æ•°:
        use_augmentation: æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼º
        val_ratio: éªŒè¯é›†æ¯”ä¾‹

    è¿”å›:
        train_loader: è®­ç»ƒé›†DataLoader
        val_loader: éªŒè¯é›†DataLoader
    """
    print(f"\næ­£åœ¨åŠ è½½ CIFAR-10 æ•°æ®é›† (æ•°æ®å¢å¼º: {use_augmentation})...")

    # è·å–transforms
    train_transform, val_transform = get_transforms(use_augmentation)

    # åŠ è½½å®Œæ•´çš„è®­ç»ƒé›†
    full_train_dataset = datasets.CIFAR10(
        root='./data',
        train=True,
        download=True,
        transform=None  # å…ˆä¸åº”ç”¨transform
    )

    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    total_size = len(full_train_dataset)
    val_size = int(total_size * val_ratio)
    train_size = total_size - val_size

    train_indices, val_indices = torch.utils.data.random_split(
        range(total_size),
        [train_size, val_size],
        generator=torch.Generator().manual_seed(42)
    )

    # åˆ›å»ºå­æ•°æ®é›†å¹¶åº”ç”¨ä¸åŒçš„transform
    train_dataset = torch.utils.data.Subset(
        datasets.CIFAR10(root='./data', train=True, download=False, transform=train_transform),
        train_indices.indices
    )

    val_dataset = torch.utils.data.Subset(
        datasets.CIFAR10(root='./data', train=True, download=False, transform=val_transform),
        val_indices.indices
    )

    # åˆ›å»ºDataLoader
    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)

    print(f"è®­ç»ƒé›†: {len(train_dataset)} å¼ å›¾ç‰‡")
    print(f"éªŒè¯é›†: {len(val_dataset)} å¼ å›¾ç‰‡")

    return train_loader, val_loader


# ============================================================
# 4. è®­ç»ƒä¸€ä¸ªepoch
# ============================================================
def train_one_epoch(model, train_loader, criterion, optimizer, epoch, writer):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()

    running_loss = 0.0
    total_samples = 0

    for batch_idx, (images, labels) in enumerate(train_loader):
        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)
        total_samples += images.size(0)

        if (batch_idx + 1) % 100 == 0:
            avg_loss = running_loss / total_samples
            print(f"  Batch [{batch_idx+1}/{len(train_loader)}] Loss: {avg_loss:.4f}")

    avg_loss = running_loss / total_samples
    return avg_loss


# ============================================================
# 5. éªŒè¯å‡½æ•°
# ============================================================
def validate(model, val_loader, criterion):
    """åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹"""
    model.eval()

    running_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in val_loader:
            outputs = model(images)
            loss = criterion(outputs, labels)

            running_loss += loss.item() * images.size(0)

            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    avg_loss = running_loss / total
    accuracy = 100 * correct / total

    return avg_loss, accuracy


# ============================================================
# 6. ä¸»è®­ç»ƒå¾ªç¯
# ============================================================
def train(model, train_loader, val_loader, criterion, optimizer, scheduler, experiment_name, num_epochs=20):
    """
    å®Œæ•´çš„è®­ç»ƒ+éªŒè¯å¾ªç¯

    å‚æ•°:
        model: ç¥ç»ç½‘ç»œæ¨¡å‹
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        criterion: æŸå¤±å‡½æ•°
        optimizer: ä¼˜åŒ–å™¨
        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
        experiment_name: å®éªŒåç§°
        num_epochs: è®­ç»ƒè½®æ•°
    """
    print(f"\nå¼€å§‹è®­ç»ƒ ({experiment_name})...")
    print("=" * 70)

    # åˆ›å»ºTensorBoard writer
    log_dir = f'/home/seeback/PycharmProjects/DeepLearning/tensor_board/05_data_augmentation/{experiment_name}'
    os.makedirs(log_dir, exist_ok=True)
    writer = SummaryWriter(log_dir)
    print(f"TensorBoard æ—¥å¿—: {log_dir}")
    print("=" * 70)

    best_val_acc = 0.0
    train_accs = []
    val_accs = []

    for epoch in range(num_epochs):
        print(f"\nEpoch [{epoch+1}/{num_epochs}]")
        print("-" * 70)

        # è®­ç»ƒé˜¶æ®µ
        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, epoch, writer)

        # éªŒè¯é˜¶æ®µ
        val_loss, val_acc = validate(model, val_loader, criterion)

        # è®¡ç®—è®­ç»ƒé›†å‡†ç¡®ç‡ (ç”¨äºæ£€æµ‹è¿‡æ‹Ÿåˆ)
        _, train_acc = validate(model, train_loader, criterion)
        train_accs.append(train_acc)
        val_accs.append(val_acc)

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š Epoch [{epoch+1}/{num_epochs}] æ€»ç»“:")
        print(f"  è®­ç»ƒLoss: {train_loss:.4f} | è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.2f}%")
        print(f"  éªŒè¯Loss: {val_loss:.4f} | éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%")

        # è¿‡æ‹Ÿåˆæ£€æµ‹
        if train_acc - val_acc > 10:
            print(f"  âš ï¸ è­¦å‘Š: å¯èƒ½è¿‡æ‹Ÿåˆ (è®­ç»ƒå‡†ç¡®ç‡æ¯”éªŒè¯å‡†ç¡®ç‡é«˜{train_acc - val_acc:.1f}%)")

        # å†™å…¥TensorBoard
        writer.add_scalar('Loss/Train', train_loss, epoch)
        writer.add_scalar('Loss/Validation', val_loss, epoch)
        writer.add_scalar('Accuracy/Train', train_acc, epoch)
        writer.add_scalar('Accuracy/Validation', val_acc, epoch)
        writer.add_scalar('Accuracy/Gap', train_acc - val_acc, epoch)  # è¿‡æ‹ŸåˆæŒ‡æ ‡

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            print(f"  â­ æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡!")

        scheduler.step()
        print("-" * 70)

    writer.close()
    print(f"\nâœ… è®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")

    return best_val_acc, train_accs, val_accs


# ============================================================
# 7. å¯è§†åŒ–æ•°æ®å¢å¼ºæ•ˆæœ - æ–°å¢!
# ============================================================
def visualize_augmentation():
    """å¯è§†åŒ–æ•°æ®å¢å¼ºçš„æ•ˆæœ"""
    print("\n" + "=" * 70)
    print("å¯è§†åŒ–æ•°æ®å¢å¼ºæ•ˆæœ")
    print("=" * 70)

    # åŠ è½½ä¸€å¼ åŸå§‹å›¾ç‰‡
    dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=None)
    image, label = dataset[0]
    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                   'dog', 'frog', 'horse', 'ship', 'truck']

    # åˆ›å»ºæ•°æ®å¢å¼ºtransform
    augmentation = transforms.Compose([
        transforms.RandomHorizontalFlip(p=1.0),
        transforms.RandomRotation(15),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
        transforms.ToTensor(),
    ])

    # ç”Ÿæˆ8ä¸ªå¢å¼ºç‰ˆæœ¬
    fig, axes = plt.subplots(3, 3, figsize=(12, 12))
    fig.suptitle(f'æ•°æ®å¢å¼ºæ•ˆæœå±•ç¤º - åŸå§‹ç±»åˆ«: {class_names[label]}',
                 fontsize=16, fontweight='bold')

    # ç¬¬ä¸€ä¸ªæ˜¾ç¤ºåŸå›¾
    axes[0, 0].imshow(image)
    axes[0, 0].set_title('åŸå§‹å›¾åƒ', fontsize=12)
    axes[0, 0].axis('off')

    # å…¶ä»–8ä¸ªæ˜¾ç¤ºå¢å¼ºåçš„å›¾åƒ
    for i in range(1, 9):
        row = i // 3
        col = i % 3

        # åº”ç”¨æ•°æ®å¢å¼º
        aug_image = augmentation(image)

        # è½¬æ¢ä¸ºnumpyç”¨äºæ˜¾ç¤º
        aug_image_np = aug_image.permute(1, 2, 0).numpy()
        aug_image_np = np.clip(aug_image_np, 0, 1)

        axes[row, col].imshow(aug_image_np)
        axes[row, col].set_title(f'å¢å¼ºç‰ˆæœ¬ {i}', fontsize=12)
        axes[row, col].axis('off')

    plt.tight_layout()

    # ä¿å­˜å›¾ç‰‡
    output_path = 'artifacts/data_augmentation_demo.png'
    os.makedirs('artifacts', exist_ok=True)
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"\nâœ… æ•°æ®å¢å¼ºå¯è§†åŒ–ä¿å­˜åˆ°: {output_path}")

    plt.close()


# ============================================================
# 8. å¯¹æ¯”æœ‰æ— æ•°æ®å¢å¼º - æ–°å¢!
# ============================================================
def compare_augmentation():
    """å¯¹æ¯”æœ‰æ— æ•°æ®å¢å¼ºçš„è®­ç»ƒæ•ˆæœ"""
    print("\n" + "=" * 70)
    print("å¯¹æ¯”å®éªŒ: æœ‰æ— æ•°æ®å¢å¼º")
    print("=" * 70)

    # æŸå¤±å‡½æ•°
    criterion = nn.CrossEntropyLoss()

    results = {}

    # å®éªŒ1: ä¸ä½¿ç”¨æ•°æ®å¢å¼º
    print("\n" + "="*70)
    print("å®éªŒ1: ä¸ä½¿ç”¨æ•°æ®å¢å¼º")
    print("="*70)

    train_loader, val_loader = prepare_data(use_augmentation=False)
    model1 = SimpleCNN()
    torch.manual_seed(42)

    optimizer1 = optim.SGD(model1.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)
    scheduler1 = optim.lr_scheduler.CosineAnnealingLR(optimizer1, T_max=20)

    best_acc1, train_accs1, val_accs1 = train(
        model1, train_loader, val_loader,
        criterion, optimizer1, scheduler1,
        experiment_name='without_augmentation',
        num_epochs=20
    )
    results['ä¸ä½¿ç”¨å¢å¼º'] = best_acc1

    # å®éªŒ2: ä½¿ç”¨æ•°æ®å¢å¼º
    print("\n" + "="*70)
    print("å®éªŒ2: ä½¿ç”¨æ•°æ®å¢å¼º")
    print("="*70)

    train_loader, val_loader = prepare_data(use_augmentation=True)
    model2 = SimpleCNN()
    torch.manual_seed(42)

    optimizer2 = optim.SGD(model2.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)
    scheduler2 = optim.lr_scheduler.CosineAnnealingLR(optimizer2, T_max=20)

    best_acc2, train_accs2, val_accs2 = train(
        model2, train_loader, val_loader,
        criterion, optimizer2, scheduler2,
        experiment_name='with_augmentation',
        num_epochs=20
    )
    results['ä½¿ç”¨å¢å¼º'] = best_acc2

    # æ‰“å°å¯¹æ¯”ç»“æœ
    print("\n" + "=" * 70)
    print("ğŸ“Š å¯¹æ¯”ç»“æœ")
    print("=" * 70)
    print(f"\n{'å®éªŒ':<15} {'æœ€ä½³éªŒè¯å‡†ç¡®ç‡':>15} {'æå‡':>10}")
    print("-" * 42)
    print(f"{'ä¸ä½¿ç”¨å¢å¼º':<15} {best_acc1:>14.2f}% {'-':>10}")
    print(f"{'ä½¿ç”¨å¢å¼º':<15} {best_acc2:>14.2f}% {f'+{best_acc2-best_acc1:.2f}%':>10}")
    print("=" * 70)

    # åˆ†æè¿‡æ‹Ÿåˆæƒ…å†µ
    final_gap1 = train_accs1[-1] - val_accs1[-1]
    final_gap2 = train_accs2[-1] - val_accs2[-1]

    print(f"\nğŸ“ˆ è¿‡æ‹Ÿåˆåˆ†æ (è®­ç»ƒå‡†ç¡®ç‡ - éªŒè¯å‡†ç¡®ç‡):")
    print(f"  ä¸ä½¿ç”¨å¢å¼º: {final_gap1:.2f}% (è¶Šå¤§è¶Šè¿‡æ‹Ÿåˆ)")
    print(f"  ä½¿ç”¨å¢å¼º:   {final_gap2:.2f}% (è¶Šå°è¶Šå¥½)")
    print(f"\nğŸ’¡ ç»“è®º: æ•°æ®å¢å¼º{'æœ‰æ•ˆ' if final_gap2 < final_gap1 else 'æœªæ˜æ˜¾'}ç¼“è§£äº†è¿‡æ‹Ÿåˆ")


# ============================================================
# 9. ä¸»å‡½æ•°
# ============================================================
def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ç¤ºä¾‹5: æ•°æ®å¢å¼º")
    print("=" * 70)

    print("\nğŸ“– æ•°æ®å¢å¼ºæŠ€æœ¯è¯´æ˜:")
    print("-" * 70)
    print("""
    1. å‡ ä½•å˜æ¢:
       - RandomHorizontalFlip: éšæœºæ°´å¹³ç¿»è½¬
       - RandomRotation: éšæœºæ—‹è½¬
       - RandomCrop: éšæœºè£å‰ª
       - RandomResizedCrop: éšæœºè£å‰ªå¹¶è°ƒæ•´å¤§å°

    2. é¢œè‰²å˜æ¢:
       - ColorJitter: äº®åº¦/å¯¹æ¯”åº¦/é¥±å’Œåº¦/è‰²è°ƒæŠ–åŠ¨
       - RandomGrayscale: éšæœºè½¬ç°åº¦å›¾
       - RandomInvert: éšæœºåè‰²

    3. é®æŒ¡:
       - RandomErasing: éšæœºæ“¦é™¤åŒºåŸŸ (æ¨¡æ‹Ÿé®æŒ¡)

    4. ä½œç”¨:
       - å¢åŠ è®­ç»ƒæ•°æ®å¤šæ ·æ€§
       - æé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›
       - é˜²æ­¢è¿‡æ‹Ÿåˆ
       - æå‡éªŒè¯/æµ‹è¯•å‡†ç¡®ç‡
    """)

    # æ­¥éª¤1: å¯è§†åŒ–æ•°æ®å¢å¼ºæ•ˆæœ
    visualize_augmentation()

    # æ­¥éª¤2: å¯¹æ¯”æœ‰æ— æ•°æ®å¢å¼ºçš„è®­ç»ƒæ•ˆæœ
    print("\n\nå¯¹æ¯”å®éªŒå°†è®­ç»ƒ2ä¸ªæ¨¡å‹,éœ€è¦ä¸€äº›æ—¶é—´...")
    response = input("æ˜¯å¦æ‰§è¡Œå¯¹æ¯”å®éªŒ? (y/n): ")
    if response.lower() == 'y':
        compare_augmentation()

    print("\n" + "=" * 70)
    print("âœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆ!")
    print("=" * 70)
    print("\nğŸ’¡ æ–°å¢å†…å®¹:")
    print("  1. âœ… éšæœºæ°´å¹³ç¿»è½¬")
    print("  2. âœ… éšæœºæ—‹è½¬")
    print("  3. âœ… éšæœºè£å‰ª")
    print("  4. âœ… é¢œè‰²æŠ–åŠ¨ (äº®åº¦/å¯¹æ¯”åº¦/é¥±å’Œåº¦/è‰²è°ƒ)")
    print("  5. âœ… éšæœºæ“¦é™¤")
    print("  6. âœ… Dropouté˜²æ­¢è¿‡æ‹Ÿåˆ")
    print("  7. âœ… å¯è§†åŒ–å¢å¼ºæ•ˆæœ")
    print("  8. âœ… å¯¹æ¯”æœ‰æ— å¢å¼ºçš„è®­ç»ƒæ•ˆæœ")
    print("  9. âœ… è¿‡æ‹Ÿåˆæ£€æµ‹å’Œåˆ†æ")
    print("\nğŸ“Š æŸ¥çœ‹è®­ç»ƒå¯è§†åŒ–:")
    print("  tensorboard --logdir=/home/seeback/PycharmProjects/DeepLearning/tensor_board/05_data_augmentation")
    print("=" * 70)


if __name__ == '__main__':
    main()
