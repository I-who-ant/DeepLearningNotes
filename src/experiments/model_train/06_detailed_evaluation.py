"""
ç¤ºä¾‹6: è¯¦ç»†çš„æ¨¡å‹è¯„ä¼°ä¸åˆ†æ

åœ¨å‰é¢ç¤ºä¾‹çš„åŸºç¡€ä¸Šæ·»åŠ :
- ä½¿ç”¨argmaxè·å–é¢„æµ‹ç»“æœçš„è¯¦ç»†è§£é‡Š
- æµ‹è¯•é›†ä¸Šçš„å®Œæ•´è¯„ä¼°
- æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°
- æ··æ·†çŸ©é˜µå¯è§†åŒ–
- Top-Kå‡†ç¡®ç‡
- é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒåˆ†æ
- é”™è¯¯æ ·æœ¬å¯è§†åŒ–
- ç½®ä¿¡åº¦åˆ†æ

è¿è¡Œ: python src/experiments/model_train/06_detailed_evaluation.py
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torch.utils.tensorboard import SummaryWriter
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
import os
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns


# ============================================================
# 1. å®šä¹‰ç›¸åŒçš„CNNæ¨¡å‹
# ============================================================
class SimpleCNN(nn.Module):
    """ç®€å•çš„3å±‚å·ç§¯ç¥ç»ç½‘ç»œ"""
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(128 * 4 * 4, 256)
        self.fc2 = nn.Linear(256, 10)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = self.pool(self.relu(self.conv3(x)))
        x = x.view(x.size(0), -1)
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x


# ============================================================
# 2. å‡†å¤‡æ•°æ®
# ============================================================
def prepare_data(val_ratio=0.2):
    """åŠ è½½CIFAR-10æ•°æ®é›†"""
    print("æ­£åœ¨åŠ è½½ CIFAR-10 æ•°æ®é›†...")

    # æ•°æ®å¢å¼º
    train_transform = transforms.Compose([
        transforms.RandomHorizontalFlip(),
        transforms.RandomCrop(32, padding=4),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    # æµ‹è¯•é›†ä¸ä½¿ç”¨æ•°æ®å¢å¼º
    test_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    # è®­ç»ƒé›†
    full_train_dataset = datasets.CIFAR10(
        root='./data', train=True, download=True, transform=train_transform
    )

    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    total_size = len(full_train_dataset)
    val_size = int(total_size * val_ratio)
    train_size = total_size - val_size

    train_dataset, val_dataset = random_split(
        full_train_dataset, [train_size, val_size],
        generator=torch.Generator().manual_seed(42)
    )

    # æµ‹è¯•é›†
    test_dataset = datasets.CIFAR10(
        root='./data', train=False, download=True, transform=test_transform
    )

    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)

    print(f"è®­ç»ƒé›†: {len(train_dataset)} å¼ å›¾ç‰‡")
    print(f"éªŒè¯é›†: {len(val_dataset)} å¼ å›¾ç‰‡")
    print(f"æµ‹è¯•é›†: {len(test_dataset)} å¼ å›¾ç‰‡")

    return train_loader, val_loader, test_loader


# ============================================================
# 3. ç®€å•è®­ç»ƒå‡½æ•° (å¤ç”¨ä¹‹å‰çš„é€»è¾‘)
# ============================================================
def train_one_epoch(model, train_loader, criterion, optimizer):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    running_loss = 0.0
    total_samples = 0

    for images, labels in train_loader:
        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)
        total_samples += images.size(0)

    return running_loss / total_samples


def validate(model, val_loader, criterion):
    """éªŒè¯å‡½æ•°"""
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in val_loader:
            outputs = model(images)
            loss = criterion(outputs, labels)

            running_loss += loss.item() * images.size(0)

            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    return running_loss / total, 100 * correct / total


# ============================================================
# 4. è¯¦ç»†çš„æµ‹è¯•é›†è¯„ä¼° - æ–°å¢!
# ============================================================
def detailed_evaluation(model, test_loader, class_names):
    """
    åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œè¯¦ç»†è¯„ä¼°

    å‚æ•°:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        class_names: ç±»åˆ«åç§°åˆ—è¡¨

    è¿”å›:
        all_labels: æ‰€æœ‰çœŸå®æ ‡ç­¾
        all_preds: æ‰€æœ‰é¢„æµ‹æ ‡ç­¾
        all_probs: æ‰€æœ‰é¢„æµ‹æ¦‚ç‡
    """
    print("\n" + "=" * 70)
    print("ğŸ“Š è¯¦ç»†çš„æµ‹è¯•é›†è¯„ä¼°")
    print("=" * 70)

    model.eval()

    all_labels = []      # å­˜å‚¨æ‰€æœ‰çœŸå®æ ‡ç­¾
    all_preds = []       # å­˜å‚¨æ‰€æœ‰é¢„æµ‹æ ‡ç­¾
    all_probs = []       # å­˜å‚¨æ‰€æœ‰é¢„æµ‹æ¦‚ç‡

    correct = 0
    total = 0

    print("\næ­£åœ¨è¯„ä¼°æµ‹è¯•é›†...")

    with torch.no_grad():
        for batch_idx, (images, labels) in enumerate(test_loader):
            # ========================================
            # å‰å‘ä¼ æ’­è·å–è¾“å‡º
            # ========================================
            outputs = model(images)  # shape: [batch_size, num_classes]

            # ========================================
            # æ–¹æ³•1: ä½¿ç”¨ torch.max è·å–é¢„æµ‹ç±»åˆ«
            # ========================================
            # torch.maxè¿”å›ä¸¤ä¸ªå€¼: (æœ€å¤§å€¼, æœ€å¤§å€¼çš„ç´¢å¼•)
            # dim=1 è¡¨ç¤ºåœ¨ç±»åˆ«ç»´åº¦ä¸Šæ‰¾æœ€å¤§å€¼
            max_values, predicted = torch.max(outputs, dim=1)

            # ========================================
            # æ–¹æ³•2: ä½¿ç”¨ argmax è·å–é¢„æµ‹ç±»åˆ« (ç­‰ä»·äºtorch.max)
            # ========================================
            # predicted_argmax = torch.argmax(outputs, dim=1)
            # æ³¨æ„: torch.max å’Œ torch.argmax ç»“æœç›¸åŒ
            # torch.max é¢å¤–è¿”å›æœ€å¤§å€¼,è€Œ argmax åªè¿”å›ç´¢å¼•

            # ========================================
            # è·å–é¢„æµ‹æ¦‚ç‡ (ä½¿ç”¨softmax)
            # ========================================
            probabilities = torch.softmax(outputs, dim=1)  # shape: [batch_size, num_classes]

            # æ”¶é›†ç»“æœ
            all_labels.extend(labels.cpu().numpy())
            all_preds.extend(predicted.cpu().numpy())
            all_probs.extend(probabilities.cpu().numpy())

            # è®¡ç®—å‡†ç¡®ç‡
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            if (batch_idx + 1) % 50 == 0:
                print(f"  å·²å¤„ç† {batch_idx + 1}/{len(test_loader)} æ‰¹æ¬¡")

    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    all_labels = np.array(all_labels)
    all_preds = np.array(all_preds)
    all_probs = np.array(all_probs)

    # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
    accuracy = 100 * correct / total

    print(f"\nâœ… è¯„ä¼°å®Œæˆ!")
    print(f"ğŸ“Š æ€»ä½“å‡†ç¡®ç‡: {accuracy:.2f}% ({correct}/{total})")

    return all_labels, all_preds, all_probs


# ============================================================
# 5. æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†æŒ‡æ ‡ - æ–°å¢!
# ============================================================
def per_class_metrics(all_labels, all_preds, class_names):
    """
    è®¡ç®—æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†æŒ‡æ ‡

    å‚æ•°:
        all_labels: çœŸå®æ ‡ç­¾
        all_preds: é¢„æµ‹æ ‡ç­¾
        class_names: ç±»åˆ«åç§°
    """
    print("\n" + "=" * 70)
    print("ğŸ“ˆ æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†æŒ‡æ ‡")
    print("=" * 70)

    # ä½¿ç”¨sklearnè®¡ç®—åˆ†ç±»æŠ¥å‘Š
    report = classification_report(
        all_labels,
        all_preds,
        target_names=class_names,
        digits=4,
        output_dict=True
    )

    # æ‰“å°è¡¨å¤´
    print(f"\n{'ç±»åˆ«':<12} {'ç²¾ç¡®ç‡':>10} {'å¬å›ç‡':>10} {'F1åˆ†æ•°':>10} {'æ ·æœ¬æ•°':>8}")
    print("-" * 55)

    # æ‰“å°æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡
    for i, class_name in enumerate(class_names):
        metrics = report[class_name]
        print(f"{class_name:<12} {metrics['precision']:>9.2%} {metrics['recall']:>9.2%} "
              f"{metrics['f1-score']:>9.2%} {int(metrics['support']):>8}")

    # æ‰“å°æ€»ä½“æŒ‡æ ‡
    print("-" * 55)
    print(f"{'æ€»ä½“å‡†ç¡®ç‡':<12} {report['accuracy']:>9.2%}")
    print(f"{'å®å¹³å‡':<12} {report['macro avg']['precision']:>9.2%} "
          f"{report['macro avg']['recall']:>9.2%} {report['macro avg']['f1-score']:>9.2%}")
    print(f"{'åŠ æƒå¹³å‡':<12} {report['weighted avg']['precision']:>9.2%} "
          f"{report['weighted avg']['recall']:>9.2%} {report['weighted avg']['f1-score']:>9.2%}")

    print("\nğŸ’¡ æŒ‡æ ‡è¯´æ˜:")
    print("  - ç²¾ç¡®ç‡ (Precision): é¢„æµ‹ä¸ºè¯¥ç±»çš„æ ·æœ¬ä¸­,çœŸæ­£å±äºè¯¥ç±»çš„æ¯”ä¾‹")
    print("  - å¬å›ç‡ (Recall): çœŸæ­£å±äºè¯¥ç±»çš„æ ·æœ¬ä¸­,è¢«æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹")
    print("  - F1åˆ†æ•°: ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡æ•°")


# ============================================================
# 6. æ··æ·†çŸ©é˜µå¯è§†åŒ– - æ–°å¢!
# ============================================================
def plot_confusion_matrix(all_labels, all_preds, class_names, save_path='artifacts/confusion_matrix.png'):
    """
    ç»˜åˆ¶æ··æ·†çŸ©é˜µ

    å‚æ•°:
        all_labels: çœŸå®æ ‡ç­¾
        all_preds: é¢„æµ‹æ ‡ç­¾
        class_names: ç±»åˆ«åç§°
        save_path: ä¿å­˜è·¯å¾„
    """
    print("\n" + "=" * 70)
    print("ğŸ”¥ æ··æ·†çŸ©é˜µ")
    print("=" * 70)

    # è®¡ç®—æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(all_labels, all_preds)

    # åˆ›å»ºå›¾è¡¨
    plt.figure(figsize=(12, 10))

    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    sns.heatmap(
        cm,
        annot=True,           # æ˜¾ç¤ºæ•°å€¼
        fmt='d',              # æ•´æ•°æ ¼å¼
        cmap='Blues',         # é¢œè‰²æ˜ å°„
        xticklabels=class_names,
        yticklabels=class_names,
        cbar_kws={'label': 'æ ·æœ¬æ•°é‡'}
    )

    plt.title('æ··æ·†çŸ©é˜µ (Confusion Matrix)', fontsize=16, fontweight='bold', pad=20)
    plt.xlabel('é¢„æµ‹ç±»åˆ«', fontsize=12)
    plt.ylabel('çœŸå®ç±»åˆ«', fontsize=12)
    plt.tight_layout()

    # ä¿å­˜å›¾ç‰‡
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"\nâœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: {save_path}")

    plt.close()

    # åˆ†ææ··æ·†çŸ©é˜µ
    print("\nğŸ’¡ æ··æ·†çŸ©é˜µåˆ†æ:")
    print("  - å¯¹è§’çº¿: æ­£ç¡®é¢„æµ‹çš„æ ·æœ¬æ•°é‡")
    print("  - éå¯¹è§’çº¿: é”™è¯¯é¢„æµ‹çš„æ ·æœ¬æ•°é‡")

    # æ‰¾å‡ºæœ€å®¹æ˜“æ··æ·†çš„ç±»åˆ«å¯¹
    np.fill_diagonal(cm, 0)  # å¿½ç•¥å¯¹è§’çº¿
    max_confusion_idx = np.unravel_index(cm.argmax(), cm.shape)
    true_class = class_names[max_confusion_idx[0]]
    pred_class = class_names[max_confusion_idx[1]]
    confusion_count = cm[max_confusion_idx]

    print(f"\nâš ï¸ æœ€å®¹æ˜“æ··æ·†çš„ç±»åˆ«å¯¹:")
    print(f"  çœŸå®ç±»åˆ«: {true_class}")
    print(f"  é¢„æµ‹ä¸º: {pred_class}")
    print(f"  æ··æ·†æ¬¡æ•°: {confusion_count} æ¬¡")


# ============================================================
# 7. Top-Kå‡†ç¡®ç‡ - æ–°å¢!
# ============================================================
def top_k_accuracy(all_labels, all_probs, class_names, k_values=[1, 3, 5]):
    """
    è®¡ç®—Top-Kå‡†ç¡®ç‡

    å‚æ•°:
        all_labels: çœŸå®æ ‡ç­¾
        all_probs: é¢„æµ‹æ¦‚ç‡
        class_names: ç±»åˆ«åç§°
        k_values: Kå€¼åˆ—è¡¨
    """
    print("\n" + "=" * 70)
    print("ğŸ¯ Top-K å‡†ç¡®ç‡")
    print("=" * 70)

    print("\nğŸ’¡ Top-Kå‡†ç¡®ç‡è¯´æ˜:")
    print("  Top-1: é¢„æµ‹æ¦‚ç‡æœ€é«˜çš„ç±»åˆ«æ˜¯æ­£ç¡®ç±»åˆ«çš„æ¯”ä¾‹")
    print("  Top-3: é¢„æµ‹æ¦‚ç‡å‰3çš„ç±»åˆ«ä¸­åŒ…å«æ­£ç¡®ç±»åˆ«çš„æ¯”ä¾‹")
    print("  Top-5: é¢„æµ‹æ¦‚ç‡å‰5çš„ç±»åˆ«ä¸­åŒ…å«æ­£ç¡®ç±»åˆ«çš„æ¯”ä¾‹")

    print(f"\n{'Kå€¼':<6} {'å‡†ç¡®ç‡':>10} {'è¯´æ˜'}")
    print("-" * 40)

    for k in k_values:
        # è·å–Top-Ké¢„æµ‹
        top_k_preds = np.argsort(all_probs, axis=1)[:, -k:]  # æ¯ä¸ªæ ·æœ¬çš„Top-Ké¢„æµ‹

        # è®¡ç®—Top-Kå‡†ç¡®ç‡
        correct = 0
        for i, true_label in enumerate(all_labels):
            if true_label in top_k_preds[i]:
                correct += 1

        accuracy = 100 * correct / len(all_labels)
        print(f"Top-{k:<3} {accuracy:>9.2f}%  é¢„æµ‹æ¦‚ç‡å‰{k}ä¸­åŒ…å«æ­£ç¡®ç±»åˆ«")


# ============================================================
# 8. é¢„æµ‹ç½®ä¿¡åº¦åˆ†æ - æ–°å¢!
# ============================================================
def confidence_analysis(all_labels, all_preds, all_probs, save_path='artifacts/confidence_analysis.png'):
    """
    åˆ†æé¢„æµ‹ç½®ä¿¡åº¦

    å‚æ•°:
        all_labels: çœŸå®æ ‡ç­¾
        all_preds: é¢„æµ‹æ ‡ç­¾
        all_probs: é¢„æµ‹æ¦‚ç‡
        save_path: ä¿å­˜è·¯å¾„
    """
    print("\n" + "=" * 70)
    print("ğŸ“Š é¢„æµ‹ç½®ä¿¡åº¦åˆ†æ")
    print("=" * 70)

    # è·å–é¢„æµ‹çš„æœ€å¤§æ¦‚ç‡ (å³ç½®ä¿¡åº¦)
    confidences = np.max(all_probs, axis=1)

    # åˆ¤æ–­é¢„æµ‹æ˜¯å¦æ­£ç¡®
    correct_mask = (all_labels == all_preds)

    # åˆ†åˆ«è·å–æ­£ç¡®å’Œé”™è¯¯é¢„æµ‹çš„ç½®ä¿¡åº¦
    correct_confidences = confidences[correct_mask]
    wrong_confidences = confidences[~correct_mask]

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\næ­£ç¡®é¢„æµ‹çš„ç½®ä¿¡åº¦ç»Ÿè®¡:")
    print(f"  å¹³å‡å€¼: {np.mean(correct_confidences):.4f}")
    print(f"  ä¸­ä½æ•°: {np.median(correct_confidences):.4f}")
    print(f"  æœ€å°å€¼: {np.min(correct_confidences):.4f}")
    print(f"  æœ€å¤§å€¼: {np.max(correct_confidences):.4f}")

    print(f"\né”™è¯¯é¢„æµ‹çš„ç½®ä¿¡åº¦ç»Ÿè®¡:")
    print(f"  å¹³å‡å€¼: {np.mean(wrong_confidences):.4f}")
    print(f"  ä¸­ä½æ•°: {np.median(wrong_confidences):.4f}")
    print(f"  æœ€å°å€¼: {np.min(wrong_confidences):.4f}")
    print(f"  æœ€å¤§å€¼: {np.max(wrong_confidences):.4f}")

    # ç»˜åˆ¶ç½®ä¿¡åº¦åˆ†å¸ƒ
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # å·¦å›¾: ç½®ä¿¡åº¦ç›´æ–¹å›¾
    axes[0].hist(correct_confidences, bins=50, alpha=0.7, label='æ­£ç¡®é¢„æµ‹', color='green')
    axes[0].hist(wrong_confidences, bins=50, alpha=0.7, label='é”™è¯¯é¢„æµ‹', color='red')
    axes[0].set_xlabel('é¢„æµ‹ç½®ä¿¡åº¦', fontsize=12)
    axes[0].set_ylabel('æ ·æœ¬æ•°é‡', fontsize=12)
    axes[0].set_title('é¢„æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # å³å›¾: ç½®ä¿¡åº¦ç®±çº¿å›¾
    data = [correct_confidences, wrong_confidences]
    axes[1].boxplot(data, labels=['æ­£ç¡®é¢„æµ‹', 'é”™è¯¯é¢„æµ‹'])
    axes[1].set_ylabel('é¢„æµ‹ç½®ä¿¡åº¦', fontsize=12)
    axes[1].set_title('é¢„æµ‹ç½®ä¿¡åº¦ç®±çº¿å›¾', fontsize=14, fontweight='bold')
    axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"\nâœ… ç½®ä¿¡åº¦åˆ†æå›¾å·²ä¿å­˜åˆ°: {save_path}")

    plt.close()


# ============================================================
# 9. é”™è¯¯æ ·æœ¬å¯è§†åŒ– - æ–°å¢!
# ============================================================
def visualize_errors(model, test_dataset, all_labels, all_preds, all_probs, class_names,
                     num_samples=16, save_path='artifacts/error_samples.png'):
    """
    å¯è§†åŒ–é”™è¯¯é¢„æµ‹çš„æ ·æœ¬

    å‚æ•°:
        model: æ¨¡å‹
        test_dataset: æµ‹è¯•æ•°æ®é›†
        all_labels: çœŸå®æ ‡ç­¾
        all_preds: é¢„æµ‹æ ‡ç­¾
        all_probs: é¢„æµ‹æ¦‚ç‡
        class_names: ç±»åˆ«åç§°
        num_samples: æ˜¾ç¤ºçš„æ ·æœ¬æ•°é‡
        save_path: ä¿å­˜è·¯å¾„
    """
    print("\n" + "=" * 70)
    print("ğŸ” é”™è¯¯æ ·æœ¬å¯è§†åŒ–")
    print("=" * 70)

    # æ‰¾å‡ºæ‰€æœ‰é”™è¯¯é¢„æµ‹çš„ç´¢å¼•
    error_indices = np.where(all_labels != all_preds)[0]

    print(f"\næ€»é”™è¯¯æ•°: {len(error_indices)}")
    print(f"æ˜¾ç¤ºå‰ {num_samples} ä¸ªé”™è¯¯æ ·æœ¬...")

    # éšæœºé€‰æ‹©ä¸€äº›é”™è¯¯æ ·æœ¬
    np.random.seed(42)
    selected_indices = np.random.choice(error_indices, min(num_samples, len(error_indices)), replace=False)

    # åˆ›å»ºå›¾è¡¨
    rows = 4
    cols = 4
    fig, axes = plt.subplots(rows, cols, figsize=(16, 16))
    fig.suptitle('é”™è¯¯é¢„æµ‹æ ·æœ¬åˆ†æ', fontsize=16, fontweight='bold')

    for idx, error_idx in enumerate(selected_indices):
        if idx >= rows * cols:
            break

        row = idx // cols
        col = idx % cols

        # è·å–å›¾ç‰‡å’Œæ ‡ç­¾
        image, _ = test_dataset[error_idx]

        # åå½’ä¸€åŒ–ç”¨äºæ˜¾ç¤º
        image_np = image.numpy().transpose(1, 2, 0)
        image_np = image_np * 0.5 + 0.5  # åå½’ä¸€åŒ–
        image_np = np.clip(image_np, 0, 1)

        # è·å–é¢„æµ‹ä¿¡æ¯
        true_label = all_labels[error_idx]
        pred_label = all_preds[error_idx]
        confidence = all_probs[error_idx, pred_label]

        # æ˜¾ç¤ºå›¾ç‰‡
        axes[row, col].imshow(image_np)
        axes[row, col].axis('off')

        # æ·»åŠ æ ‡é¢˜
        title = f'çœŸå®: {class_names[true_label]}\n' \
                f'é¢„æµ‹: {class_names[pred_label]}\n' \
                f'ç½®ä¿¡åº¦: {confidence:.2%}'
        axes[row, col].set_title(title, fontsize=10, color='red')

    plt.tight_layout()
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"\nâœ… é”™è¯¯æ ·æœ¬å¯è§†åŒ–å·²ä¿å­˜åˆ°: {save_path}")

    plt.close()


# ============================================================
# 10. argmaxè¯¦ç»†è§£é‡Š - æ–°å¢!
# ============================================================
def explain_argmax():
    """è¯¦ç»†è§£é‡Šargmaxçš„åŸç†å’Œä½¿ç”¨"""
    print("\n" + "=" * 70)
    print("ğŸ“š argmax è¯¦ç»†è§£é‡Š")
    print("=" * 70)

    print("""
ğŸ¯ ä»€ä¹ˆæ˜¯ argmax?
  argmax è¿”å›æ•°ç»„ä¸­æœ€å¤§å€¼çš„ç´¢å¼•(ä½ç½®)

ğŸ” ç¤ºä¾‹æ¼”ç¤º:
""")

    # ç¤ºä¾‹1: ç®€å•çš„1ç»´æ•°ç»„
    scores = np.array([0.1, 0.3, 0.8, 0.2, 0.5])
    max_idx = np.argmax(scores)

    print("ç¤ºä¾‹1: ä¸€ç»´æ•°ç»„")
    print(f"  è¾“å…¥: {scores}")
    print(f"  argmaxç»“æœ: {max_idx} (ç¬¬{max_idx}ä¸ªä½ç½®,å€¼ä¸º{scores[max_idx]})")

    # ç¤ºä¾‹2: ç¥ç»ç½‘ç»œè¾“å‡º
    print("\nç¤ºä¾‹2: ç¥ç»ç½‘ç»œè¾“å‡º (CIFAR-10åˆ†ç±»)")
    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                   'dog', 'frog', 'horse', 'ship', 'truck']

    # æ¨¡æ‹Ÿä¸€ä¸ªè¾“å‡º (logits)
    output = np.array([2.1, -0.5, 1.8, 0.3, -1.2, 0.8, 3.5, 1.1, 0.2, -0.8])

    print(f"\n  ç½‘ç»œè¾“å‡º (logits):")
    for i, (name, score) in enumerate(zip(class_names, output)):
        print(f"    {i}. {name:<12}: {score:>6.2f}")

    # ä½¿ç”¨argmaxè·å–é¢„æµ‹ç±»åˆ«
    pred_class = np.argmax(output)
    print(f"\n  argmaxç»“æœ: {pred_class} -> {class_names[pred_class]}")
    print(f"  æœ€å¤§å€¼: {output[pred_class]:.2f}")

    # ç¤ºä¾‹3: Batché¢„æµ‹
    print("\nç¤ºä¾‹3: Batché¢„æµ‹ (å¤šä¸ªæ ·æœ¬)")

    # æ¨¡æ‹Ÿ3ä¸ªæ ·æœ¬çš„è¾“å‡º
    batch_output = np.array([
        [2.1, -0.5, 1.8, 0.3, -1.2, 0.8, 3.5, 1.1, 0.2, -0.8],  # æ ·æœ¬1
        [1.2, 2.8, 0.3, 0.5, 1.1, 0.2, 0.7, 0.9, 1.5, 0.4],      # æ ·æœ¬2
        [0.1, 0.2, 3.2, 1.1, 0.8, 1.5, 0.9, 1.2, 0.5, 0.3],      # æ ·æœ¬3
    ])

    print(f"  Batchè¾“å‡º shape: {batch_output.shape} (3ä¸ªæ ·æœ¬, 10ä¸ªç±»åˆ«)")

    # å¯¹æ¯ä¸ªæ ·æœ¬ä½¿ç”¨argmax
    batch_preds = np.argmax(batch_output, axis=1)  # axis=1è¡¨ç¤ºåœ¨ç±»åˆ«ç»´åº¦ä¸Šå–æœ€å¤§å€¼

    print(f"\n  Batché¢„æµ‹ç»“æœ:")
    for i, pred in enumerate(batch_preds):
        print(f"    æ ·æœ¬{i+1}: ç±»åˆ«{pred} ({class_names[pred]})")

    # PyTorch vs NumPy
    print("\n" + "=" * 70)
    print("ğŸ”§ PyTorch vs NumPy")
    print("=" * 70)

    print("""
NumPy:
  pred = np.argmax(output, axis=1)

PyTorch (æ–¹æ³•1 - ä½¿ç”¨argmax):
  pred = torch.argmax(output, dim=1)

PyTorch (æ–¹æ³•2 - ä½¿ç”¨max):
  max_values, pred = torch.max(output, dim=1)
  # maxè¿”å›ä¸¤ä¸ªå€¼: (æœ€å¤§å€¼, æœ€å¤§å€¼çš„ç´¢å¼•)

ğŸ’¡ æ³¨æ„:
  - NumPyä½¿ç”¨ axis å‚æ•°
  - PyTorchä½¿ç”¨ dim å‚æ•°
  - torch.max é¢å¤–è¿”å›æœ€å¤§å€¼æœ¬èº«
  - torch.argmax åªè¿”å›ç´¢å¼•
""")


# ============================================================
# 11. ä¸»å‡½æ•°
# ============================================================
def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ç¤ºä¾‹6: è¯¦ç»†çš„æ¨¡å‹è¯„ä¼°ä¸åˆ†æ")
    print("=" * 70)

    # é¦–å…ˆè§£é‡Šargmax
    explain_argmax()

    # å‡†å¤‡æ•°æ®
    train_loader, val_loader, test_loader = prepare_data(val_ratio=0.2)

    # ç±»åˆ«åç§°
    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                   'dog', 'frog', 'horse', 'ship', 'truck']

    # é€‰é¡¹: æ˜¯å¦è®­ç»ƒæ–°æ¨¡å‹
    print("\n" + "=" * 70)
    response = input("æ˜¯å¦è®­ç»ƒæ–°æ¨¡å‹? (y/n, ç›´æ¥å›è½¦ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹): ")

    if response.lower() == 'y':
        # è®­ç»ƒæ¨¡å‹
        print("\nå¼€å§‹è®­ç»ƒæ¨¡å‹...")
        model = SimpleCNN()
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)

        best_val_acc = 0.0
        num_epochs = 20

        for epoch in range(num_epochs):
            train_loss = train_one_epoch(model, train_loader, criterion, optimizer)
            val_loss, val_acc = validate(model, val_loader, criterion)

            print(f"Epoch [{epoch+1}/{num_epochs}] "
                  f"Train Loss: {train_loss:.4f} | "
                  f"Val Loss: {val_loss:.4f} | "
                  f"Val Acc: {val_acc:.2f}%")

            if val_acc > best_val_acc:
                best_val_acc = val_acc
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                os.makedirs('artifacts/checkpoints', exist_ok=True)
                torch.save(model.state_dict(), 'artifacts/checkpoints/best_model_eval.pth')

            scheduler.step()

        print(f"\nâœ… è®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")

    else:
        # å°è¯•åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        model = SimpleCNN()
        model_path = 'artifacts/checkpoints/best_model_eval.pth'

        if os.path.exists(model_path):
            model.load_state_dict(torch.load(model_path))
            print(f"\nâœ… å·²åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_path}")
        else:
            print(f"\nâš ï¸ æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹,å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹")
            print("   (å»ºè®®é€‰æ‹© 'y' è®­ç»ƒæ–°æ¨¡å‹ä»¥è·å¾—æ›´å¥½çš„è¯„ä¼°ç»“æœ)")

    # ========================================
    # è¯¦ç»†è¯„ä¼°
    # ========================================

    # 1. æµ‹è¯•é›†è¯„ä¼°
    test_dataset = datasets.CIFAR10(
        root='./data', train=False, download=True,
        transform=transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
    )

    all_labels, all_preds, all_probs = detailed_evaluation(model, test_loader, class_names)

    # 2. æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†æŒ‡æ ‡
    per_class_metrics(all_labels, all_preds, class_names)

    # 3. æ··æ·†çŸ©é˜µ
    plot_confusion_matrix(all_labels, all_preds, class_names)

    # 4. Top-Kå‡†ç¡®ç‡
    top_k_accuracy(all_labels, all_probs, class_names, k_values=[1, 3, 5])

    # 5. ç½®ä¿¡åº¦åˆ†æ
    confidence_analysis(all_labels, all_preds, all_probs)

    # 6. é”™è¯¯æ ·æœ¬å¯è§†åŒ–
    visualize_errors(model, test_dataset, all_labels, all_preds, all_probs, class_names)

    print("\n" + "=" * 70)
    print("âœ… æ‰€æœ‰è¯„ä¼°å®Œæˆ!")
    print("=" * 70)
    print("\nğŸ’¡ æ–°å¢å†…å®¹:")
    print("  1. âœ… argmaxè¯¦ç»†è§£é‡Šå’Œç¤ºä¾‹")
    print("  2. âœ… æµ‹è¯•é›†å®Œæ•´è¯„ä¼°")
    print("  3. âœ… æ¯ä¸ªç±»åˆ«çš„ç²¾ç¡®ç‡/å¬å›ç‡/F1åˆ†æ•°")
    print("  4. âœ… æ··æ·†çŸ©é˜µå¯è§†åŒ–")
    print("  5. âœ… Top-Kå‡†ç¡®ç‡")
    print("  6. âœ… é¢„æµ‹ç½®ä¿¡åº¦åˆ†æ")
    print("  7. âœ… é”™è¯¯æ ·æœ¬å¯è§†åŒ–")
    print("\nğŸ“Š ç”Ÿæˆçš„å¯è§†åŒ–æ–‡ä»¶:")
    print("  - artifacts/confusion_matrix.png      (æ··æ·†çŸ©é˜µ)")
    print("  - artifacts/confidence_analysis.png   (ç½®ä¿¡åº¦åˆ†æ)")
    print("  - artifacts/error_samples.png         (é”™è¯¯æ ·æœ¬)")
    print("=" * 70)


if __name__ == '__main__':
    main()
