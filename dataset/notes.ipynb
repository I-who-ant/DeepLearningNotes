{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face æ•°æ®é›†ç›®å½•è¯´æ˜\n",
    "\n",
    "æœ¬ä»“åº“é€šè¿‡ `datasets.load_dataset(\"Bingsu/Cat_and_Dog\")` æ‹‰å–æ•°æ®ï¼Œå¹¶åœ¨ `dataset/` ä¸‹ç”Ÿæˆä¸¤ä¸ªå…³é”®ç›®å½•ã€‚ç†è§£å®ƒä»¬çš„èŒè´£æœ‰åŠ©äºåç»­ç®¡ç†ï¼š\n",
    "\n",
    "- `hf_cache/`ï¼šğŸ¤— Datasets çš„è‡ªåŠ¨ç¼“å­˜ã€‚åŒ…å«ä¸‹è½½çš„å‹ç¼©åŒ…ã€è§£åŒ…åçš„ `dataset.arrow` åˆ†ç‰‡ã€`state.json` ç­‰å…ƒæ•°æ®ã€‚åº“å†…éƒ¨ä½¿ç”¨å“ˆå¸Œç»“æ„å‘½åï¼Œ**ä¸è¦æ‰‹å·¥æ”¹åŠ¨**ï¼Œå¦åˆ™ç¼“å­˜å‘½ä¸­ä¸å¢é‡æ›´æ–°éƒ½ä¼šå¤±æ•ˆã€‚\n",
    "- `Cat_and_Dog/`ï¼šè°ƒç”¨ `DatasetDict.save_to_disk()` åçš„åºåˆ—åŒ–å‰¯æœ¬ï¼Œä¿ç•™å½“å‰æ‰€æœ‰ split åŠå…¶ schemaã€‚ç›®å½•ä¸­æ¯ä¸ª split æ‹¥æœ‰ `data-00000-of-00001.arrow` ä¸ `dataset_info.json` ç­‰æ–‡ä»¶ï¼Œå¯é€šè¿‡ `load_from_disk` è·¨å¹³å°å…±äº«ã€‚\n",
    "\n",
    "å¦‚æœå¸Œæœ›å¯¼å‡ºåŸå§‹å›¾ç‰‡ï¼Œå¯éå† `DatasetDict` å¹¶æ‰‹åŠ¨è°ƒç”¨ `Image.save()` å†™å…¥å…¶ä»–æ–‡ä»¶å¤¹ï¼›å¯¹ç¼“å­˜å’Œç£ç›˜å‰¯æœ¬æœ¬èº«ä¸åšä¿®æ”¹ã€‚"
   ],
   "id": "4a73676aade05330"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸ºä»€ä¹ˆæ˜¯ .arrow æ ¼å¼ï¼Ÿ\n",
    "\n",
    "- **åˆ—å¼å­˜å‚¨**ï¼šApache Arrow ä»¥åˆ—ä¸ºå•ä½ç»„ç»‡æ•°æ®ï¼Œæ”¯æŒå†…å­˜æ˜ å°„ï¼ˆmemory mappingï¼‰ï¼Œæ— éœ€ä¸€æ¬¡æ€§è½½å…¥å³å¯é«˜æ•ˆéšæœºè®¿é—®ï¼Œéå¸¸é€‚åˆå¤§è§„æ¨¡è®­ç»ƒæ•°æ®ã€‚\n",
    "- **é›¶æ‹·è´ç®¡é“**ï¼šå¸¸ç”¨çš„ `map`ã€`filter`ã€`shuffle` æ“ä½œç›´æ¥ä½œç”¨äº Arrow ç¼“å†²åŒºï¼Œå‡å°‘ Python å±‚å¾ªç¯ä¸åºåˆ—åŒ–æˆæœ¬ï¼Œå¹¶èƒ½æ›´å¿«åœ°åœ¨ CPU/GPU ä¹‹é—´ä¼ è¾“ã€‚\n",
    "- **è·¨è¯­è¨€ç”Ÿæ€**ï¼šArrow æ ‡å‡†è¢« Pandasã€PySparkã€DuckDB ç­‰å·¥å…·å¤ç”¨ï¼Œ`.arrow` æ–‡ä»¶å¯ä»¥è¢«å…¶ä»–æ•°æ®å·¥ç¨‹ç»„ä»¶ç›´æ¥è¯»å–ï¼Œåˆ©äºä¸ä¸‹æ¸¸æµç¨‹å¯¹æ¥ã€‚\n",
    "- **ç»Ÿä¸€ç‰¹å¾å®šä¹‰**ï¼šæ— è®ºåŸå§‹æ˜¯å›¾åƒã€æ–‡æœ¬è¿˜æ˜¯ç»“æ„åŒ–è¡¨ï¼ŒArrow ä¼šè¿åŒ `dataset_info.json` ä¸€èµ·ä¿å­˜ schema å’Œå…ƒæ•°æ®ï¼›å›¾åƒç‰¹å¾ä¼šå¼•ç”¨ç¼“å­˜ä¸­çš„å®é™…æ–‡ä»¶è·¯å¾„æˆ–å­—èŠ‚æµï¼Œå…¼é¡¾å¯è¯»æ€§ä¸æ€§èƒ½ã€‚\n",
    "\n",
    "å› æ­¤ï¼Œæˆ‘ä»¬åŒæ—¶ä¿ç•™ç¼“å­˜ä¸ç£ç›˜å‰¯æœ¬ï¼šç¼“å­˜ä¿è¯é‡å¤åŠ è½½æ—¶æ— éœ€é‡æ–°ä¸‹è½½ï¼Œç£ç›˜å‰¯æœ¬åˆ™ä¾¿äºå…±äº«ã€å¤‡ä»½å’Œç‰ˆæœ¬åŒ–ç®¡ç†ã€‚"
   ],
   "id": "537dce37e7ee4667"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¯»å– `data-00000-of-00001.arrow` çš„ç¤ºä¾‹\n",
    "\n",
    "`dataset/Cat_and_Dog/train` ä¸­çš„ Arrow æ–‡ä»¶å­˜å‚¨äº†è®­ç»ƒ split çš„æ‰€æœ‰æ ·æœ¬ã€‚ä¸‹é¢æ¼”ç¤ºå‡ ç§å¸¸è§çš„è®¿é—®æ–¹å¼ã€‚"
   ],
   "id": "c25d0d72005b6207"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path('~/PycharmProjects/DeepLearning').expanduser()\n",
    "train_ds = load_from_disk(root / 'dataset/Cat_and_Dog')['train']\n",
    "train_ds"
   ],
   "id": "4ad211fd7c60add2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ä½¿ç”¨ `dataset[0]['image']` ç›´æ¥æ‹¿åˆ° `PIL.Image`\n",
    "\n",
    "ğŸ¤— Datasets ä¼šè‡ªåŠ¨è§£ç  `Image` ç‰¹å¾ã€‚æˆ‘ä»¬å¯ä»¥ç›´æ¥è·å– PIL å¯¹è±¡æˆ–è½¬ Tensorï¼š"
   ],
   "id": "9caa6fbc61d041a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "sample = train_ds[0]  # è®¿é—®ç¬¬ 0 ä¸ªæ ·æœ¬, å¯ä»¥ç›´æ¥è·å–å›¾ç‰‡å’Œæ ‡ç­¾\n",
    "pil_image = sample['image']  # ç›´æ¥è·å– PIL å›¾ç‰‡\n",
    "label = sample['labels']  # ç›´æ¥è·å–æ ‡ç­¾\n",
    "tensor_image = transforms.ToTensor()(pil_image)  # è½¬æ¢ä¸º Tensor\n",
    "label, pil_image, tensor_image.shape"
   ],
   "id": "53cbeb8593e7857"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ä¿å­˜æ ·æœ¬åˆ°ç£ç›˜\n",
    "\n",
    "éœ€è¦å°† Arrow ä¸­çš„å›¾ç‰‡å¯¼å‡ºæˆ PNG/JPEGï¼Œå¯ç”¨ PIL ä¿å­˜ï¼š"
   ],
   "id": "2b8d48b9de34b282"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = root / 'dataset' / 'export_train_images'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for idx in range(5):  # ç¤ºä¾‹å¯¼å‡ºå‰ 5 å¼ \n",
    "    sample = train_ds[idx]\n",
    "    img = sample['image']\n",
    "    label = sample['labels']\n",
    "    img.save(output_dir / f'{idx}_{label}.png')"
   ],
   "id": "2a70bffd98e059e5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. è½¬ä¸º PyTorch / TensorFlow / NumPy dataloader\n",
    "\n",
    "ğŸ¤— Datasets å†…ç½® `with_format` ä¸ `to_tf_dataset` ç­‰æ–¹æ³•ï¼Œå¯ç›´æ¥è½¬æˆæ¡†æ¶å…¼å®¹çš„è¿­ä»£å™¨ã€‚ä¸‹é¢å±•ç¤º PyTorch å†™æ³•ï¼š"
   ],
   "id": "f9fbd792e595f437"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_pt = train_ds.with_format('torch')\n",
    "batch = train_pt[:4]\n",
    "batch['image'].shape, batch['labels']"
   ],
   "id": "d9dbe3b2c8460a2b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. åˆ©ç”¨ `map` æ‰¹é‡å¤„ç†\n",
    "\n",
    "å¯ä»¥ä½¿ç”¨ `map` åœ¨ Arrow å±‚åšæ‰¹é‡å¤„ç†ï¼Œå¹¶é…åˆ `batched=True` åŠ é€Ÿã€‚ç¤ºä¾‹ï¼šä¸ºå›¾ç‰‡æ·»åŠ éšæœºç¿»è½¬åå†å†™å›ç£ç›˜ã€‚"
   ],
   "id": "6afad6e1de9532fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomHorizontalFlip\n",
    "\n",
    "flip = RandomHorizontalFlip(p=1.0)\n",
    "\n",
    "def augment(batch):\n",
    "    images = [flip(img) for img in batch['image']]\n",
    "    batch['image'] = images\n",
    "    return batch\n",
    "\n",
    "aug_ds = train_ds.map(augment, batched=True, batch_size=32)\n",
    "aug_ds"
   ],
   "id": "613911d8f4673f7f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **æ³¨æ„**ï¼šæ‰€æœ‰æ–¹æ³•æœ€ç»ˆéƒ½æ˜¯é€šè¿‡ ğŸ¤— Datasets è¯»å– Arrow æ–‡ä»¶ï¼›æ— éœ€è‡ªè¡Œè§£æäºŒè¿›åˆ¶å†…å®¹ï¼Œä»è€Œä¿æŒå®‰å…¨ä¸é«˜æ•ˆã€‚"
   ],
   "id": "79c9c3a33823e285"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å¸¸è§æ•°æ®åŠ è½½æ–¹æ¡ˆå¯¹æ¯”\n",
    "\n",
    "| æ¥æº | åº•å±‚æ ¼å¼ | å…¸å‹å…¥å£ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| ğŸ¤— Datasets | Apache Arrowï¼ˆ`*.arrow` + å…ƒæ•°æ®ï¼‰ | `datasets.load_dataset` / `load_from_disk` | æ”¯æŒæ‡’åŠ è½½ã€çŸ¢é‡åŒ– `map`ã€è‡ªåŠ¨è§£ç å¤šæ¨¡æ€ç‰¹å¾ï¼›è·¨è¯­è¨€ç”Ÿæ€å¥½ | éœ€è¦å¿«é€Ÿè¿­ä»£ã€è·¨æ¡†æ¶å…±äº«çš„å¤§è§„æ¨¡æ•°æ® |\n",
    "| torchvision.datasets | åŸå§‹æ–‡ä»¶ï¼ˆPNG/JPEGã€äºŒè¿›åˆ¶æ‰¹æ¬¡ç­‰ï¼‰ | `torchvision.datasets.CIFAR10` ç­‰ | ç›´æ¥è¿”å› `(PIL | Tensor, label)`ï¼Œä¸ `DataLoader` æ— ç¼è¡”æ¥ï¼›é€šå¸¸å†…ç½®ä¸‹è½½è„šæœ¬ | ä¼ ç»Ÿ CV ä»»åŠ¡ï¼Œä¾èµ– PyTorch ç”Ÿæ€ |\n",
    "| torchtext / torchaudio | æ–‡æœ¬ï¼šåŸå§‹è¯­æ–™ï¼›éŸ³é¢‘ï¼šwav/flac | `torchtext.datasets.AG_NEWS` ç­‰ | é’ˆå¯¹ç‰¹å®šæ¨¡æ€å®šåˆ¶å¤„ç†æµæ°´çº¿ | NLP / éŸ³é¢‘ä»»åŠ¡ |\n",
    "| è‡ªå®šä¹‰æ–‡ä»¶å¤¹ | JPG/PNG + è‡ªå®šä¹‰æ ‡ç­¾ | `ImageFolder` / `Dataset` å­ç±» | æœ€å¤§è‡ªç”±åº¦ï¼Œéœ€è¦è‡ªè¡Œç»´æŠ¤ç¼“å­˜/ç´¢å¼• | ä¼ä¸šå†…éƒ¨ç§æœ‰æ•°æ® |\n",
    "\n",
    "**å…³é”®å·®å¼‚**ï¼šğŸ¤— Datasets å€šèµ– Arrow æä¾›ç»Ÿä¸€ schema ä¸é«˜æ•ˆç®¡é“ï¼›`torchvision.datasets` ç­‰ä¼ ç»Ÿæ¥å£æ›´è´´è¿‘ PyTorch `Dataset`/`DataLoader` è¯­ä¹‰ï¼Œç›´æ¥å›´ç»•æ–‡ä»¶å¤¹æˆ–å‹ç¼©åŒ…æ„å»ºã€‚ä¸¤è€…å¯ä»¥äº’è½¬ï¼šArrow æ•°æ®ç»è¿‡ `with_format('torch')` å¯ç›´æ¥å¡å…¥ `DataLoader`ï¼Œ`torchvision` æ•°æ®ä¹Ÿèƒ½è½¬æˆ `Dataset.from_dict` å†æ¨åˆ° Hugging Face Hubã€‚"
   ],
   "id": "18f6357456a24738"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchvision.datasets ç¤ºä¾‹\n",
    "\n",
    "ä»¥ä¸‹ä»£ç æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ `torchvision.datasets.CIFAR10` è¯»å–æ•°æ®ã€‚è¿è¡Œæ—¶å¦‚æœ¬åœ°æ— ç¼“å­˜ä¼šè‡ªåŠ¨ä¸‹è½½ï¼š"
   ],
   "id": "ddf0d3a6d71c4fd6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "cifar_train = CIFAR10(root=root / 'torchvision_data', train=True, download=False, transform=transform)\n",
    "len(cifar_train), cifar_train[0][0].shape, cifar_train.classes[:5]"
   ],
   "id": "af1c8cd1b5aa474e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### äº’æ“ä½œå»ºè®®\n",
    "\n",
    "- å¦‚æœå·²æœ‰ Arrow æ•°æ®ï¼Œéœ€è¦åœ¨ PyTorch ä¸­è®­ç»ƒï¼Œå¯é€šè¿‡ `with_format('torch')` æˆ– `set_format` ç›´æ¥è¿”å› Tensorã€‚\n",
    "- è‹¥è¦æŠŠ torchvision æ•°æ®é›†ä¸Šä¼ åˆ° Hugging Face Hubï¼Œå¯éå† `Dataset`ï¼Œè½¬æˆ `datasets.Dataset.from_dict` æˆ– `Dataset.from_generator`ã€‚\n",
    "- å¤§å‹é¡¹ç›®é€šå¸¸å°†åŸå§‹æ–‡ä»¶å­˜ä¸€ä»½ï¼ˆä¾¿äºå¤ç°ï¼‰ï¼Œå†æ´¾ç”Ÿå‡º Arrow / TFRecord / LMDB ç­‰å¤šç§æ ¼å¼ï¼Œè§†è®­ç»ƒç®¡é“é€‰æ‹©å¯¹åº”åŠ è½½å™¨ã€‚"
   ],
   "id": "0a6f7a1618f24d95"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}