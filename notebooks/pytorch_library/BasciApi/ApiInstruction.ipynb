{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7cc069d",
   "metadata": {},
   "source": [
    "# PyTorch API 导航与专题笔记映射\n",
    "\n",
    "> 本文档按照官方 Python API 分类罗列核心模块，并为每个主题给出学习重点及对应的专题笔记（`Torch_rl.ipynb`、`Torch_rec.ipynb`、`Torch_codec.ipynb`、`Torch_vision.ipynb`、`Torch_data.ipynb`、`Torch_tune.ipynb`、`Torch_audio.ipynb`）能提供的辅助说明，方便按需查阅。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e06e76",
   "metadata": {},
   "source": [
    "## 1. 核心张量与神经网络构建\n",
    "### 1.1 torch / torch.Tensor\n",
    "- **内容**：Tensor 创建、运算、自动广播、装置迁移、张量属性视图。\n",
    "- **专题帮助**：\n",
    "  - `Torch_vision.ipynb` 在图像变换中大量使用 Tensor 操作。\n",
    "  - `Torch_audio.ipynb` 展示音频张量的 resample、feature 提取。\n",
    "  - `Torch_rl.ipynb` 的环境交互与策略网络均基于 TensorDict/Tensor。\n",
    "\n",
    "### 1.2 torch.nn / torch.nn.functional / torch.nn.init / torch.nn.attention\n",
    "- **内容**：网络模块、激活层、损失函数、参数初始化、多头注意力。\n",
    "- **专题帮助**：\n",
    "  - `Torch_tune.ipynb` 讲解 LLM 微调时的 LoRA/QLoRA 模块，依赖 nn 子模块。\n",
    "  - `Torch_rl.ipynb` 构建策略/价值网络使用 nn.Module。\n",
    "  - `Torch_vision.ipynb` 中的模型与 transforms 结合。\n",
    "\n",
    "### 1.3 torch.autograd / torch.func / torch.amp / torch.random\n",
    "- **内容**：自动求导、函数变换、自动混合精度、随机数控制。\n",
    "- **专题帮助**：\n",
    "  - `Torch_tune.ipynb` 涉及混合精度与梯度控制（LoRA/QAT）。\n",
    "  - `Torch_data.ipynb` 讲解 StatefulDataLoader 时涉及随机种子。\n",
    "  - `Torch_rl.ipynb` 中 DQN 训练演示 backprop 流程。\n",
    "\n",
    "### 1.4 torch.linalg / torch.fft / torch.special / torch.signal\n",
    "- **内容**：线性代数、FFT、特殊函数、信号处理。\n",
    "- **专题帮助**：\n",
    "  - `Torch_audio.ipynb` 使用 `torch.signal`/`torch.fft` 进行频域变换。\n",
    "  - `Torch_vision.ipynb` 的图像特征提取可能引用特殊函数。\n",
    "\n",
    "### 1.5 torch.sparse / torch.nested / torch.masked\n",
    "- **内容**：稀疏张量、嵌套张量、掩码运算。\n",
    "- **专题帮助**：\n",
    "  - `Torch_rec.ipynb` 使用 `KeyedJaggedTensor`/稀疏嵌入，与稀疏 API 关系密切。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ae17ca",
   "metadata": {},
   "source": [
    "## 2. 优化、训练与推理工具\n",
    "### 2.1 torch.optim / torch.optim.lr_scheduler\n",
    "- **内容**：优化器、学习率调度。\n",
    "- **专题帮助**：\n",
    "  - `Torch_rl.ipynb` DQN 示例使用 Adam 优化器。\n",
    "  - `Torch_tune.ipynb` 微调流程涉及自定义优化器设置。\n",
    "\n",
    "### 2.2 torch.profiler / torch.utils.benchmark / bottleneck\n",
    "- **内容**：性能分析工具。\n",
    "- **专题帮助**：\n",
    "  - `Torch_rec.ipynb` 提到 TorchRec 的性能优化，可结合 profiler 使用。\n",
    "  - `Torch_data.ipynb` 中 `nodes` 性能对比可借助 benchmark 工具。\n",
    "\n",
    "### 2.3 torch.jit / torch.export / torch.onnx / torch.package\n",
    "- **内容**：模型导出、编译、ONNX、打包。\n",
    "- **专题帮助**：\n",
    "  - `Torch_rec.ipynb` 推理部分介绍 TorchScript/TorchCodec 集成。\n",
    "  - `Torch_audio.ipynb` 提到 TorchCodec 与 torch.onnx 结合。\n",
    "  - `Torch_tune.ipynb` 中 LoRA 模型上线可能需要 TorchScript。\n",
    "\n",
    "### 2.4 torch.compile / torch.fx / torch.fx.experimental\n",
    "- **内容**：动态图追踪、编译优化。\n",
    "- **专题帮助**：\n",
    "  - `Torch_vision.ipynb` 处理 pipelines 时可使用 FX 转换。\n",
    "  - `Torch_tune.ipynb` 中模型优化（QLoRA/QAT）可结合 compile。\n",
    "\n",
    "### 2.5 torch.utils.checkpoint / torch.utils.deterministic\n",
    "- **内容**：梯度检查点、省内存训练、确定性控制。\n",
    "- **专题帮助**：\n",
    "  - `Torch_tune.ipynb` 的内存优化章节（LoRA/QAT）可结合 checkpoint。\n",
    "  - `Torch_rec.ipynb` 在大型推荐模型中常用 checkpoint。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b4615a",
   "metadata": {},
   "source": [
    "## 3. 设备与加速\n",
    "### 3.1 torch.cuda / torch.cuda.memory / torch.nn.parallel\n",
    "- **内容**：CUDA 设备管理、显存监控、数据并行。\n",
    "- **专题帮助**：\n",
    "  - `Torch_rec.ipynb` 深度讨论 FBGEMM、分布式。\n",
    "  - `Torch_tune.ipynb` 介绍 QAT/LoRA 的 GPU 需求。\n",
    "  - `Torch_audio.ipynb` 与 `Torch_vision.ipynb` 都涉及 CUDA transforms。\n",
    "\n",
    "### 3.2 torch.mps / torch.xpu / torch.mtia\n",
    "- **内容**：Apple MPS、Intel XPU、Meta Training Inference Accelerator。\n",
    "- **专题帮助**：\n",
    "  - `Torch_tune.ipynb` 可扩展至 MPS/XPU 上做轻量微调。\n",
    "  - `Torch_audio.ipynb` 需关注 MPS 对音频处理的支持情况。\n",
    "\n",
    "### 3.3 Meta device\n",
    "- **内容**：Meta (虚拟) 设备，用于延迟初始化。\n",
    "- **专题帮助**：\n",
    "  - `Torch_rec.ipynb` 中分片初始化时使用 `device='meta'`。\n",
    "  - `Torch_tune.ipynb` LLM 模型初始化可能借助 meta 设备降低显存需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71558fa2",
   "metadata": {},
   "source": [
    "## 4. 分布式与集群\n",
    "### 4.1 torch.distributed / torch.distributed.rpc / distributed.elastic\n",
    "- **内容**：分布式训练、RPC、弹性训练。\n",
    "- **专题帮助**：\n",
    "  - `Torch_rec.ipynb` 主要强调 `torch.distributed` 与 FSDP/Fully Shard。\n",
    "  - `Torch_tune.ipynb` 提及多节点微调、FSDP 配置。\n",
    "\n",
    "### 4.2 torch.distributed.fsdp / fsdp.fully_shard / tensor parallel\n",
    "- **内容**：FSDP、完全分片、张量并行。\n",
    "- **专题帮助**：\n",
    "  - `Torch_tune.ipynb` 的多 GPU 微调部分。\n",
    "  - `Torch_rec.ipynb` 描述 ShardedEmbeddingCollection。\n",
    "\n",
    "### 4.3 torch.distributed.checkpoint / torch.distributed.optim\n",
    "- **内容**：分布式检查点、优化器。\n",
    "- **专题帮助**：\n",
    "  - `Torch_tune.ipynb` 讲解断点与继续训练策略。\n",
    "  - `Torch_data.ipynb` 中 StatefulDataLoader 状态保存可结合 checkpoint。\n",
    "\n",
    "### 4.4 torch.distributed.tensor / join / piplined parallel\n",
    "- **内容**：张量并行、Join 算法、流水线并行。\n",
    "- **专题帮助**：\n",
    "  - `Torch_tune.ipynb` 涉及 LLM 大模型训练。\n",
    "  - `Torch_rec.ipynb` 在大规模模型中可考虑流水线。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c96e50e",
   "metadata": {},
   "source": [
    "## 5. 模块化生态\n",
    "### 5.1 torch.utils.data / torch.data\n",
    "- **内容**：数据集、DataLoader、异步加载。\n",
    "- **专题帮助**：\n",
    "  - `Torch_data.ipynb` 详解 TorchData 的 nodes/StatefulDataLoader。\n",
    "  - `Torch_tune.ipynb` 使用 Hugging Face 数据集需结合 DataLoader。\n",
    "\n",
    "### 5.2 torch.utils.tensorboard / torch.utils.module_tracker\n",
    "- **内容**：日志记录、模块追踪。\n",
    "- **专题帮助**：\n",
    "  - `Torch_tune.ipynb` 记录训练指标。\n",
    "  - `Torch_rl.ipynb` 可用 tensorboard 记录奖励曲线。\n",
    "\n",
    "### 5.3 torch.utils.mobile_optimizer / torch.package\n",
    "- **内容**：移动端优化、模型打包。\n",
    "- **专题帮助**：\n",
    "  - `Torch_vision.ipynb` 模型部署场景。\n",
    "  - `Torch_audio.ipynb` 音频模型部署。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eca2cc",
   "metadata": {},
   "source": [
    "## 6. 专题 API\n",
    "### 6.1 torch.fx / torch.hub / torch.hub.load\n",
    "- **内容**：模型转换、预训练模型拉取。\n",
    "- **专题帮助**：\n",
    "  - `Torch_vision.ipynb` 通过 hub 加载 torchvision 模型。\n",
    "  - `Torch_tune.ipynb` 使用 FX 做 LoRA 权重注入。\n",
    "\n",
    "### 6.2 torch.profiler / torch.monitor\n",
    "- **内容**：监控、性能剖析。\n",
    "- **专题帮助**：\n",
    "  - `Torch_rec.ipynb` 性能瓶颈分析。\n",
    "  - `Torch_data.ipynb` 关注 nodes 性能。\n",
    "\n",
    "### 6.3 torch.distributions / torch.special\n",
    "- **内容**：分布对象、概率函数。\n",
    "- **专题帮助**：\n",
    "  - `Torch_rl.ipynb` 策略分布（categorical/gaussian）。\n",
    "  - `Torch_tune.ipynb` LLM 生成策略（采样/概率）。\n",
    "\n",
    "### 6.4 torch.onnx / torch._dynamo / torch.compiler\n",
    "- **内容**：ONNX 导出、编译器内核（torch.compile）。\n",
    "- **专题帮助**：\n",
    "  - `Torch_rec.ipynb` 大表模型导出需求。\n",
    "  - `Torch_tune.ipynb` 结合 torch.compile 提升推理效率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93cfe45",
   "metadata": {},
   "source": [
    "## 7. 调试与日志\n",
    "### 7.1 torch._logging / torch._logging.set_logs\n",
    "- **内容**：内部日志等级配置。\n",
    "- **专题帮助**：\n",
    "  - `Torch_data.ipynb` 调试 `nodes` pipeline 日志。\n",
    "  - `Torch_rec.ipynb` 调整 planner 输出。\n",
    "\n",
    "### 7.2 环境变量 (Threads/CUDA/MPS/Debug)\n",
    "- **内容**：线程数、CUDA 调试、MPS 配置。\n",
    "- **专题帮助**：\n",
    "  - `Torch_tune.ipynb` 提示多 GPU/多节点环境变量。\n",
    "  - `Torch_audio.ipynb` 在 CUDA/MPS 上跑音频模型需参考。\n",
    "\n",
    "### 7.3 torch.__config__ / torch.__future__\n",
    "- **内容**：编译配置、未来行为控制。\n",
    "- **专题帮助**：\n",
    "  - `Torch_rec.ipynb` 关注与 FBGEMM/FSDP 的选项。\n",
    "  - `Torch_tune.ipynb` 可检查编译器配置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8276389",
   "metadata": {},
   "source": [
    "## 8. 复合主题索引\n",
    "- **TorchVision (`Torch_vision.ipynb`)**：关注 `torchvision` + 核心 API（Tensor、nn、transforms、onnx、compile）。\n",
    "- **TorchAudio (`Torch_audio.ipynb`)**：关注 `torchaudio.functional / transforms` + FFT/signal、Tensor 等。\n",
    "- **TorchRec (`Torch_rec.ipynb`)**：深入 `torch.distributed`、稀疏张量、优化器、TorchScript。\n",
    "- **TorchData (`Torch_data.ipynb`)**：聚焦 `torch.utils.data`、`torchdata.nodes`、StatefulDataLoader。\n",
    "- **TorchTune (`Torch_tune.ipynb`)**：LLM 微调，涉及 `torch.nn`, `torch.optim`, `distributed`, `amp`, `compiler`。\n",
    "- **TorchRL (`Torch_rl.ipynb`)**：重度使用 `torch.nn`, `torch.distributions`, `torch.utils.data`, `torch.fx`。\n",
    "- **TorchCodec (`Torch_codec.ipynb`)**：音视频编解码，与 `torch.onnx`, `torch.jit`, `torch.package` 相连。\n",
    "\n",
    "> 使用建议：先根据任务定位对应专题笔记，再结合本导航深入具体 API 文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9138f",
   "metadata": {},
   "source": [
    "## 9. 附录：torch API 速查清单\n",
    "\n",
    "- 数据来源：本地 PyTorch 安装路径 `/home/seeback/.conda/envs/DeepLearning/lib/python3.11/site-packages/torch`，可通过 `python - <<'PY'` + `help(torch.xxx)` / `inspect.getsource` 追踪实现。\n",
    "- 使用建议：结合上方导航快速定位模块，必要时进入源码阅读，遵循 KISS/YAGNI —— 只在调试或扩展时深入细节。\n",
    "- 为避免重复维护，本清单直接同步官方公开 API 名称；配合 `Torch_*` 专题笔记理解上下文。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbf5192",
   "metadata": {},
   "source": [
    "```text\n",
    "torch\n",
    "torch.is_tensor\n",
    "torch.is_storage\n",
    "torch.is_complex\n",
    "torch.is_conj\n",
    "torch.is_floating_point\n",
    "torch.is_nonzero\n",
    "torch.set_default_dtype\n",
    "torch.get_default_dtype\n",
    "torch.set_default_device\n",
    "torch.get_default_device\n",
    "torch.set_default_tensor_type\n",
    "torch.numel\n",
    "torch.set_printoptions\n",
    "torch.set_flush_denormal\n",
    "torch.tensor\n",
    "torch.sparse_coo_tensor\n",
    "torch.sparse_csr_tensor\n",
    "torch.sparse_csc_tensor\n",
    "torch.sparse_bsr_tensor\n",
    "torch.sparse_bsc_tensor\n",
    "torch.asarray\n",
    "torch.as_tensor\n",
    "torch.as_strided\n",
    "torch.from_file\n",
    "torch.from_numpy\n",
    "torch.from_dlpack\n",
    "torch.frombuffer\n",
    "torch.zeros\n",
    "torch.zeros_like\n",
    "torch.ones\n",
    "torch.ones_like\n",
    "torch.arange\n",
    "torch.range\n",
    "torch.linspace\n",
    "torch.logspace\n",
    "torch.eye\n",
    "torch.empty\n",
    "torch.empty_like\n",
    "torch.empty_strided\n",
    "torch.full\n",
    "torch.full_like\n",
    "torch.quantize_per_tensor\n",
    "torch.quantize_per_channel\n",
    "torch.dequantize\n",
    "torch.complex\n",
    "torch.polar\n",
    "torch.heaviside\n",
    "torch.adjoint\n",
    "torch.argwhere\n",
    "torch.cat\n",
    "torch.concat\n",
    "torch.concatenate\n",
    "torch.conj\n",
    "torch.chunk\n",
    "torch.dsplit\n",
    "torch.column_stack\n",
    "torch.dstack\n",
    "torch.gather\n",
    "torch.hsplit\n",
    "torch.hstack\n",
    "torch.index_add\n",
    "torch.index_copy\n",
    "torch.index_reduce\n",
    "torch.index_select\n",
    "torch.masked_select\n",
    "torch.movedim\n",
    "torch.moveaxis\n",
    "torch.narrow\n",
    "torch.narrow_copy\n",
    "torch.nonzero\n",
    "torch.permute\n",
    "torch.reshape\n",
    "torch.row_stack\n",
    "torch.select\n",
    "torch.scatter\n",
    "torch.diagonal_scatter\n",
    "torch.select_scatter\n",
    "torch.slice_scatter\n",
    "torch.scatter_add\n",
    "torch.scatter_reduce\n",
    "torch.segment_reduce\n",
    "torch.split\n",
    "torch.squeeze\n",
    "torch.stack\n",
    "torch.swapaxes\n",
    "torch.swapdims\n",
    "torch.t\n",
    "torch.take\n",
    "torch.take_along_dim\n",
    "torch.tensor_split\n",
    "torch.tile\n",
    "torch.transpose\n",
    "torch.unbind\n",
    "torch.unravel_index\n",
    "torch.unsqueeze\n",
    "torch.vsplit\n",
    "torch.vstack\n",
    "torch.where\n",
    "Stream\n",
    "Event\n",
    "Generator\n",
    "torch.seed\n",
    "torch.manual_seed\n",
    "torch.initial_seed\n",
    "torch.get_rng_state\n",
    "torch.set_rng_state\n",
    "torch.bernoulli\n",
    "torch.multinomial\n",
    "torch.normal\n",
    "torch.poisson\n",
    "torch.rand\n",
    "torch.rand_like\n",
    "torch.randint\n",
    "torch.randint_like\n",
    "torch.randn\n",
    "torch.randn_like\n",
    "torch.randperm\n",
    "SobolEngine\n",
    "torch.save\n",
    "torch.load\n",
    "torch.get_num_threads\n",
    "torch.set_num_threads\n",
    "torch.get_num_interop_threads\n",
    "torch.set_num_interop_threads\n",
    "no_grad\n",
    "enable_grad\n",
    "set_grad_enabled\n",
    "torch.is_grad_enabled\n",
    "inference_mode\n",
    "torch.is_inference_mode_enabled\n",
    "torch.abs\n",
    "torch.absolute\n",
    "torch.acos\n",
    "torch.arccos\n",
    "torch.acosh\n",
    "torch.arccosh\n",
    "torch.add\n",
    "torch.addcdiv\n",
    "torch.addcmul\n",
    "torch.angle\n",
    "torch.asin\n",
    "torch.arcsin\n",
    "torch.asinh\n",
    "torch.arcsinh\n",
    "torch.atan\n",
    "torch.arctan\n",
    "torch.atanh\n",
    "torch.arctanh\n",
    "torch.atan2\n",
    "torch.arctan2\n",
    "torch.bitwise_not\n",
    "torch.bitwise_and\n",
    "torch.bitwise_or\n",
    "torch.bitwise_xor\n",
    "torch.bitwise_left_shift\n",
    "torch.bitwise_right_shift\n",
    "torch.ceil\n",
    "torch.clamp\n",
    "torch.clip\n",
    "torch.conj_physical\n",
    "torch.copysign\n",
    "torch.cos\n",
    "torch.cosh\n",
    "torch.deg2rad\n",
    "torch.div\n",
    "torch.divide\n",
    "torch.digamma\n",
    "torch.erf\n",
    "torch.erfc\n",
    "torch.erfinv\n",
    "torch.exp\n",
    "torch.exp2\n",
    "torch.expm1\n",
    "torch.fake_quantize_per_channel_affine\n",
    "torch.fake_quantize_per_tensor_affine\n",
    "torch.fix\n",
    "torch.float_power\n",
    "torch.floor\n",
    "torch.floor_divide\n",
    "torch.fmod\n",
    "torch.frac\n",
    "torch.frexp\n",
    "torch.gradient\n",
    "torch.imag\n",
    "torch.ldexp\n",
    "torch.lerp\n",
    "torch.lgamma\n",
    "torch.log\n",
    "torch.log10\n",
    "torch.log1p\n",
    "torch.log2\n",
    "torch.logaddexp\n",
    "torch.logaddexp2\n",
    "torch.logical_and\n",
    "torch.logical_not\n",
    "torch.logical_or\n",
    "torch.logical_xor\n",
    "torch.logit\n",
    "torch.hypot\n",
    "torch.i0\n",
    "torch.igamma\n",
    "torch.igammac\n",
    "torch.mul\n",
    "torch.multiply\n",
    "torch.mvlgamma\n",
    "torch.nan_to_num\n",
    "torch.neg\n",
    "torch.negative\n",
    "torch.nextafter\n",
    "torch.polygamma\n",
    "torch.positive\n",
    "torch.pow\n",
    "torch.quantized_batch_norm\n",
    "torch.quantized_max_pool1d\n",
    "torch.quantized_max_pool2d\n",
    "torch.rad2deg\n",
    "torch.real\n",
    "torch.reciprocal\n",
    "torch.remainder\n",
    "torch.round\n",
    "torch.rsqrt\n",
    "torch.sigmoid\n",
    "torch.sign\n",
    "torch.sgn\n",
    "torch.signbit\n",
    "torch.sin\n",
    "torch.sinc\n",
    "torch.sinh\n",
    "torch.softmax\n",
    "torch.sqrt\n",
    "torch.square\n",
    "torch.sub\n",
    "torch.subtract\n",
    "torch.tan\n",
    "torch.tanh\n",
    "torch.true_divide\n",
    "torch.trunc\n",
    "torch.xlogy\n",
    "torch.argmax\n",
    "torch.argmin\n",
    "torch.amax\n",
    "torch.amin\n",
    "torch.aminmax\n",
    "torch.all\n",
    "torch.any\n",
    "torch.max\n",
    "torch.min\n",
    "torch.dist\n",
    "torch.logsumexp\n",
    "torch.mean\n",
    "torch.nanmean\n",
    "torch.median\n",
    "torch.nanmedian\n",
    "torch.mode\n",
    "torch.norm\n",
    "torch.nansum\n",
    "torch.prod\n",
    "torch.quantile\n",
    "torch.nanquantile\n",
    "torch.std\n",
    "torch.std_mean\n",
    "torch.sum\n",
    "torch.unique\n",
    "torch.unique_consecutive\n",
    "torch.var\n",
    "torch.var_mean\n",
    "torch.count_nonzero\n",
    "torch.hash_tensor\n",
    "torch.allclose\n",
    "torch.argsort\n",
    "torch.eq\n",
    "torch.equal\n",
    "torch.ge\n",
    "torch.greater_equal\n",
    "torch.gt\n",
    "torch.greater\n",
    "torch.isclose\n",
    "torch.isfinite\n",
    "torch.isin\n",
    "torch.isinf\n",
    "torch.isposinf\n",
    "torch.isneginf\n",
    "torch.isnan\n",
    "torch.isreal\n",
    "torch.kthvalue\n",
    "torch.le\n",
    "torch.less_equal\n",
    "torch.lt\n",
    "torch.less\n",
    "torch.maximum\n",
    "torch.minimum\n",
    "torch.fmax\n",
    "torch.fmin\n",
    "torch.ne\n",
    "torch.not_equal\n",
    "torch.sort\n",
    "torch.topk\n",
    "torch.msort\n",
    "torch.stft\n",
    "torch.istft\n",
    "torch.bartlett_window\n",
    "torch.blackman_window\n",
    "torch.hamming_window\n",
    "torch.hann_window\n",
    "torch.kaiser_window\n",
    "torch.atleast_1d\n",
    "torch.atleast_2d\n",
    "torch.atleast_3d\n",
    "torch.bincount\n",
    "torch.block_diag\n",
    "torch.broadcast_tensors\n",
    "torch.broadcast_to\n",
    "torch.broadcast_shapes\n",
    "torch.bucketize\n",
    "torch.cartesian_prod\n",
    "torch.cdist\n",
    "torch.clone\n",
    "torch.combinations\n",
    "torch.corrcoef\n",
    "torch.cov\n",
    "torch.cross\n",
    "torch.cummax\n",
    "torch.cummin\n",
    "torch.cumprod\n",
    "torch.cumsum\n",
    "torch.diag\n",
    "torch.diag_embed\n",
    "torch.diagflat\n",
    "torch.diagonal\n",
    "torch.diff\n",
    "torch.einsum\n",
    "torch.flatten\n",
    "torch.flip\n",
    "torch.fliplr\n",
    "torch.flipud\n",
    "torch.kron\n",
    "torch.rot90\n",
    "torch.gcd\n",
    "torch.histc\n",
    "torch.histogram\n",
    "torch.histogramdd\n",
    "torch.meshgrid\n",
    "torch.lcm\n",
    "torch.logcumsumexp\n",
    "torch.ravel\n",
    "torch.renorm\n",
    "torch.repeat_interleave\n",
    "torch.roll\n",
    "torch.searchsorted\n",
    "torch.tensordot\n",
    "torch.trace\n",
    "torch.tril\n",
    "torch.tril_indices\n",
    "torch.triu\n",
    "torch.triu_indices\n",
    "torch.unflatten\n",
    "torch.vander\n",
    "torch.view_as_real\n",
    "torch.view_as_complex\n",
    "torch.resolve_conj\n",
    "torch.resolve_neg\n",
    "torch.addbmm\n",
    "torch.addmm\n",
    "torch.addmv\n",
    "torch.addr\n",
    "torch.baddbmm\n",
    "torch.bmm\n",
    "torch.chain_matmul\n",
    "torch.cholesky\n",
    "torch.cholesky_inverse\n",
    "torch.cholesky_solve\n",
    "torch.dot\n",
    "torch.geqrf\n",
    "torch.ger\n",
    "torch.inner\n",
    "torch.inverse\n",
    "torch.det\n",
    "torch.logdet\n",
    "torch.slogdet\n",
    "torch.lu\n",
    "torch.lu_solve\n",
    "torch.lu_unpack\n",
    "torch.matmul\n",
    "torch.matrix_power\n",
    "torch.matrix_exp\n",
    "torch.mm\n",
    "torch.mv\n",
    "torch.orgqr\n",
    "torch.ormqr\n",
    "torch.outer\n",
    "torch.pinverse\n",
    "torch.qr\n",
    "torch.svd\n",
    "torch.svd_lowrank\n",
    "torch.pca_lowrank\n",
    "torch.lobpcg\n",
    "torch.trapz\n",
    "torch.trapezoid\n",
    "torch.cumulative_trapezoid\n",
    "torch.triangular_solve\n",
    "torch.vdot\n",
    "torch._foreach_abs\n",
    "torch._foreach_abs_\n",
    "torch._foreach_acos\n",
    "torch._foreach_acos_\n",
    "torch._foreach_asin\n",
    "torch._foreach_asin_\n",
    "torch._foreach_atan\n",
    "torch._foreach_atan_\n",
    "torch._foreach_ceil\n",
    "torch._foreach_ceil_\n",
    "torch._foreach_cos\n",
    "torch._foreach_cos_\n",
    "torch._foreach_cosh\n",
    "torch._foreach_cosh_\n",
    "torch._foreach_erf\n",
    "torch._foreach_erf_\n",
    "torch._foreach_erfc\n",
    "torch._foreach_erfc_\n",
    "torch._foreach_exp\n",
    "torch._foreach_exp_\n",
    "torch._foreach_expm1\n",
    "torch._foreach_expm1_\n",
    "torch._foreach_floor\n",
    "torch._foreach_floor_\n",
    "torch._foreach_log\n",
    "torch._foreach_log_\n",
    "torch._foreach_log10\n",
    "torch._foreach_log10_\n",
    "torch._foreach_log1p\n",
    "torch._foreach_log1p_\n",
    "torch._foreach_log2\n",
    "torch._foreach_log2_\n",
    "torch._foreach_neg\n",
    "torch._foreach_neg_\n",
    "torch._foreach_tan\n",
    "torch._foreach_tan_\n",
    "torch._foreach_sin\n",
    "torch._foreach_sin_\n",
    "torch._foreach_sinh\n",
    "torch._foreach_sinh_\n",
    "torch._foreach_round\n",
    "torch._foreach_round_\n",
    "torch._foreach_sqrt\n",
    "torch._foreach_sqrt_\n",
    "torch._foreach_lgamma\n",
    "torch._foreach_lgamma_\n",
    "torch._foreach_frac\n",
    "torch._foreach_frac_\n",
    "torch._foreach_reciprocal\n",
    "torch._foreach_reciprocal_\n",
    "torch._foreach_sigmoid\n",
    "torch._foreach_sigmoid_\n",
    "torch._foreach_trunc\n",
    "torch._foreach_trunc_\n",
    "torch._foreach_zero_\n",
    "torch.compiled_with_cxx11_abi\n",
    "torch.result_type\n",
    "torch.can_cast\n",
    "torch.promote_types\n",
    "torch.use_deterministic_algorithms\n",
    "torch.are_deterministic_algorithms_enabled\n",
    "torch.is_deterministic_algorithms_warn_only_enabled\n",
    "torch.set_deterministic_debug_mode\n",
    "torch.get_deterministic_debug_mode\n",
    "torch.set_float32_matmul_precision\n",
    "torch.get_float32_matmul_precision\n",
    "torch.set_warn_always\n",
    "torch.get_device_module\n",
    "torch.is_warn_always_enabled\n",
    "torch.vmap\n",
    "torch._assert\n",
    "torch.sym_float\n",
    "torch.sym_fresh_size\n",
    "torch.sym_int\n",
    "torch.sym_max\n",
    "torch.sym_min\n",
    "torch.sym_not\n",
    "torch.sym_ite\n",
    "torch.sym_sum\n",
    "torch.cond\n",
    "torch.compile\n",
    "Aliases in torch\n",
    "torch.functional.align_tensors\n",
    "torch.functional.atleast_1d\n",
    "torch.functional.atleast_2d\n",
    "torch.functional.atleast_3d\n",
    "torch.functional.block_diag\n",
    "torch.functional.broadcast_shapes\n",
    "torch.functional.broadcast_tensors\n",
    "torch.functional.cartesian_prod\n",
    "torch.functional.cdist\n",
    "torch.functional.chain_matmul\n",
    "torch.functional.einsum\n",
    "torch.functional.lu\n",
    "torch.functional.meshgrid\n",
    "torch.functional.norm\n",
    "torch.functional.split\n",
    "torch.functional.stft\n",
    "torch.functional.tensordot\n",
    "torch.functional.unique\n",
    "torch.functional.unique_consecutive\n",
    "torch.functional.unravel_index\n",
    "Aliases in torch.nn\n",
    "Sequential\n",
    "ModuleList\n",
    "ModuleDict\n",
    "ParameterList\n",
    "ParameterDict\n",
    "Conv1d\n",
    "Conv2d\n",
    "Conv3d\n",
    "ConvTranspose1d\n",
    "ConvTranspose2d\n",
    "ConvTranspose3d\n",
    "LazyConv1d\n",
    "LazyConv2d\n",
    "LazyConv3d\n",
    "LazyConvTranspose1d\n",
    "LazyConvTranspose2d\n",
    "LazyConvTranspose3d\n",
    "Unfold\n",
    "Fold\n",
    "MaxPool1d\n",
    "MaxPool2d\n",
    "MaxPool3d\n",
    "MaxUnpool1d\n",
    "MaxUnpool2d\n",
    "MaxUnpool3d\n",
    "AvgPool1d\n",
    "AvgPool2d\n",
    "AvgPool3d\n",
    "FractionalMaxPool2d\n",
    "FractionalMaxPool3d\n",
    "LPPool1d\n",
    "LPPool2d\n",
    "LPPool3d\n",
    "AdaptiveMaxPool1d\n",
    "AdaptiveMaxPool2d\n",
    "AdaptiveMaxPool3d\n",
    "AdaptiveAvgPool1d\n",
    "AdaptiveAvgPool2d\n",
    "AdaptiveAvgPool3d\n",
    "ReflectionPad1d\n",
    "ReflectionPad2d\n",
    "ReflectionPad3d\n",
    "ReplicationPad1d\n",
    "ReplicationPad2d\n",
    "ReplicationPad3d\n",
    "ZeroPad1d\n",
    "ZeroPad2d\n",
    "ZeroPad3d\n",
    "ConstantPad1d\n",
    "ConstantPad2d\n",
    "ConstantPad3d\n",
    "CircularPad1d\n",
    "CircularPad2d\n",
    "CircularPad3d\n",
    "ELU\n",
    "Hardshrink\n",
    "Hardsigmoid\n",
    "Hardtanh\n",
    "Hardswish\n",
    "LeakyReLU\n",
    "LogSigmoid\n",
    "MultiheadAttention\n",
    "PReLU\n",
    "ReLU\n",
    "ReLU6\n",
    "RReLU\n",
    "SELU\n",
    "CELU\n",
    "GELU\n",
    "Sigmoid\n",
    "SiLU\n",
    "Mish\n",
    "Softplus\n",
    "Softshrink\n",
    "Softsign\n",
    "Tanh\n",
    "Tanhshrink\n",
    "Threshold\n",
    "GLU\n",
    "Softmin\n",
    "Softmax\n",
    "Softmax2d\n",
    "LogSoftmax\n",
    "AdaptiveLogSoftmaxWithLoss\n",
    "BatchNorm1d\n",
    "BatchNorm2d\n",
    "BatchNorm3d\n",
    "LazyBatchNorm1d\n",
    "LazyBatchNorm2d\n",
    "LazyBatchNorm3d\n",
    "GroupNorm\n",
    "SyncBatchNorm\n",
    "InstanceNorm1d\n",
    "InstanceNorm2d\n",
    "InstanceNorm3d\n",
    "LazyInstanceNorm1d\n",
    "LazyInstanceNorm2d\n",
    "LazyInstanceNorm3d\n",
    "LayerNorm\n",
    "LocalResponseNorm\n",
    "RMSNorm\n",
    "RNNBase\n",
    "RNN\n",
    "LSTM\n",
    "GRU\n",
    "RNNCell\n",
    "LSTMCell\n",
    "GRUCell\n",
    "Transformer\n",
    "TransformerEncoder\n",
    "TransformerDecoder\n",
    "TransformerEncoderLayer\n",
    "TransformerDecoderLayer\n",
    "Identity\n",
    "Linear\n",
    "Bilinear\n",
    "LazyLinear\n",
    "Dropout\n",
    "Dropout1d\n",
    "Dropout2d\n",
    "Dropout3d\n",
    "AlphaDropout\n",
    "FeatureAlphaDropout\n",
    "Embedding\n",
    "EmbeddingBag\n",
    "CosineSimilarity\n",
    "PairwiseDistance\n",
    "L1Loss\n",
    "MSELoss\n",
    "CrossEntropyLoss\n",
    "CTCLoss\n",
    "NLLLoss\n",
    "PoissonNLLLoss\n",
    "GaussianNLLLoss\n",
    "KLDivLoss\n",
    "BCELoss\n",
    "BCEWithLogitsLoss\n",
    "MarginRankingLoss\n",
    "HingeEmbeddingLoss\n",
    "MultiLabelMarginLoss\n",
    "HuberLoss\n",
    "SmoothL1Loss\n",
    "SoftMarginLoss\n",
    "MultiLabelSoftMarginLoss\n",
    "CosineEmbeddingLoss\n",
    "MultiMarginLoss\n",
    "TripletMarginLoss\n",
    "TripletMarginWithDistanceLoss\n",
    "PixelShuffle\n",
    "PixelUnshuffle\n",
    "Upsample\n",
    "UpsamplingNearest2d\n",
    "UpsamplingBilinear2d\n",
    "ChannelShuffle\n",
    "torch.nn.utils.clip_grad.clip_grad_norm_\n",
    "torch.nn.utils.clip_grad.clip_grad_norm\n",
    "torch.nn.utils.clip_grad.clip_grad_value_\n",
    "torch.nn.utils.convert_parameters.parameters_to_vector\n",
    "torch.nn.utils.convert_parameters.vector_to_parameters\n",
    "torch.nn.utils.fusion.fuse_conv_bn_eval\n",
    "torch.nn.utils.fusion.fuse_conv_bn_weights\n",
    "torch.nn.utils.fusion.fuse_linear_bn_eval\n",
    "torch.nn.utils.fusion.fuse_linear_bn_weights\n",
    "torch.nn.utils.memory_format.convert_conv2d_weight_memory_format\n",
    "torch.nn.utils.memory_format.convert_conv3d_weight_memory_format\n",
    "torch.nn.utils.weight_norm.weight_norm\n",
    "torch.nn.utils.weight_norm.remove_weight_norm\n",
    "torch.nn.utils.spectral_norm.spectral_norm\n",
    "torch.nn.utils.spectral_norm.remove_spectral_norm\n",
    "torch.nn.utils.init.skip_init\n",
    "torch.nn\n",
    "Buffer\n",
    "Parameter\n",
    "UninitializedParameter\n",
    "UninitializedBuffer\n",
    "Module\n",
    "Sequential\n",
    "ModuleList\n",
    "ModuleDict\n",
    "ParameterList\n",
    "ParameterDict\n",
    "torch.nn.modules.module.register_module_forward_pre_hook\n",
    "torch.nn.modules.module.register_module_forward_hook\n",
    "torch.nn.modules.module.register_module_backward_hook\n",
    "torch.nn.modules.module.register_module_full_backward_pre_hook\n",
    "torch.nn.modules.module.register_module_full_backward_hook\n",
    "torch.nn.modules.module.register_module_buffer_registration_hook\n",
    "torch.nn.modules.module.register_module_module_registration_hook\n",
    "torch.nn.modules.module.register_module_parameter_registration_hook\n",
    "Conv1d\n",
    "Conv2d\n",
    "Conv3d\n",
    "ConvTranspose1d\n",
    "ConvTranspose2d\n",
    "ConvTranspose3d\n",
    "LazyConv1d\n",
    "LazyConv2d\n",
    "LazyConv3d\n",
    "LazyConvTranspose1d\n",
    "LazyConvTranspose2d\n",
    "LazyConvTranspose3d\n",
    "Unfold\n",
    "Fold\n",
    "MaxPool1d\n",
    "MaxPool2d\n",
    "MaxPool3d\n",
    "MaxUnpool1d\n",
    "MaxUnpool2d\n",
    "MaxUnpool3d\n",
    "AvgPool1d\n",
    "AvgPool2d\n",
    "AvgPool3d\n",
    "FractionalMaxPool2d\n",
    "FractionalMaxPool3d\n",
    "LPPool1d\n",
    "LPPool2d\n",
    "LPPool3d\n",
    "AdaptiveMaxPool1d\n",
    "AdaptiveMaxPool2d\n",
    "AdaptiveMaxPool3d\n",
    "AdaptiveAvgPool1d\n",
    "AdaptiveAvgPool2d\n",
    "AdaptiveAvgPool3d\n",
    "ReflectionPad1d\n",
    "ReflectionPad2d\n",
    "ReflectionPad3d\n",
    "ReplicationPad1d\n",
    "ReplicationPad2d\n",
    "ReplicationPad3d\n",
    "ZeroPad1d\n",
    "ZeroPad2d\n",
    "ZeroPad3d\n",
    "ConstantPad1d\n",
    "ConstantPad2d\n",
    "ConstantPad3d\n",
    "CircularPad1d\n",
    "CircularPad2d\n",
    "CircularPad3d\n",
    "ELU\n",
    "Hardshrink\n",
    "Hardsigmoid\n",
    "Hardtanh\n",
    "Hardswish\n",
    "LeakyReLU\n",
    "LogSigmoid\n",
    "MultiheadAttention\n",
    "PReLU\n",
    "ReLU\n",
    "ReLU6\n",
    "RReLU\n",
    "SELU\n",
    "CELU\n",
    "GELU\n",
    "Sigmoid\n",
    "SiLU\n",
    "Mish\n",
    "Softplus\n",
    "Softshrink\n",
    "Softsign\n",
    "Tanh\n",
    "Tanhshrink\n",
    "Threshold\n",
    "GLU\n",
    "Softmin\n",
    "Softmax\n",
    "Softmax2d\n",
    "LogSoftmax\n",
    "AdaptiveLogSoftmaxWithLoss\n",
    "BatchNorm1d\n",
    "BatchNorm2d\n",
    "BatchNorm3d\n",
    "LazyBatchNorm1d\n",
    "LazyBatchNorm2d\n",
    "LazyBatchNorm3d\n",
    "GroupNorm\n",
    "SyncBatchNorm\n",
    "InstanceNorm1d\n",
    "InstanceNorm2d\n",
    "InstanceNorm3d\n",
    "LazyInstanceNorm1d\n",
    "LazyInstanceNorm2d\n",
    "LazyInstanceNorm3d\n",
    "LayerNorm\n",
    "LocalResponseNorm\n",
    "RMSNorm\n",
    "RNNBase\n",
    "RNN\n",
    "LSTM\n",
    "GRU\n",
    "RNNCell\n",
    "LSTMCell\n",
    "GRUCell\n",
    "Transformer\n",
    "TransformerEncoder\n",
    "TransformerDecoder\n",
    "TransformerEncoderLayer\n",
    "TransformerDecoderLayer\n",
    "Identity\n",
    "Linear\n",
    "Bilinear\n",
    "LazyLinear\n",
    "Dropout\n",
    "Dropout1d\n",
    "Dropout2d\n",
    "Dropout3d\n",
    "AlphaDropout\n",
    "FeatureAlphaDropout\n",
    "Embedding\n",
    "EmbeddingBag\n",
    "CosineSimilarity\n",
    "PairwiseDistance\n",
    "L1Loss\n",
    "MSELoss\n",
    "CrossEntropyLoss\n",
    "CTCLoss\n",
    "NLLLoss\n",
    "PoissonNLLLoss\n",
    "GaussianNLLLoss\n",
    "KLDivLoss\n",
    "BCELoss\n",
    "BCEWithLogitsLoss\n",
    "MarginRankingLoss\n",
    "HingeEmbeddingLoss\n",
    "MultiLabelMarginLoss\n",
    "HuberLoss\n",
    "SmoothL1Loss\n",
    "SoftMarginLoss\n",
    "MultiLabelSoftMarginLoss\n",
    "CosineEmbeddingLoss\n",
    "MultiMarginLoss\n",
    "TripletMarginLoss\n",
    "TripletMarginWithDistanceLoss\n",
    "PixelShuffle\n",
    "PixelUnshuffle\n",
    "Upsample\n",
    "UpsamplingNearest2d\n",
    "UpsamplingBilinear2d\n",
    "ChannelShuffle\n",
    "DataParallel\n",
    "DistributedDataParallel\n",
    "torch.nn.utils.clip_grad_norm_\n",
    "torch.nn.utils.clip_grad_norm\n",
    "torch.nn.utils.clip_grad_value_\n",
    "torch.nn.utils.get_total_norm\n",
    "torch.nn.utils.clip_grads_with_norm_\n",
    "torch.nn.utils.parameters_to_vector\n",
    "torch.nn.utils.vector_to_parameters\n",
    "torch.nn.utils.fuse_conv_bn_eval\n",
    "torch.nn.utils.fuse_conv_bn_weights\n",
    "torch.nn.utils.fuse_linear_bn_eval\n",
    "torch.nn.utils.fuse_linear_bn_weights\n",
    "torch.nn.utils.convert_conv2d_weight_memory_format\n",
    "torch.nn.utils.convert_conv3d_weight_memory_format\n",
    "torch.nn.utils.weight_norm\n",
    "torch.nn.utils.remove_weight_norm\n",
    "torch.nn.utils.spectral_norm\n",
    "torch.nn.utils.remove_spectral_norm\n",
    "torch.nn.utils.skip_init\n",
    "BasePruningMethod\n",
    "PruningContainer\n",
    "Identity\n",
    "RandomUnstructured\n",
    "L1Unstructured\n",
    "RandomStructured\n",
    "LnStructured\n",
    "CustomFromMask\n",
    "torch.nn.utils.prune.identity\n",
    "torch.nn.utils.prune.random_unstructured\n",
    "torch.nn.utils.prune.l1_unstructured\n",
    "torch.nn.utils.prune.random_structured\n",
    "torch.nn.utils.prune.ln_structured\n",
    "torch.nn.utils.prune.global_unstructured\n",
    "torch.nn.utils.prune.custom_from_mask\n",
    "torch.nn.utils.prune.remove\n",
    "torch.nn.utils.prune.is_pruned\n",
    "torch.nn.utils.parametrizations.orthogonal\n",
    "torch.nn.utils.parametrizations.weight_norm\n",
    "torch.nn.utils.parametrizations.spectral_norm\n",
    "torch.nn.utils.parametrize.register_parametrization\n",
    "torch.nn.utils.parametrize.remove_parametrizations\n",
    "torch.nn.utils.parametrize.cached\n",
    "torch.nn.utils.parametrize.is_parametrized\n",
    "torch.nn.utils.parametrize.transfer_parametrizations_and_params\n",
    "torch.nn.utils.parametrize.type_before_parametrizations\n",
    "ParametrizationList\n",
    "torch.nn.utils.stateless.functional_call\n",
    "PackedSequence\n",
    "torch.nn.utils.rnn.pack_padded_sequence\n",
    "torch.nn.utils.rnn.pad_packed_sequence\n",
    "torch.nn.utils.rnn.pad_sequence\n",
    "torch.nn.utils.rnn.pack_sequence\n",
    "torch.nn.utils.rnn.unpack_sequence\n",
    "torch.nn.utils.rnn.unpad_sequence\n",
    "torch.nn.utils.rnn.invert_permutation\n",
    "torch.nn.parameter.is_lazy\n",
    "torch.nn.factory_kwargs\n",
    "Flatten\n",
    "Unflatten\n",
    "LazyModuleMixin\n",
    "torch.nn.functional\n",
    "torch.nn.functional.conv1d\n",
    "torch.nn.functional.conv2d\n",
    "torch.nn.functional.conv3d\n",
    "torch.nn.functional.conv_transpose1d\n",
    "torch.nn.functional.conv_transpose2d\n",
    "torch.nn.functional.conv_transpose3d\n",
    "torch.nn.functional.unfold\n",
    "torch.nn.functional.fold\n",
    "torch.nn.functional.avg_pool1d\n",
    "torch.nn.functional.avg_pool2d\n",
    "torch.nn.functional.avg_pool3d\n",
    "torch.nn.functional.max_pool1d\n",
    "torch.nn.functional.max_pool2d\n",
    "torch.nn.functional.max_pool3d\n",
    "torch.nn.functional.max_unpool1d\n",
    "torch.nn.functional.max_unpool2d\n",
    "torch.nn.functional.max_unpool3d\n",
    "torch.nn.functional.lp_pool1d\n",
    "torch.nn.functional.lp_pool2d\n",
    "torch.nn.functional.lp_pool3d\n",
    "torch.nn.functional.adaptive_max_pool1d\n",
    "torch.nn.functional.adaptive_max_pool2d\n",
    "torch.nn.functional.adaptive_max_pool3d\n",
    "torch.nn.functional.adaptive_avg_pool1d\n",
    "torch.nn.functional.adaptive_avg_pool2d\n",
    "torch.nn.functional.adaptive_avg_pool3d\n",
    "torch.nn.functional.fractional_max_pool2d\n",
    "torch.nn.functional.fractional_max_pool3d\n",
    "torch.nn.functional.scaled_dot_product_attention\n",
    "torch.nn.functional.threshold\n",
    "torch.nn.functional.threshold_\n",
    "torch.nn.functional.relu\n",
    "torch.nn.functional.relu_\n",
    "torch.nn.functional.hardtanh\n",
    "torch.nn.functional.hardtanh_\n",
    "torch.nn.functional.hardswish\n",
    "torch.nn.functional.relu6\n",
    "torch.nn.functional.elu\n",
    "torch.nn.functional.elu_\n",
    "torch.nn.functional.selu\n",
    "torch.nn.functional.celu\n",
    "torch.nn.functional.leaky_relu\n",
    "torch.nn.functional.leaky_relu_\n",
    "torch.nn.functional.prelu\n",
    "torch.nn.functional.rrelu\n",
    "torch.nn.functional.rrelu_\n",
    "torch.nn.functional.glu\n",
    "torch.nn.functional.gelu\n",
    "torch.nn.functional.logsigmoid\n",
    "torch.nn.functional.hardshrink\n",
    "torch.nn.functional.tanhshrink\n",
    "torch.nn.functional.softsign\n",
    "torch.nn.functional.softplus\n",
    "torch.nn.functional.softmin\n",
    "torch.nn.functional.softmax\n",
    "torch.nn.functional.softshrink\n",
    "torch.nn.functional.gumbel_softmax\n",
    "torch.nn.functional.log_softmax\n",
    "torch.nn.functional.tanh\n",
    "torch.nn.functional.sigmoid\n",
    "torch.nn.functional.hardsigmoid\n",
    "torch.nn.functional.silu\n",
    "torch.nn.functional.mish\n",
    "torch.nn.functional.batch_norm\n",
    "torch.nn.functional.group_norm\n",
    "torch.nn.functional.instance_norm\n",
    "torch.nn.functional.layer_norm\n",
    "torch.nn.functional.local_response_norm\n",
    "torch.nn.functional.rms_norm\n",
    "torch.nn.functional.normalize\n",
    "torch.nn.functional.linear\n",
    "torch.nn.functional.bilinear\n",
    "torch.nn.functional.dropout\n",
    "torch.nn.functional.alpha_dropout\n",
    "torch.nn.functional.feature_alpha_dropout\n",
    "torch.nn.functional.dropout1d\n",
    "torch.nn.functional.dropout2d\n",
    "torch.nn.functional.dropout3d\n",
    "torch.nn.functional.embedding\n",
    "torch.nn.functional.embedding_bag\n",
    "torch.nn.functional.one_hot\n",
    "torch.nn.functional.pairwise_distance\n",
    "torch.nn.functional.cosine_similarity\n",
    "torch.nn.functional.pdist\n",
    "torch.nn.functional.binary_cross_entropy\n",
    "torch.nn.functional.binary_cross_entropy_with_logits\n",
    "torch.nn.functional.poisson_nll_loss\n",
    "torch.nn.functional.cosine_embedding_loss\n",
    "torch.nn.functional.cross_entropy\n",
    "torch.nn.functional.ctc_loss\n",
    "torch.nn.functional.gaussian_nll_loss\n",
    "torch.nn.functional.hinge_embedding_loss\n",
    "torch.nn.functional.kl_div\n",
    "torch.nn.functional.l1_loss\n",
    "torch.nn.functional.mse_loss\n",
    "torch.nn.functional.margin_ranking_loss\n",
    "torch.nn.functional.multilabel_margin_loss\n",
    "torch.nn.functional.multilabel_soft_margin_loss\n",
    "torch.nn.functional.multi_margin_loss\n",
    "torch.nn.functional.nll_loss\n",
    "torch.nn.functional.huber_loss\n",
    "torch.nn.functional.smooth_l1_loss\n",
    "torch.nn.functional.soft_margin_loss\n",
    "torch.nn.functional.triplet_margin_loss\n",
    "torch.nn.functional.triplet_margin_with_distance_loss\n",
    "torch.nn.functional.pixel_shuffle\n",
    "torch.nn.functional.pixel_unshuffle\n",
    "torch.nn.functional.pad\n",
    "torch.nn.functional.interpolate\n",
    "torch.nn.functional.upsample\n",
    "torch.nn.functional.upsample_nearest\n",
    "torch.nn.functional.upsample_bilinear\n",
    "torch.nn.functional.grid_sample\n",
    "torch.nn.functional.affine_grid\n",
    "torch.nn.functional.torch.nn.parallel.data_parallel\n",
    "torch.Tensor\n",
    "torch.Tensor.new_tensor\n",
    "torch.Tensor.new_full\n",
    "torch.Tensor.new_empty\n",
    "torch.Tensor.new_ones\n",
    "torch.Tensor.new_zeros\n",
    "torch.Tensor.is_cuda\n",
    "torch.Tensor.is_quantized\n",
    "torch.Tensor.is_meta\n",
    "torch.Tensor.device\n",
    "torch.Tensor.grad\n",
    "torch.Tensor.ndim\n",
    "torch.Tensor.real\n",
    "torch.Tensor.imag\n",
    "torch.Tensor.nbytes\n",
    "torch.Tensor.itemsize\n",
    "torch.Tensor.abs\n",
    "torch.Tensor.abs_\n",
    "torch.Tensor.absolute\n",
    "torch.Tensor.absolute_\n",
    "torch.Tensor.acos\n",
    "torch.Tensor.acos_\n",
    "torch.Tensor.arccos\n",
    "torch.Tensor.arccos_\n",
    "torch.Tensor.add\n",
    "torch.Tensor.add_\n",
    "torch.Tensor.addbmm\n",
    "torch.Tensor.addbmm_\n",
    "torch.Tensor.addcdiv\n",
    "torch.Tensor.addcdiv_\n",
    "torch.Tensor.addcmul\n",
    "torch.Tensor.addcmul_\n",
    "torch.Tensor.addmm\n",
    "torch.Tensor.addmm_\n",
    "torch.Tensor.sspaddmm\n",
    "torch.Tensor.addmv\n",
    "torch.Tensor.addmv_\n",
    "torch.Tensor.addr\n",
    "torch.Tensor.addr_\n",
    "torch.Tensor.adjoint\n",
    "torch.Tensor.allclose\n",
    "torch.Tensor.amax\n",
    "torch.Tensor.amin\n",
    "torch.Tensor.aminmax\n",
    "torch.Tensor.angle\n",
    "torch.Tensor.apply_\n",
    "torch.Tensor.argmax\n",
    "torch.Tensor.argmin\n",
    "torch.Tensor.argsort\n",
    "torch.Tensor.argwhere\n",
    "torch.Tensor.asin\n",
    "torch.Tensor.asin_\n",
    "torch.Tensor.arcsin\n",
    "torch.Tensor.arcsin_\n",
    "torch.Tensor.as_strided\n",
    "torch.Tensor.atan\n",
    "torch.Tensor.atan_\n",
    "torch.Tensor.arctan\n",
    "torch.Tensor.arctan_\n",
    "torch.Tensor.atan2\n",
    "torch.Tensor.atan2_\n",
    "torch.Tensor.arctan2\n",
    "torch.Tensor.arctan2_\n",
    "torch.Tensor.all\n",
    "torch.Tensor.any\n",
    "torch.Tensor.backward\n",
    "torch.Tensor.baddbmm\n",
    "torch.Tensor.baddbmm_\n",
    "torch.Tensor.bernoulli\n",
    "torch.Tensor.bernoulli_\n",
    "torch.Tensor.bfloat16\n",
    "torch.Tensor.bincount\n",
    "torch.Tensor.bitwise_not\n",
    "torch.Tensor.bitwise_not_\n",
    "torch.Tensor.bitwise_and\n",
    "torch.Tensor.bitwise_and_\n",
    "torch.Tensor.bitwise_or\n",
    "torch.Tensor.bitwise_or_\n",
    "torch.Tensor.bitwise_xor\n",
    "torch.Tensor.bitwise_xor_\n",
    "torch.Tensor.bitwise_left_shift\n",
    "torch.Tensor.bitwise_left_shift_\n",
    "torch.Tensor.bitwise_right_shift\n",
    "torch.Tensor.bitwise_right_shift_\n",
    "torch.Tensor.bmm\n",
    "torch.Tensor.bool\n",
    "torch.Tensor.byte\n",
    "torch.Tensor.broadcast_to\n",
    "torch.Tensor.cauchy_\n",
    "torch.Tensor.ceil\n",
    "torch.Tensor.ceil_\n",
    "torch.Tensor.char\n",
    "torch.Tensor.cholesky\n",
    "torch.Tensor.cholesky_inverse\n",
    "torch.Tensor.cholesky_solve\n",
    "torch.Tensor.chunk\n",
    "torch.Tensor.clamp\n",
    "torch.Tensor.clamp_\n",
    "torch.Tensor.clip\n",
    "torch.Tensor.clip_\n",
    "torch.Tensor.clone\n",
    "torch.Tensor.contiguous\n",
    "torch.Tensor.copy_\n",
    "torch.Tensor.conj\n",
    "torch.Tensor.conj_physical\n",
    "torch.Tensor.conj_physical_\n",
    "torch.Tensor.resolve_conj\n",
    "torch.Tensor.resolve_neg\n",
    "torch.Tensor.copysign\n",
    "torch.Tensor.copysign_\n",
    "torch.Tensor.cos\n",
    "torch.Tensor.cos_\n",
    "torch.Tensor.cosh\n",
    "torch.Tensor.cosh_\n",
    "torch.Tensor.corrcoef\n",
    "torch.Tensor.count_nonzero\n",
    "torch.Tensor.cov\n",
    "torch.Tensor.acosh\n",
    "torch.Tensor.acosh_\n",
    "torch.Tensor.arccosh\n",
    "torch.Tensor.arccosh_\n",
    "torch.Tensor.cpu\n",
    "torch.Tensor.cross\n",
    "torch.Tensor.cuda\n",
    "torch.Tensor.logcumsumexp\n",
    "torch.Tensor.cummax\n",
    "torch.Tensor.cummin\n",
    "torch.Tensor.cumprod\n",
    "torch.Tensor.cumprod_\n",
    "torch.Tensor.cumsum\n",
    "torch.Tensor.cumsum_\n",
    "torch.Tensor.chalf\n",
    "torch.Tensor.cfloat\n",
    "torch.Tensor.cdouble\n",
    "torch.Tensor.data_ptr\n",
    "torch.Tensor.deg2rad\n",
    "torch.Tensor.dequantize\n",
    "torch.Tensor.det\n",
    "torch.Tensor.dense_dim\n",
    "torch.Tensor.detach\n",
    "torch.Tensor.detach_\n",
    "torch.Tensor.diag\n",
    "torch.Tensor.diag_embed\n",
    "torch.Tensor.diagflat\n",
    "torch.Tensor.diagonal\n",
    "torch.Tensor.diagonal_scatter\n",
    "torch.Tensor.fill_diagonal_\n",
    "torch.Tensor.fmax\n",
    "torch.Tensor.fmin\n",
    "torch.Tensor.diff\n",
    "torch.Tensor.digamma\n",
    "torch.Tensor.digamma_\n",
    "torch.Tensor.dim\n",
    "torch.Tensor.dim_order\n",
    "torch.Tensor.dist\n",
    "torch.Tensor.div\n",
    "torch.Tensor.div_\n",
    "torch.Tensor.divide\n",
    "torch.Tensor.divide_\n",
    "torch.Tensor.dot\n",
    "torch.Tensor.double\n",
    "torch.Tensor.dsplit\n",
    "torch.Tensor.element_size\n",
    "torch.Tensor.eq\n",
    "torch.Tensor.eq_\n",
    "torch.Tensor.equal\n",
    "torch.Tensor.erf\n",
    "torch.Tensor.erf_\n",
    "torch.Tensor.erfc\n",
    "torch.Tensor.erfc_\n",
    "torch.Tensor.erfinv\n",
    "torch.Tensor.erfinv_\n",
    "torch.Tensor.exp\n",
    "torch.Tensor.exp_\n",
    "torch.Tensor.expm1\n",
    "torch.Tensor.expm1_\n",
    "torch.Tensor.expand\n",
    "torch.Tensor.expand_as\n",
    "torch.Tensor.exponential_\n",
    "torch.Tensor.fix\n",
    "torch.Tensor.fix_\n",
    "torch.Tensor.fill_\n",
    "torch.Tensor.flatten\n",
    "torch.Tensor.flip\n",
    "torch.Tensor.fliplr\n",
    "torch.Tensor.flipud\n",
    "torch.Tensor.float\n",
    "torch.Tensor.float_power\n",
    "torch.Tensor.float_power_\n",
    "torch.Tensor.floor\n",
    "torch.Tensor.floor_\n",
    "torch.Tensor.floor_divide\n",
    "torch.Tensor.floor_divide_\n",
    "torch.Tensor.fmod\n",
    "torch.Tensor.fmod_\n",
    "torch.Tensor.frac\n",
    "torch.Tensor.frac_\n",
    "torch.Tensor.frexp\n",
    "torch.Tensor.gather\n",
    "torch.Tensor.gcd\n",
    "torch.Tensor.gcd_\n",
    "torch.Tensor.ge\n",
    "torch.Tensor.ge_\n",
    "torch.Tensor.greater_equal\n",
    "torch.Tensor.greater_equal_\n",
    "torch.Tensor.geometric_\n",
    "torch.Tensor.geqrf\n",
    "torch.Tensor.ger\n",
    "torch.Tensor.get_device\n",
    "torch.Tensor.gt\n",
    "torch.Tensor.gt_\n",
    "torch.Tensor.greater\n",
    "torch.Tensor.greater_\n",
    "torch.Tensor.half\n",
    "torch.Tensor.hardshrink\n",
    "torch.Tensor.heaviside\n",
    "torch.Tensor.histc\n",
    "torch.Tensor.histogram\n",
    "torch.Tensor.hsplit\n",
    "torch.Tensor.hypot\n",
    "torch.Tensor.hypot_\n",
    "torch.Tensor.i0\n",
    "torch.Tensor.i0_\n",
    "torch.Tensor.igamma\n",
    "torch.Tensor.igamma_\n",
    "torch.Tensor.igammac\n",
    "torch.Tensor.igammac_\n",
    "torch.Tensor.index_add_\n",
    "torch.Tensor.index_add\n",
    "torch.Tensor.index_copy_\n",
    "torch.Tensor.index_copy\n",
    "torch.Tensor.index_fill_\n",
    "torch.Tensor.index_fill\n",
    "torch.Tensor.index_put_\n",
    "torch.Tensor.index_put\n",
    "torch.Tensor.index_reduce_\n",
    "torch.Tensor.index_reduce\n",
    "torch.Tensor.index_select\n",
    "torch.Tensor.indices\n",
    "torch.Tensor.inner\n",
    "torch.Tensor.int\n",
    "torch.Tensor.int_repr\n",
    "torch.Tensor.inverse\n",
    "torch.Tensor.isclose\n",
    "torch.Tensor.isfinite\n",
    "torch.Tensor.isinf\n",
    "torch.Tensor.isposinf\n",
    "torch.Tensor.isneginf\n",
    "torch.Tensor.isnan\n",
    "torch.Tensor.is_contiguous\n",
    "torch.Tensor.is_complex\n",
    "torch.Tensor.is_conj\n",
    "torch.Tensor.is_floating_point\n",
    "torch.Tensor.is_inference\n",
    "torch.Tensor.is_leaf\n",
    "torch.Tensor.is_pinned\n",
    "torch.Tensor.is_set_to\n",
    "torch.Tensor.is_shared\n",
    "torch.Tensor.is_signed\n",
    "torch.Tensor.is_sparse\n",
    "torch.Tensor.istft\n",
    "torch.Tensor.isreal\n",
    "torch.Tensor.item\n",
    "torch.Tensor.kthvalue\n",
    "torch.Tensor.lcm\n",
    "torch.Tensor.lcm_\n",
    "torch.Tensor.ldexp\n",
    "torch.Tensor.ldexp_\n",
    "torch.Tensor.le\n",
    "torch.Tensor.le_\n",
    "torch.Tensor.less_equal\n",
    "torch.Tensor.less_equal_\n",
    "torch.Tensor.lerp\n",
    "torch.Tensor.lerp_\n",
    "torch.Tensor.lgamma\n",
    "torch.Tensor.lgamma_\n",
    "torch.Tensor.log\n",
    "torch.Tensor.log_\n",
    "torch.Tensor.logdet\n",
    "torch.Tensor.log10\n",
    "torch.Tensor.log10_\n",
    "torch.Tensor.log1p\n",
    "torch.Tensor.log1p_\n",
    "torch.Tensor.log2\n",
    "torch.Tensor.log2_\n",
    "torch.Tensor.log_normal_\n",
    "torch.Tensor.logaddexp\n",
    "torch.Tensor.logaddexp2\n",
    "torch.Tensor.logsumexp\n",
    "torch.Tensor.logical_and\n",
    "torch.Tensor.logical_and_\n",
    "torch.Tensor.logical_not\n",
    "torch.Tensor.logical_not_\n",
    "torch.Tensor.logical_or\n",
    "torch.Tensor.logical_or_\n",
    "torch.Tensor.logical_xor\n",
    "torch.Tensor.logical_xor_\n",
    "torch.Tensor.logit\n",
    "torch.Tensor.logit_\n",
    "torch.Tensor.long\n",
    "torch.Tensor.lt\n",
    "torch.Tensor.lt_\n",
    "torch.Tensor.less\n",
    "torch.Tensor.less_\n",
    "torch.Tensor.lu\n",
    "torch.Tensor.lu_solve\n",
    "torch.Tensor.as_subclass\n",
    "torch.Tensor.map_\n",
    "torch.Tensor.masked_scatter_\n",
    "torch.Tensor.masked_scatter\n",
    "torch.Tensor.masked_fill_\n",
    "torch.Tensor.masked_fill\n",
    "torch.Tensor.masked_select\n",
    "torch.Tensor.matmul\n",
    "torch.Tensor.matrix_power\n",
    "torch.Tensor.matrix_exp\n",
    "torch.Tensor.max\n",
    "torch.Tensor.maximum\n",
    "torch.Tensor.mean\n",
    "torch.Tensor.module_load\n",
    "torch.Tensor.nanmean\n",
    "torch.Tensor.median\n",
    "torch.Tensor.nanmedian\n",
    "torch.Tensor.min\n",
    "torch.Tensor.minimum\n",
    "torch.Tensor.mm\n",
    "torch.Tensor.smm\n",
    "torch.Tensor.mode\n",
    "torch.Tensor.movedim\n",
    "torch.Tensor.moveaxis\n",
    "torch.Tensor.msort\n",
    "torch.Tensor.mul\n",
    "torch.Tensor.mul_\n",
    "torch.Tensor.multiply\n",
    "torch.Tensor.multiply_\n",
    "torch.Tensor.multinomial\n",
    "torch.Tensor.mv\n",
    "torch.Tensor.mvlgamma\n",
    "torch.Tensor.mvlgamma_\n",
    "torch.Tensor.nansum\n",
    "torch.Tensor.narrow\n",
    "torch.Tensor.narrow_copy\n",
    "torch.Tensor.ndimension\n",
    "torch.Tensor.nan_to_num\n",
    "torch.Tensor.nan_to_num_\n",
    "torch.Tensor.ne\n",
    "torch.Tensor.ne_\n",
    "torch.Tensor.not_equal\n",
    "torch.Tensor.not_equal_\n",
    "torch.Tensor.neg\n",
    "torch.Tensor.neg_\n",
    "torch.Tensor.negative\n",
    "torch.Tensor.negative_\n",
    "torch.Tensor.nelement\n",
    "torch.Tensor.nextafter\n",
    "torch.Tensor.nextafter_\n",
    "torch.Tensor.nonzero\n",
    "torch.Tensor.norm\n",
    "torch.Tensor.normal_\n",
    "torch.Tensor.numel\n",
    "torch.Tensor.numpy\n",
    "torch.Tensor.orgqr\n",
    "torch.Tensor.ormqr\n",
    "torch.Tensor.outer\n",
    "torch.Tensor.permute\n",
    "torch.Tensor.pin_memory\n",
    "torch.Tensor.pinverse\n",
    "torch.Tensor.polygamma\n",
    "torch.Tensor.polygamma_\n",
    "torch.Tensor.positive\n",
    "torch.Tensor.pow\n",
    "torch.Tensor.pow_\n",
    "torch.Tensor.prod\n",
    "torch.Tensor.put_\n",
    "torch.Tensor.qr\n",
    "torch.Tensor.qscheme\n",
    "torch.Tensor.quantile\n",
    "torch.Tensor.nanquantile\n",
    "torch.Tensor.q_scale\n",
    "torch.Tensor.q_zero_point\n",
    "torch.Tensor.q_per_channel_scales\n",
    "torch.Tensor.q_per_channel_zero_points\n",
    "torch.Tensor.q_per_channel_axis\n",
    "torch.Tensor.rad2deg\n",
    "torch.Tensor.random_\n",
    "torch.Tensor.ravel\n",
    "torch.Tensor.reciprocal\n",
    "torch.Tensor.reciprocal_\n",
    "torch.Tensor.record_stream\n",
    "torch.Tensor.register_hook\n",
    "torch.Tensor.register_post_accumulate_grad_hook\n",
    "torch.Tensor.remainder\n",
    "torch.Tensor.remainder_\n",
    "torch.Tensor.renorm\n",
    "torch.Tensor.renorm_\n",
    "torch.Tensor.repeat\n",
    "torch.Tensor.repeat_interleave\n",
    "torch.Tensor.requires_grad\n",
    "torch.Tensor.requires_grad_\n",
    "torch.Tensor.reshape\n",
    "torch.Tensor.reshape_as\n",
    "torch.Tensor.resize_\n",
    "torch.Tensor.resize_as_\n",
    "torch.Tensor.retain_grad\n",
    "torch.Tensor.retains_grad\n",
    "torch.Tensor.roll\n",
    "torch.Tensor.rot90\n",
    "torch.Tensor.round\n",
    "torch.Tensor.round_\n",
    "torch.Tensor.rsqrt\n",
    "torch.Tensor.rsqrt_\n",
    "torch.Tensor.scatter\n",
    "torch.Tensor.scatter_\n",
    "torch.Tensor.scatter_add_\n",
    "torch.Tensor.scatter_add\n",
    "torch.Tensor.scatter_reduce_\n",
    "torch.Tensor.scatter_reduce\n",
    "torch.Tensor.select\n",
    "torch.Tensor.select_scatter\n",
    "torch.Tensor.set_\n",
    "torch.Tensor.share_memory_\n",
    "torch.Tensor.short\n",
    "torch.Tensor.sigmoid\n",
    "torch.Tensor.sigmoid_\n",
    "torch.Tensor.sign\n",
    "torch.Tensor.sign_\n",
    "torch.Tensor.signbit\n",
    "torch.Tensor.sgn\n",
    "torch.Tensor.sgn_\n",
    "torch.Tensor.sin\n",
    "torch.Tensor.sin_\n",
    "torch.Tensor.sinc\n",
    "torch.Tensor.sinc_\n",
    "torch.Tensor.sinh\n",
    "torch.Tensor.sinh_\n",
    "torch.Tensor.asinh\n",
    "torch.Tensor.asinh_\n",
    "torch.Tensor.arcsinh\n",
    "torch.Tensor.arcsinh_\n",
    "torch.Tensor.shape\n",
    "torch.Tensor.size\n",
    "torch.Tensor.slogdet\n",
    "torch.Tensor.slice_scatter\n",
    "torch.Tensor.softmax\n",
    "torch.Tensor.sort\n",
    "torch.Tensor.split\n",
    "torch.Tensor.sparse_mask\n",
    "torch.Tensor.sparse_dim\n",
    "torch.Tensor.sqrt\n",
    "torch.Tensor.sqrt_\n",
    "torch.Tensor.square\n",
    "torch.Tensor.square_\n",
    "torch.Tensor.squeeze\n",
    "torch.Tensor.squeeze_\n",
    "torch.Tensor.std\n",
    "torch.Tensor.stft\n",
    "torch.Tensor.storage\n",
    "torch.Tensor.untyped_storage\n",
    "torch.Tensor.storage_offset\n",
    "torch.Tensor.storage_type\n",
    "torch.Tensor.stride\n",
    "torch.Tensor.sub\n",
    "torch.Tensor.sub_\n",
    "torch.Tensor.subtract\n",
    "torch.Tensor.subtract_\n",
    "torch.Tensor.sum\n",
    "torch.Tensor.sum_to_size\n",
    "torch.Tensor.svd\n",
    "torch.Tensor.swapaxes\n",
    "torch.Tensor.swapdims\n",
    "torch.Tensor.t\n",
    "torch.Tensor.t_\n",
    "torch.Tensor.tensor_split\n",
    "torch.Tensor.tile\n",
    "torch.Tensor.to\n",
    "torch.Tensor.to_mkldnn\n",
    "torch.Tensor.take\n",
    "torch.Tensor.take_along_dim\n",
    "torch.Tensor.tan\n",
    "torch.Tensor.tan_\n",
    "torch.Tensor.tanh\n",
    "torch.Tensor.tanh_\n",
    "torch.Tensor.atanh\n",
    "torch.Tensor.atanh_\n",
    "torch.Tensor.arctanh\n",
    "torch.Tensor.arctanh_\n",
    "torch.Tensor.tolist\n",
    "torch.Tensor.topk\n",
    "torch.Tensor.to_dense\n",
    "torch.Tensor.to_sparse\n",
    "torch.Tensor.to_sparse_csr\n",
    "torch.Tensor.to_sparse_csc\n",
    "torch.Tensor.to_sparse_bsr\n",
    "torch.Tensor.to_sparse_bsc\n",
    "torch.Tensor.trace\n",
    "torch.Tensor.transpose\n",
    "torch.Tensor.transpose_\n",
    "torch.Tensor.triangular_solve\n",
    "torch.Tensor.tril\n",
    "torch.Tensor.tril_\n",
    "torch.Tensor.triu\n",
    "torch.Tensor.triu_\n",
    "torch.Tensor.true_divide\n",
    "torch.Tensor.true_divide_\n",
    "torch.Tensor.trunc\n",
    "torch.Tensor.trunc_\n",
    "torch.Tensor.type\n",
    "torch.Tensor.type_as\n",
    "torch.Tensor.unbind\n",
    "torch.Tensor.unflatten\n",
    "torch.Tensor.unfold\n",
    "torch.Tensor.uniform_\n",
    "torch.Tensor.unique\n",
    "torch.Tensor.unique_consecutive\n",
    "torch.Tensor.unsqueeze\n",
    "torch.Tensor.unsqueeze_\n",
    "torch.Tensor.values\n",
    "torch.Tensor.var\n",
    "torch.Tensor.vdot\n",
    "torch.Tensor.view\n",
    "torch.Tensor.view_as\n",
    "torch.Tensor.vsplit\n",
    "torch.Tensor.where\n",
    "torch.Tensor.xlogy\n",
    "torch.Tensor.xlogy_\n",
    "torch.Tensor.xpu\n",
    "torch.Tensor.zero_\n",
    "Tensor Attributes\n",
    "Tensor Views\n",
    "torch.amp\n",
    "torch.autograd\n",
    "torch.autograd.backward\n",
    "torch.autograd.grad\n",
    "dual_level\n",
    "torch.autograd.forward_ad.make_dual\n",
    "torch.autograd.forward_ad.unpack_dual\n",
    "torch.autograd.forward_ad.enter_dual_level\n",
    "torch.autograd.forward_ad.exit_dual_level\n",
    "UnpackedDualTensor\n",
    "torch.autograd.functional.jacobian\n",
    "torch.autograd.functional.hessian\n",
    "torch.autograd.functional.vjp\n",
    "torch.autograd.functional.jvp\n",
    "torch.autograd.functional.vhp\n",
    "torch.autograd.functional.hvp\n",
    "torch.autograd.Function.forward\n",
    "torch.autograd.Function.backward\n",
    "torch.autograd.Function.jvp\n",
    "torch.autograd.Function.vmap\n",
    "torch.autograd.function.FunctionCtx.mark_dirty\n",
    "torch.autograd.function.FunctionCtx.mark_non_differentiable\n",
    "torch.autograd.function.FunctionCtx.save_for_backward\n",
    "torch.autograd.function.FunctionCtx.set_materialize_grads\n",
    "torch.autograd.function.once_differentiable\n",
    "BackwardCFunction\n",
    "InplaceFunction\n",
    "NestedIOFunction\n",
    "torch.autograd.gradcheck.gradcheck\n",
    "torch.autograd.gradcheck.gradgradcheck\n",
    "torch.autograd.gradcheck.GradcheckError\n",
    "torch.autograd.profiler.profile.export_chrome_trace\n",
    "torch.autograd.profiler.profile.key_averages\n",
    "torch.autograd.profiler.profile.self_cpu_time_total\n",
    "torch.autograd.profiler.profile.total_average\n",
    "torch.autograd.profiler.parse_nvprof_trace\n",
    "EnforceUnique\n",
    "KinetoStepTracker\n",
    "record_function\n",
    "Interval\n",
    "Kernel\n",
    "MemRecordsAcc\n",
    "StringTable\n",
    "torch.autograd.profiler.load_nvprof\n",
    "set_multithreading_enabled\n",
    "torch.autograd.graph.Node.name\n",
    "torch.autograd.graph.Node.metadata\n",
    "torch.autograd.graph.Node.next_functions\n",
    "torch.autograd.graph.Node.register_hook\n",
    "torch.autograd.graph.Node.register_prehook\n",
    "torch.autograd.graph.increment_version\n",
    "torch.library\n",
    "torch.accelerator\n",
    "torch.accelerator.device_count\n",
    "torch.accelerator.is_available\n",
    "torch.accelerator.current_accelerator\n",
    "torch.accelerator.set_device_index\n",
    "torch.accelerator.set_device_idx\n",
    "torch.accelerator.current_device_index\n",
    "torch.accelerator.current_device_idx\n",
    "torch.accelerator.set_stream\n",
    "torch.accelerator.current_stream\n",
    "torch.accelerator.synchronize\n",
    "device_index\n",
    "torch.accelerator.memory.empty_cache\n",
    "torch.accelerator.memory.max_memory_allocated\n",
    "torch.accelerator.memory.max_memory_reserved\n",
    "torch.accelerator.memory.memory_allocated\n",
    "torch.accelerator.memory.memory_reserved\n",
    "torch.accelerator.memory.memory_stats\n",
    "torch.accelerator.memory.reset_accumulated_memory_stats\n",
    "torch.accelerator.memory.reset_peak_memory_stats\n",
    "torch.cpu\n",
    "torch.cpu.current_device\n",
    "torch.cpu.current_stream\n",
    "torch.cpu.is_available\n",
    "torch.cpu.synchronize\n",
    "torch.cpu.stream\n",
    "torch.cpu.set_device\n",
    "torch.cpu.device_count\n",
    "StreamContext\n",
    "Stream\n",
    "torch.cuda\n",
    "StreamContext\n",
    "torch.cuda.can_device_access_peer\n",
    "torch.cuda.current_blas_handle\n",
    "torch.cuda.current_device\n",
    "torch.cuda.current_stream\n",
    "torch.cuda.cudart\n",
    "torch.cuda.default_stream\n",
    "device\n",
    "torch.cuda.device_count\n",
    "torch.cuda.device_memory_used\n",
    "device_of\n",
    "torch.cuda.get_arch_list\n",
    "torch.cuda.get_device_capability\n",
    "torch.cuda.get_device_name\n",
    "torch.cuda.get_device_properties\n",
    "torch.cuda.get_gencode_flags\n",
    "torch.cuda.get_stream_from_external\n",
    "torch.cuda.get_sync_debug_mode\n",
    "torch.cuda.init\n",
    "torch.cuda.ipc_collect\n",
    "torch.cuda.is_available\n",
    "torch.cuda.is_initialized\n",
    "torch.cuda.is_tf32_supported\n",
    "torch.cuda.memory_usage\n",
    "torch.cuda.set_device\n",
    "torch.cuda.set_stream\n",
    "torch.cuda.set_sync_debug_mode\n",
    "torch.cuda.stream\n",
    "torch.cuda.synchronize\n",
    "torch.cuda.utilization\n",
    "torch.cuda.temperature\n",
    "torch.cuda.power_draw\n",
    "torch.cuda.clock_rate\n",
    "torch.cuda.AcceleratorError\n",
    "torch.cuda.OutOfMemoryError\n",
    "torch.cuda.get_rng_state\n",
    "torch.cuda.get_rng_state_all\n",
    "torch.cuda.set_rng_state\n",
    "torch.cuda.set_rng_state_all\n",
    "torch.cuda.manual_seed\n",
    "torch.cuda.manual_seed_all\n",
    "torch.cuda.seed\n",
    "torch.cuda.seed_all\n",
    "torch.cuda.initial_seed\n",
    "torch.cuda.comm.broadcast\n",
    "torch.cuda.comm.broadcast_coalesced\n",
    "torch.cuda.comm.reduce_add\n",
    "torch.cuda.comm.reduce_add_coalesced\n",
    "torch.cuda.comm.scatter\n",
    "torch.cuda.comm.gather\n",
    "Stream\n",
    "ExternalStream\n",
    "Event\n",
    "torch.cuda.is_current_stream_capturing\n",
    "torch.cuda.graph_pool_handle\n",
    "CUDAGraph\n",
    "graph\n",
    "torch.cuda.make_graphed_callables\n",
    "torch.cuda.memory.empty_cache\n",
    "torch.cuda.memory.get_per_process_memory_fraction\n",
    "torch.cuda.memory.list_gpu_processes\n",
    "torch.cuda.memory.mem_get_info\n",
    "torch.cuda.memory.memory_stats\n",
    "torch.cuda.memory.memory_stats_as_nested_dict\n",
    "torch.cuda.memory.reset_accumulated_memory_stats\n",
    "torch.cuda.memory.host_memory_stats\n",
    "torch.cuda.memory.host_memory_stats_as_nested_dict\n",
    "torch.cuda.memory.reset_accumulated_host_memory_stats\n",
    "torch.cuda.memory.memory_allocated\n",
    "torch.cuda.memory.max_memory_allocated\n",
    "torch.cuda.memory.reset_max_memory_allocated\n",
    "torch.cuda.memory.memory_reserved\n",
    "torch.cuda.memory.max_memory_reserved\n",
    "torch.cuda.memory.set_per_process_memory_fraction\n",
    "torch.cuda.memory.memory_cached\n",
    "torch.cuda.memory.max_memory_cached\n",
    "torch.cuda.memory.reset_max_memory_cached\n",
    "torch.cuda.memory.reset_peak_memory_stats\n",
    "torch.cuda.memory.reset_peak_host_memory_stats\n",
    "torch.cuda.memory.caching_allocator_alloc\n",
    "torch.cuda.memory.caching_allocator_delete\n",
    "torch.cuda.memory.get_allocator_backend\n",
    "CUDAPluggableAllocator\n",
    "torch.cuda.memory.change_current_allocator\n",
    "MemPool\n",
    "torch.cuda.memory.caching_allocator_enable\n",
    "torch.cuda.nvtx.mark\n",
    "torch.cuda.nvtx.range_push\n",
    "torch.cuda.nvtx.range_pop\n",
    "torch.cuda.nvtx.range\n",
    "torch.cuda.jiterator._create_jit_fn\n",
    "torch.cuda.jiterator._create_multi_output_jit_fn\n",
    "TunableOp\n",
    "CUDA Stream Sanitizer\n",
    "torch.cuda.gds.gds_register_buffer\n",
    "torch.cuda.gds.gds_deregister_buffer\n",
    "GdsFile\n",
    "torch.cuda.memory\n",
    "torch.mps\n",
    "torch.mps.device_count\n",
    "torch.mps.synchronize\n",
    "torch.mps.get_rng_state\n",
    "torch.mps.set_rng_state\n",
    "torch.mps.manual_seed\n",
    "torch.mps.seed\n",
    "torch.mps.empty_cache\n",
    "torch.mps.set_per_process_memory_fraction\n",
    "torch.mps.current_allocated_memory\n",
    "torch.mps.driver_allocated_memory\n",
    "torch.mps.recommended_max_memory\n",
    "torch.mps.compile_shader\n",
    "torch.mps.profiler.start\n",
    "torch.mps.profiler.stop\n",
    "torch.mps.profiler.profile\n",
    "torch.mps.profiler.is_capturing_metal\n",
    "torch.mps.profiler.is_metal_capture_enabled\n",
    "torch.mps.profiler.metal_capture\n",
    "Event\n",
    "Stream\n",
    "torch.xpu\n",
    "StreamContext\n",
    "torch.xpu.current_device\n",
    "torch.xpu.current_stream\n",
    "device\n",
    "torch.xpu.device_count\n",
    "device_of\n",
    "torch.xpu.get_arch_list\n",
    "torch.xpu.get_device_capability\n",
    "torch.xpu.get_device_name\n",
    "torch.xpu.get_device_properties\n",
    "torch.xpu.get_gencode_flags\n",
    "torch.xpu.get_stream_from_external\n",
    "torch.xpu.init\n",
    "torch.xpu.is_available\n",
    "torch.xpu.is_initialized\n",
    "torch.xpu.set_device\n",
    "torch.xpu.set_stream\n",
    "torch.xpu.stream\n",
    "torch.xpu.synchronize\n",
    "torch.xpu.get_rng_state\n",
    "torch.xpu.get_rng_state_all\n",
    "torch.xpu.initial_seed\n",
    "torch.xpu.manual_seed\n",
    "torch.xpu.manual_seed_all\n",
    "torch.xpu.seed\n",
    "torch.xpu.seed_all\n",
    "torch.xpu.set_rng_state\n",
    "torch.xpu.set_rng_state_all\n",
    "Event\n",
    "Stream\n",
    "torch.xpu.memory.empty_cache\n",
    "torch.xpu.memory.max_memory_allocated\n",
    "torch.xpu.memory.max_memory_reserved\n",
    "torch.xpu.memory.mem_get_info\n",
    "torch.xpu.memory.memory_allocated\n",
    "torch.xpu.memory.memory_reserved\n",
    "torch.xpu.memory.memory_stats\n",
    "torch.xpu.memory.memory_stats_as_nested_dict\n",
    "torch.xpu.memory.reset_accumulated_memory_stats\n",
    "torch.xpu.memory.reset_peak_memory_stats\n",
    "torch.mtia\n",
    "StreamContext\n",
    "torch.mtia.current_device\n",
    "torch.mtia.current_stream\n",
    "torch.mtia.default_stream\n",
    "torch.mtia.device_count\n",
    "torch.mtia.init\n",
    "torch.mtia.is_available\n",
    "torch.mtia.is_initialized\n",
    "torch.mtia.memory_stats\n",
    "torch.mtia.get_device_capability\n",
    "torch.mtia.empty_cache\n",
    "torch.mtia.record_memory_history\n",
    "torch.mtia.snapshot\n",
    "torch.mtia.attach_out_of_memory_observer\n",
    "torch.mtia.set_device\n",
    "torch.mtia.set_stream\n",
    "torch.mtia.stream\n",
    "torch.mtia.synchronize\n",
    "device\n",
    "torch.mtia.set_rng_state\n",
    "torch.mtia.get_rng_state\n",
    "torch.mtia.DeferredMtiaCallError\n",
    "Event\n",
    "Stream\n",
    "torch.mtia.memory\n",
    "torch.mtia.memory.memory_stats\n",
    "torch.mtia.memory.memory_allocated\n",
    "torch.mtia.memory.memory_reserved\n",
    "Meta device\n",
    "torch.backends\n",
    "torch.export\n",
    "torch.export API Reference\n",
    "torch.export Programming Model\n",
    "torch.export IR Specification\n",
    "PT2 Archive Spec\n",
    "Draft Export\n",
    "Joint with descriptors\n",
    "Control Flow - Cond\n",
    "ExportDB\n",
    "torch.escape-hatch\n",
    "torch.cond\n",
    "torch.dynamic-shape\n",
    "python.closure\n",
    "torch.dynamic-value\n",
    "python.data-structure\n",
    "python.assert\n",
    "python.control-flow\n",
    "torch.map\n",
    "python.builtin\n",
    "python.object-model\n",
    "python.context-manager\n",
    "torch.operator\n",
    "torch.mutation\n",
    "AOTInductor: Ahead-Of-Time Compilation for Torch.Export-ed Models\n",
    "torch._logging\n",
    "torch._logging.set_logs\n",
    "AOTInductor Minifier\n",
    "AOTInductor Debugging Guide\n",
    "IRs\n",
    "Dynamic Shapes\n",
    "Fake tensor\n",
    "Writing Graph Transformations on ATen IR\n",
    "torch.distributed\n",
    "Experimental Object Oriented Distributed API\n",
    "torch.distributed.tensor\n",
    "torch.distributed.algorithms.join\n",
    "torch.distributed.elastic\n",
    "Quickstart\n",
    "Train script\n",
    "Examples\n",
    "torchrun (Elastic Launch)\n",
    "Elastic Agent\n",
    "Multiprocessing\n",
    "Error Propagation\n",
    "Rendezvous\n",
    "Expiration Timers\n",
    "Metrics\n",
    "Events\n",
    "Subprocess Handling\n",
    "Control Plane\n",
    "NUMA Binding Utilities\n",
    "Customization\n",
    "TorchElastic Kubernetes\n",
    "torch.distributed.fsdp\n",
    "torch.distributed.fsdp.fully_shard\n",
    "torch.distributed.tensor.parallel\n",
    "torch.distributed.optim\n",
    "torch.distributed.pipelining\n",
    "torch.distributed.checkpoint\n",
    "torch.distributions\n",
    "torch.compiler\n",
    "Getting Started\n",
    "torch.compiler API reference\n",
    "torch.compiler.compile\n",
    "torch.compiler.reset\n",
    "torch.compiler.allow_in_graph\n",
    "torch.compiler.substitute_in_graph\n",
    "torch.compiler.assume_constant_result\n",
    "torch.compiler.list_backends\n",
    "torch.compiler.disable\n",
    "torch.compiler.set_stance\n",
    "torch.compiler.set_enable_guard_collectives\n",
    "torch.compiler.cudagraph_mark_step_begin\n",
    "torch.compiler.is_compiling\n",
    "torch.compiler.is_dynamo_compiling\n",
    "torch.compiler.is_exporting\n",
    "torch.compiler.skip_guard_on_inbuilt_nn_modules_unsafe\n",
    "torch.compiler.skip_guard_on_all_nn_modules_unsafe\n",
    "torch.compiler.keep_tensor_guards_unsafe\n",
    "torch.compiler.skip_guard_on_globals_unsafe\n",
    "torch.compiler.nested_compile_region\n",
    "torch.compiler.config\n",
    "TorchDynamo APIs for fine-grained tracing\n",
    "torch.compile has different autograd semantics\n",
    "AOTInductor: Ahead-Of-Time Compilation for Torch.Export-ed Models\n",
    "torch._logging\n",
    "torch._logging.set_logs\n",
    "AOTInductor Minifier\n",
    "AOTInductor Debugging Guide\n",
    "TorchInductor GPU Profiling\n",
    "Profiling to understand torch.compile performance\n",
    "Frequently Asked Questions\n",
    "torch.compile Troubleshooting\n",
    "PyTorch 2.0 Performance Dashboard\n",
    "TorchInductor and AOTInductor Provenance Tracking\n",
    "torch.compile Programming Model\n",
    "Dynamo Core Concepts\n",
    "Working with Graph Breaks\n",
    "Use fullgraph=True to Identify and Eliminate Graph Breaks\n",
    "Common Graph Breaks\n",
    "Use torch._dynamo.nonstrict_trace\n",
    "Custom Operators\n",
    "Working with fullgraph=False\n",
    "Non-strict Tracing Programming Model\n",
    "Dealing with Recompilations\n",
    "tlparse / TORCH_TRACE\n",
    "Reporting Issues\n",
    "Dynamo Overview\n",
    "Dynamo Deep-Dive\n",
    "Dynamic Shapes\n",
    "torch._logging\n",
    "torch._logging.set_logs\n",
    "PYTORCH ProcessGroupNCCL Environment Variables\n",
    "torch.fft\n",
    "torch.fft.fft\n",
    "torch.fft.ifft\n",
    "torch.fft.fft2\n",
    "torch.fft.ifft2\n",
    "torch.fft.fftn\n",
    "torch.fft.ifftn\n",
    "torch.fft.rfft\n",
    "torch.fft.irfft\n",
    "torch.fft.rfft2\n",
    "torch.fft.irfft2\n",
    "torch.fft.rfftn\n",
    "torch.fft.irfftn\n",
    "torch.fft.hfft\n",
    "torch.fft.ihfft\n",
    "torch.fft.hfft2\n",
    "torch.fft.ihfft2\n",
    "torch.fft.hfftn\n",
    "torch.fft.ihfftn\n",
    "torch.fft.fftfreq\n",
    "torch.fft.rfftfreq\n",
    "torch.fft.fftshift\n",
    "torch.fft.ifftshift\n",
    "torch.func\n",
    "torch.func Whirlwind Tour\n",
    "torch.func API Reference\n",
    "torch.func.vmap\n",
    "torch.func.grad\n",
    "torch.func.grad_and_value\n",
    "torch.func.vjp\n",
    "torch.func.jvp\n",
    "torch.func.linearize\n",
    "torch.func.jacrev\n",
    "torch.func.jacfwd\n",
    "torch.func.hessian\n",
    "torch.func.functionalize\n",
    "torch.func.functional_call\n",
    "torch.func.stack_module_state\n",
    "torch.func.replace_all_batch_norm_modules_\n",
    "Patching Batch Norm\n",
    "torch.func.debug_unwrap\n",
    "UX Limitations\n",
    "Migrating from functorch to torch.func\n",
    "torch.futures\n",
    "torch.fx\n",
    "torch.fx.experimental\n",
    "ShapeEnv\n",
    "DimDynamic\n",
    "StrictMinMaxConstraint\n",
    "RelaxedUnspecConstraint\n",
    "EqualityConstraint\n",
    "SymbolicContext\n",
    "StatelessSymbolicContext\n",
    "StatefulSymbolicContext\n",
    "SubclassSymbolicContext\n",
    "DimConstraints\n",
    "ShapeEnvSettings\n",
    "ConvertIntKey\n",
    "CallMethodKey\n",
    "PropagateUnbackedSymInts\n",
    "DivideByKey\n",
    "InnerTensorKey\n",
    "Specialization\n",
    "torch.fx.experimental.symbolic_shapes.hint_int\n",
    "torch.fx.experimental.symbolic_shapes.is_concrete_int\n",
    "torch.fx.experimental.symbolic_shapes.is_concrete_bool\n",
    "torch.fx.experimental.symbolic_shapes.is_concrete_float\n",
    "torch.fx.experimental.symbolic_shapes.has_free_symbols\n",
    "torch.fx.experimental.symbolic_shapes.has_free_unbacked_symbols\n",
    "torch.fx.experimental.symbolic_shapes.guard_or_true\n",
    "torch.fx.experimental.symbolic_shapes.guard_or_false\n",
    "torch.fx.experimental.symbolic_shapes.guard_size_oblivious\n",
    "torch.fx.experimental.symbolic_shapes.sym_and\n",
    "torch.fx.experimental.symbolic_shapes.sym_eq\n",
    "torch.fx.experimental.symbolic_shapes.sym_or\n",
    "torch.fx.experimental.symbolic_shapes.constrain_range\n",
    "torch.fx.experimental.symbolic_shapes.constrain_unify\n",
    "torch.fx.experimental.symbolic_shapes.canonicalize_bool_expr\n",
    "torch.fx.experimental.symbolic_shapes.statically_known_true\n",
    "torch.fx.experimental.symbolic_shapes.statically_known_false\n",
    "torch.fx.experimental.symbolic_shapes.has_static_value\n",
    "torch.fx.experimental.symbolic_shapes.lru_cache\n",
    "torch.fx.experimental.symbolic_shapes.check_consistent\n",
    "torch.fx.experimental.symbolic_shapes.compute_unbacked_bindings\n",
    "torch.fx.experimental.symbolic_shapes.rebind_unbacked\n",
    "torch.fx.experimental.symbolic_shapes.rebind_unbacked_bindings\n",
    "torch.fx.experimental.symbolic_shapes.resolve_unbacked_bindings\n",
    "torch.fx.experimental.symbolic_shapes.is_accessor_node\n",
    "torch.fx.experimental.proxy_tensor.make_fx\n",
    "torch.fx.experimental.proxy_tensor.handle_sym_dispatch\n",
    "torch.fx.experimental.proxy_tensor.get_proxy_mode\n",
    "torch.fx.experimental.proxy_tensor.maybe_enable_thunkify\n",
    "torch.fx.experimental.proxy_tensor.maybe_disable_thunkify\n",
    "torch.hub\n",
    "torch.jit\n",
    "torch.linalg\n",
    "torch.monitor\n",
    "torch.signal\n",
    "torch.special\n",
    "torch.overrides\n",
    "torch.package\n",
    "torch.profiler\n",
    "torch.nn.init\n",
    "torch.nn.attention\n",
    "torch.nn.attention.sdpa_kernel\n",
    "SDPBackend\n",
    "torch.nn.attention.flex_attention\n",
    "torch.nn.attention.bias\n",
    "torch.nn.attention.experimental\n",
    "torch.onnx\n",
    "torch.export-based ONNX Exporter\n",
    "torch.onnx.ops\n",
    "torch.onnx.verification\n",
    "torch.optim\n",
    "torch.optim.Optimizer.add_param_group\n",
    "torch.optim.Optimizer.load_state_dict\n",
    "torch.optim.Optimizer.register_load_state_dict_pre_hook\n",
    "torch.optim.Optimizer.register_load_state_dict_post_hook\n",
    "torch.optim.Optimizer.state_dict\n",
    "torch.optim.Optimizer.register_state_dict_pre_hook\n",
    "torch.optim.Optimizer.register_state_dict_post_hook\n",
    "torch.optim.Optimizer.step\n",
    "torch.optim.Optimizer.register_step_pre_hook\n",
    "torch.optim.Optimizer.register_step_post_hook\n",
    "torch.optim.Optimizer.zero_grad\n",
    "Adadelta\n",
    "Adafactor\n",
    "Adagrad\n",
    "Adam\n",
    "AdamW\n",
    "SparseAdam\n",
    "Adamax\n",
    "ASGD\n",
    "LBFGS\n",
    "Muon\n",
    "NAdam\n",
    "RAdam\n",
    "RMSprop\n",
    "Rprop\n",
    "SGD\n",
    "LRScheduler\n",
    "LambdaLR\n",
    "MultiplicativeLR\n",
    "StepLR\n",
    "MultiStepLR\n",
    "ConstantLR\n",
    "LinearLR\n",
    "ExponentialLR\n",
    "PolynomialLR\n",
    "CosineAnnealingLR\n",
    "ChainedScheduler\n",
    "SequentialLR\n",
    "ReduceLROnPlateau\n",
    "CyclicLR\n",
    "OneCycleLR\n",
    "CosineAnnealingWarmRestarts\n",
    "AveragedModel\n",
    "SWALR\n",
    "Aliases in torch.optim\n",
    "Adadelta\n",
    "torch.optim.adadelta.adadelta\n",
    "Adagrad\n",
    "torch.optim.adagrad.adagrad\n",
    "Adam\n",
    "torch.optim.adam.adam\n",
    "Adamax\n",
    "torch.optim.adamax.adamax\n",
    "AdamW\n",
    "torch.optim.adamw.adamw\n",
    "ASGD\n",
    "torch.optim.asgd.asgd\n",
    "LBFGS\n",
    "NAdam\n",
    "torch.optim.nadam.nadam\n",
    "RAdam\n",
    "torch.optim.radam.radam\n",
    "RMSprop\n",
    "torch.optim.rmsprop.rmsprop\n",
    "Rprop\n",
    "torch.optim.rprop.rprop\n",
    "SGD\n",
    "torch.optim.sgd.sgd\n",
    "SparseAdam\n",
    "Complex Numbers\n",
    "DDP Communication Hooks\n",
    "Quantization\n",
    "Quantization API Reference\n",
    "quantize\n",
    "quantize_dynamic\n",
    "quantize_qat\n",
    "prepare\n",
    "prepare_qat\n",
    "convert\n",
    "fuse_modules\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}